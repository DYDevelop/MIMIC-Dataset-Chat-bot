1. J Med Internet Res. 2024 Apr 17;26:e48330. doi: 10.2196/48330.

Comparing Open-Access Database and Traditional Intensive Care Studies Using 
Machine Learning: Bibliometric Analysis Study.

Ke Y(#)(1), Yang R(#)(2), Liu N(2).

Author information:
(1)Division of Anesthesiology and Perioperative Medicine, Singapore General 
Hospital, Singapore, Singapore.
(2)Centre for Quantitative Medicine, Duke-NUS Medical School, National 
University of Singapore, Singapore, Singapore.
(#)Contributed equally

BACKGROUND: Intensive care research has predominantly relied on conventional 
methods like randomized controlled trials. However, the increasing popularity of 
open-access, free databases in the past decade has opened new avenues for 
research, offering fresh insights. Leveraging machine learning (ML) techniques 
enables the analysis of trends in a vast number of studies.
OBJECTIVE: This study aims to conduct a comprehensive bibliometric analysis 
using ML to compare trends and research topics in traditional intensive care 
unit (ICU) studies and those done with open-access databases (OADs).
METHODS: We used ML for the analysis of publications in the Web of Science 
database in this study. Articles were categorized into "OAD" and "traditional 
intensive care" (TIC) studies. OAD studies were included in the Medical 
Information Mart for Intensive Care (MIMIC), eICU Collaborative Research 
Database (eICU-CRD), Amsterdam University Medical Centers Database 
(AmsterdamUMCdb), High Time Resolution ICU Dataset (HiRID), and Pediatric 
Intensive Care database. TIC studies included all other intensive care studies. 
Uniform manifold approximation and projection was used to visualize the corpus 
distribution. The BERTopic technique was used to generate 30 topic-unique 
identification numbers and to categorize topics into 22 topic families.
RESULTS: A total of 227,893 records were extracted. After exclusions, 145,426 
articles were identified as TIC and 1301 articles as OAD studies. TIC studies 
experienced exponential growth over the last 2 decades, culminating in a peak of 
16,378 articles in 2021, while OAD studies demonstrated a consistent upsurge 
since 2018. Sepsis, ventilation-related research, and pediatric intensive care 
were the most frequently discussed topics. TIC studies exhibited broader 
coverage than OAD studies, suggesting a more extensive research scope.
CONCLUSIONS: This study analyzed ICU research, providing valuable insights from 
a large number of publications. OAD studies complement TIC studies, focusing on 
predictive modeling, while TIC studies capture essential qualitative 
information. Integrating both approaches in a complementary manner is the future 
direction for ICU research. Additionally, natural language processing techniques 
offer a transformative alternative for literature review and bibliometric 
analysis.

©Yuhe Ke, Rui Yang, Nan Liu. Originally published in the Journal of Medical 
Internet Research (https://www.jmir.org), 17.04.2024.

DOI: 10.2196/48330
PMCID: PMC11063894
PMID: 38630522 [Indexed for MEDLINE]

Conflict of interest statement: Conflicts of Interest: None declared.


2. Int J Med Inform. 2018 Dec;120:50-61. doi: 10.1016/j.ijmedinf.2018.09.021. Epub 
2018 Oct 2.

Towards automated clinical coding.

Catling F(1), Spithourakis GP(2), Riedel S(3).

Author information:
(1)University College London, Gower Street, London WC1E 6BT, UK. Electronic 
address: f.catling@ucl.ac.uk.
(2)University College London, Gower Street, London WC1E 6BT, UK. Electronic 
address: g.spithourakis@cs.ucl.ac.uk.
(3)University College London, Gower Street, London WC1E 6BT, UK. Electronic 
address: s.riedel@cs.ucl.ac.uk.

BACKGROUND: Patients' encounters with healthcare services must undergo clinical 
coding. These codes are typically derived from free-text notes. Manual clinical 
coding is expensive, time-consuming and prone to error. Automated clinical 
coding systems have great potential to save resources, and realtime availability 
of codes would improve oversight of patient care and accelerate research. 
Automated coding is made challenging by the idiosyncrasies of clinical text, the 
large number of disease codes and their unbalanced distribution.
METHODS: We explore methods for representing clinical text and the labels in 
hierarchical clinical coding ontologies. Text is represented as term 
frequency-inverse document frequency counts and then as word embeddings, which 
we use as input to recurrent neural networks. Labels are represented atomically, 
and then by learning representations of each node in a coding ontology and 
composing a representation for each label from its respective node path. We 
consider different strategies for initialisation of the node representations. We 
evaluate our methods using the publicly-available Medical Information Mart for 
Intensive Care III dataset: we extract the history of presenting illness section 
from each discharge summary in the dataset, then predicting the International 
Classification of Diseases, ninth revision, Clinical Modification codes 
associated with these.
RESULTS: Composing the label representations from the clinical-coding-ontology 
nodes increased weighted F1 for prediction of the 17,561 disease labels to 
0.264-0.281 from 0.232-0.249 for atomic representations. Recurrent neural 
network text representation improved weighted F1 for prediction of the 19 
disease-category labels to 0.682-0.701 from 0.662-0.682 using term 
frequency-inverse document frequency. However, term frequency-inverse document 
frequency outperformed recurrent neural networks for prediction of the 17,561 
disease labels.
CONCLUSIONS: This study demonstrates that hierarchically-structured medical 
knowledge can be incorporated into statistical models, and produces improved 
performance during automated clinical coding. This performance improvement 
results primarily from improved representation of rarer diseases. We also show 
that recurrent neural networks improve representation of medical text in some 
settings. Learning good representations of the very rare diseases in clinical 
coding ontologies from data alone remains challenging, and alternative means of 
representing these diseases will form a major focus of future work on automated 
clinical coding.

Copyright © 2018 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.ijmedinf.2018.09.021
PMID: 30409346 [Indexed for MEDLINE]


3. JACC Heart Fail. 2025 Jan;13(1):75-87. doi: 10.1016/j.jchf.2024.08.012. Epub 
2024 Oct 23.

Automated Identification of Heart Failure With Reduced Ejection Fraction Using 
Deep Learning-Based Natural Language Processing.

Nargesi AA(1), Adejumo P(2), Dhingra LS(2), Rosand B(2), Hengartner A(2), Coppi 
A(3), Benigeri S(4), Sen S(2), Ahmad T(2), Nadkarni GN(5), Lin Z(6), Ahmad 
FS(4), Krumholz HM(7), Khera R(8).

Author information:
(1)Heart and Vascular Center, Brigham and Women's Hospital, Harvard School of 
Medicine, Boston, Massachusetts, USA.
(2)Section of Cardiovascular Medicine, Department of Internal Medicine, Yale 
University, New Haven, Connecticut, USA.
(3)Section of Cardiovascular Medicine, Department of Internal Medicine, Yale 
University, New Haven, Connecticut, USA; Center for Outcomes Research and 
Evaluation (CORE), Yale New Haven Hospital, New Haven, Connecticut, USA.
(4)Division of Cardiology, Department of Medicine, Feinberg School of Medicine, 
Northwestern University, Chicago, Illinois, USA.
(5)Division of Nephrology, Department of Medicine, Icahn School of Medicine at 
Mount Sinai, New York, New York, USA.
(6)Center for Outcomes Research and Evaluation (CORE), Yale New Haven Hospital, 
New Haven, Connecticut, USA.
(7)Section of Cardiovascular Medicine, Department of Internal Medicine, Yale 
University, New Haven, Connecticut, USA; Center for Outcomes Research and 
Evaluation (CORE), Yale New Haven Hospital, New Haven, Connecticut, USA; 
Department of Health Policy and Management, Yale School of Public Health, New 
Haven, Connecticut, USA; Section of Health Informatics, Department of 
Biostatistics, Yale School of Public Health, New Haven, Connecticut, USA.
(8)Section of Cardiovascular Medicine, Department of Internal Medicine, Yale 
University, New Haven, Connecticut, USA; Center for Outcomes Research and 
Evaluation (CORE), Yale New Haven Hospital, New Haven, Connecticut, USA. 
Electronic address: rohan.khera@yale.edu.

Update of
    medRxiv. 2023 Sep 11:2023.09.10.23295315. doi: 10.1101/2023.09.10.23295315.

BACKGROUND: The lack of automated tools for measuring care quality limits the 
implementation of a national program to assess guideline-directed care in heart 
failure with reduced ejection fraction (HFrEF).
OBJECTIVES: The authors aimed to automate the identification of patients with 
HFrEF at hospital discharge, an opportunity to evaluate and improve the quality 
of care.
METHODS: The authors developed a novel deep-learning language model for 
identifying patients with HFrEF from discharge summaries of hospitalizations 
with heart failure at Yale New Haven Hospital during 2015 to 2019. HFrEF was 
defined by left ventricular ejection fraction <40% on antecedent 
echocardiography. The authors externally validated the model at Northwestern 
Medicine, community hospitals of Yale, and the MIMIC-III (Medical Information 
Mart for Intensive Care III) database.
RESULTS: A total of 13,251 notes from 5,392 unique individuals (age 73 ± 14 
years, 48% women), including 2,487 patients with HFrEF (46.1%), were used for 
model development (train/held-out: 70%/30%). The model achieved an area under 
receiver-operating characteristic curve (AUROC) of 0.97 and area under precision 
recall curve (AUPRC) of 0.97 in detecting HFrEF on the held-out set. The model 
had high performance in identifying HFrEF with AUROC = 0.94 and AUPRC = 0.91 on 
19,242 notes from Northwestern Medicine, AUROC = 0.95 and AUPRC = 0.96 on 139 
manually abstracted notes from Yale community hospitals, and AUROC = 0.91 and 
AUPRC = 0.92 on 146 manually reviewed notes from MIMIC-III. Model-based 
predictions of HFrEF corresponded to a net reclassification improvement of 60.2% 
± 1.9% compared with diagnosis codes (P < 0.001).
CONCLUSIONS: The authors developed a language model that identifies HFrEF from 
clinical notes with high precision and accuracy, representing a key element in 
automating quality assessment for individuals with HFrEF.

Copyright © 2025. Published by Elsevier Inc.

DOI: 10.1016/j.jchf.2024.08.012
PMID: 39453355 [Indexed for MEDLINE]

Conflict of interest statement: Funding Support and Author Disclosures This 
study was supported by research funding awarded to Dr Khera by the Yale School 
of Medicine and grant support from the National Heart, Lung, and Blood Institute 
(NHLBI) of the National Institutes of Health (NIH) under the award K23HL153775. 
Dr Ahmad is a consultant for Sanofi Aventis, Amgen, and Cytokinetics; and has 
received research funding from Boehringer Ingelheim, AstraZeneca, Cytokinetics, 
and Relypsa. Dr Nadkarni has consultancy agreements with AstraZeneca, BioVie, 
GLG Consulting, Pensieve Health, Reata, Renalytix, Siemens Healthineers and 
Variant Bio; has received research funding from Goldfinch Bio, and Renalytix; 
has received honoraria from AstraZeneca, BioVie, Lexicon, Daiichi Sankyo, 
Meanrini Health, and Reata; has patents or royalties with Renalytix; owns equity 
and stock options in Pensieve Health and Renalytix as a scientific cofounder; 
owns equity in Verici Dx; has received financial compensation as a scientific 
board member and advisor to Renalytix; has served on the advisory board of 
Neurona Health; and has served in an advisory or leadership role for Pensieve 
Health and Renalytix. Dr Ahmad has received grants from the Agency for 
Healthcare Research and Quality, NIH/NHLBI, and American Heart Association; and 
has received personal fees from Teladoc, Livongo, and Pfizer, outside of the 
submitted work. Dr Krumholz works under contract with the Centers for Medicare 
and Medicaid Services to support quality measurement programs; was a recipient 
of a research grant from Johnson and Johnson, through Yale University, to 
support clinical trial data sharing; was a recipient of a research agreement, 
through Yale University, from the Shenzhen Center for Health Information for 
work to advance intelligent disease prevention and health promotion; 
collaborates with the National Center for Cardiovascular Diseases in Beijing; 
receives payment from the Arnold and Porter Law Firm for work related to the 
Sanofi clopidogrel litigation, from the Martin Baughman Law Firm for work 
related to the Cook Celect IVC filter litigation, and from the Siegfried and 
Jensen Law Firm for work related to Vioxx litigation; chairs a Cardiac 
Scientific Advisory Board for UnitedHealth; was a member of the IBM Watson 
Health Life Sciences Board; is a member of the Advisory Board for Element 
Science, the Advisory Board for Facebook, and the Physician Advisory Board for 
Aetna; and is the cofounder of Hugo Health, a personal health information 
platform, and cofounder of Refactor Health, a health care AI-augmented data 
management company. Dr Khera is an Associate Editor of JAMA; receives support 
from the NHLBI of the NIH (under awards R01HL167858 and K23HL153775) and the 
Doris Duke Charitable Foundation (under award 2022060); has received research 
support, through Yale, from Bristol Myers Squibb, Novo Nordisk, and BridgeBio; 
is a coinventor of U.S. Pending Patent Applications 63/562,335, 63/177,117, 
63/428,569, 63/346,610, 63/484,426, 63/508,315, and 63/606,203; and is a 
co-founder of Ensight-AI, Inc and Evidence2Health, health platforms to improve 
cardiovascular diagnosis and evidence-based cardiovascular care. Dr Nargesi has 
received funding from the NHLBI under award number T32HL007604. All other 
authors have reported that they have no relationships relevant to the contents 
of this paper to disclose.


4. J Biomed Inform. 2022 Oct;134:104195. doi: 10.1016/j.jbi.2022.104195. Epub 2022 
Sep 21.

Modelling patient trajectories using multimodal information.

Silva JF(1), Matos S(2).

Author information:
(1)DETI/IEETA, University of Aveiro, Aveiro, Portugal. Electronic address: 
joaofsilva@ua.pt.
(2)DETI/IEETA, University of Aveiro, Aveiro, Portugal. Electronic address: 
aleixomatos@ua.pt.

BACKGROUND: Electronic Health Records (EHRs) aggregate diverse information at 
the patient level, holding a trajectory representative of the evolution of the 
patient health status throughout time. Although this information provides 
context and can be leveraged by physicians to monitor patient health and make 
more accurate prognoses/diagnoses, patient records can contain information from 
very long time spans, which combined with the rapid generation rate of medical 
data makes clinical decision making more complex. Patient trajectory modelling 
can assist by exploring existing information in a scalable manner, and can 
contribute in augmenting health care quality by fostering preventive medicine 
practices (e.g. earlier disease diagnosis).
METHODS: We propose a solution to model patient trajectories that combines 
different types of information (e.g. clinical text, standard codes) and 
considers the temporal aspect of clinical data. This solution leverages two 
different architectures: one supporting flexible sets of input features, to 
convert patient admissions into dense representations; and a second exploring 
extracted admission representations in a recurrent-based architecture, where 
patient trajectories are processed in sub-sequences using a sliding window 
mechanism.
RESULTS: The developed solution was evaluated on two different clinical 
outcomes, unexpected patient readmission and disease progression, using the 
publicly available Medical Information Mart for Intensive Care (MIMIC)-III 
clinical database. The results obtained demonstrate the potential of the first 
architecture to model readmission and diagnoses prediction using single patient 
admissions. While information from clinical text did not show the discriminative 
power observed in other existing works, this may be explained by the need to 
fine-tune the clinicalBERT model. Finally, we demonstrate the potential of the 
sequence-based architecture using a sliding window mechanism to represent the 
input data, attaining comparable performances to other existing solutions.
CONCLUSION: Herein, we explored DL-based techniques to model patient 
trajectories and propose two flexible architectures that explore patient 
admissions on an individual and sequence basis. The combination of clinical text 
with other types of information led to positive results, which can be further 
improved by including a fine-tuned version of clinicalBERT in the architectures. 
The proposed solution can be publicly accessed at 
https://github.com/bioinformatics-ua/PatientTM.

Copyright © 2022 The Author(s). Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jbi.2022.104195
PMID: 36150641 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare that they have no known competing financial interests or personal 
relationships that could have appeared to influence the work reported in this 
paper.


5. JMIR Med Inform. 2024 Aug 19;12:e56243. doi: 10.2196/56243.

Extraction of Substance Use Information From Clinical Notes: Generative 
Pretrained Transformer-Based Investigation.

Shah-Mohammadi F(#)(1), Finkelstein J(#)(1).

Author information:
(1)Department of Biomedical Informatics, School of Medicine, The University of 
Utah, Salt Lake City, UT, United States.
(#)Contributed equally

BACKGROUND: Understanding the multifaceted nature of health outcomes requires a 
comprehensive examination of the social, economic, and environmental 
determinants that shape individual well-being. Among these determinants, 
behavioral factors play a crucial role, particularly the consumption patterns of 
psychoactive substances, which have important implications on public health. The 
Global Burden of Disease Study shows a growing impact in disability-adjusted 
life years due to substance use. The successful identification of patients' 
substance use information equips clinical care teams to address 
substance-related issues more effectively, enabling targeted support and 
ultimately improving patient outcomes.
OBJECTIVE: Traditional natural language processing methods face limitations in 
accurately parsing diverse clinical language associated with substance use. 
Large language models offer promise in overcoming these challenges by adapting 
to diverse language patterns. This study investigates the application of the 
generative pretrained transformer (GPT) model in specific GPT-3.5 for extracting 
tobacco, alcohol, and substance use information from patient discharge summaries 
in zero-shot and few-shot learning settings. This study contributes to the 
evolving landscape of health care informatics by showcasing the potential of 
advanced language models in extracting nuanced information critical for 
enhancing patient care.
METHODS: The main data source for analysis in this paper is Medical Information 
Mart for Intensive Care III data set. Among all notes in this data set, we 
focused on discharge summaries. Prompt engineering was undertaken, involving an 
iterative exploration of diverse prompts. Leveraging carefully curated examples 
and refined prompts, we investigate the model's proficiency through zero-shot as 
well as few-shot prompting strategies.
RESULTS: Results show GPT's varying effectiveness in identifying mentions of 
tobacco, alcohol, and substance use across learning scenarios. Zero-shot 
learning showed high accuracy in identifying substance use, whereas few-shot 
learning reduced accuracy but improved in identifying substance use status, 
enhancing recall and F1-score at the expense of lower precision.
CONCLUSIONS: Excellence of zero-shot learning in precisely extracting text span 
mentioning substance use demonstrates its effectiveness in situations in which 
comprehensive recall is important. Conversely, few-shot learning offers 
advantages when accurately determining the status of substance use is the 
primary focus, even if it involves a trade-off in precision. The results 
contribute to enhancement of early detection and intervention strategies, tailor 
treatment plans with greater precision, and ultimately, contribute to a holistic 
understanding of patient health profiles. By integrating these artificial 
intelligence-driven methods into electronic health record systems, clinicians 
can gain immediate, comprehensive insights into substance use that results in 
shaping interventions that are not only timely but also more personalized and 
effective.

©Fatemeh Shah-Mohammadi, Joseph Finkelstein. Originally published in JMIR 
Medical Informatics (https://medinform.jmir.org), 19.08.2024.

DOI: 10.2196/56243
PMCID: PMC11369538
PMID: 39037700

Conflict of interest statement: Conflicts of Interest: None declared.


6. J Med Internet Res. 2020 Aug 14;22(8):e18855. doi: 10.2196/18855.

Text Processing for Detection of Fungal Ocular Involvement in Critical Care 
Patients: Cross-Sectional Study.

Baxter SL(1)(2), Klie AR(3), Radha Saseendrakumar B(4), Ye GY(2), Hogarth M(2).

Author information:
(1)Viterbi Family Department of Ophthalmology and Shiley Eye Institute, 
University of California San Diego, La Jolla, CA, United States.
(2)Division of Biomedical Informatics, Department of Medicine, University of 
California San Diego, La Jolla, CA, United States.
(3)Bioinformatics and Systems Biology, University of California San Diego, La 
Jolla, CA, United States.
(4)Department of Computer Science and Engineering, University of California San 
Diego, La Jolla, CA, United States.

BACKGROUND: Fungal ocular involvement can develop in patients with fungal 
bloodstream infections and can be vision-threatening. Ocular involvement has 
become less common in the current era of improved antifungal therapies. 
Retrospectively determining the prevalence of fungal ocular involvement is 
important for informing clinical guidelines, such as the need for routine 
ophthalmologic consultations. However, manual retrospective record review to 
detect cases is time-consuming.
OBJECTIVE: This study aimed to determine the prevalence of fungal ocular 
involvement in a critical care database using both structured and unstructured 
electronic health record (EHR) data.
METHODS: We queried microbiology data from 46,467 critical care patients over 12 
years (2000-2012) from the Medical Information Mart for Intensive Care III 
(MIMIC-III) to identify 265 patients with culture-proven fungemia. For each 
fungemic patient, demographic data, fungal species present in blood culture, and 
risk factors for fungemia (eg, presence of indwelling catheters, recent major 
surgery, diabetes, immunosuppressed status) were ascertained. All structured 
diagnosis codes and free-text narrative notes associated with each patient's 
hospitalization were also extracted. Screening for fungal endophthalmitis was 
performed using two approaches: (1) by querying a wide array of eye- and 
vision-related diagnosis codes, and (2) by utilizing a custom regular expression 
pipeline to identify and collate relevant text matches pertaining to fungal 
ocular involvement. Both approaches were validated using manual record review. 
The main outcome measure was the documentation of any fungal ocular involvement.
RESULTS: In total, 265 patients had culture-proven fungemia, with Candida 
albicans (n=114, 43%) and Candida glabrata (n=74, 28%) being the most common 
fungal species in blood culture. The in-hospital mortality rate was 121 (46%). 
In total, 7 patients were identified as having eye- or vision-related diagnosis 
codes, none of whom had fungal endophthalmitis based on record review. There 
were 26,830 free-text narrative notes associated with these 265 patients. A 
regular expression pipeline based on relevant terms yielded possible matches in 
683 notes from 108 patients. Subsequent manual record review again demonstrated 
that no patients had fungal ocular involvement. Therefore, the prevalence of 
fungal ocular involvement in this cohort was 0%.
CONCLUSIONS: MIMIC-III contained no cases of ocular involvement among fungemic 
patients, consistent with prior studies reporting low rates of ocular 
involvement in fungemia. This study demonstrates an application of natural 
language processing to expedite the review of narrative notes. This approach is 
highly relevant for ophthalmology, where diagnoses are often based on physical 
examination findings that are documented within clinical notes.

©Sally L Baxter, Adam R Klie, Bharanidharan Radha Saseendrakumar, Gordon Y Ye, 
Michael Hogarth. Originally published in the Journal of Medical Internet 
Research (http://www.jmir.org), 14.08.2020.

DOI: 10.2196/18855
PMCID: PMC7455861
PMID: 32795984 [Indexed for MEDLINE]

Conflict of interest statement: Conflicts of Interest: None declared.


7. BMJ Health Care Inform. 2022 Nov;29(1):e100519. doi: 10.1136/bmjhci-2021-100519.

Clinical utility of automatic phenotype annotation in unstructured clinical 
notes: intensive care unit use.

Zhang J(#)(1), Bolanos Trujillo LD(#)(1), Tanwar A(#)(1), Ive J(1), Gupta V(1), 
Guo Y(2).

Author information:
(1)Pangaea Data Limited, London, UK.
(2)Pangaea Data Limited, London, UK yguo@pangaeadata.ai.
(#)Contributed equally

OBJECTIVE: Clinical notes contain information that has not been documented 
elsewhere, including responses to treatment and clinical findings, which are 
crucial for predicting key outcomes in patients in acute care. In this study, we 
propose the automatic annotation of phenotypes from clinical notes as a method 
to capture essential information to predict outcomes in the intensive care unit 
(ICU). This information is complementary to typically used vital signs and 
laboratory test results.
METHODS: In this study, we developed a novel phenotype annotation model to 
extract the phenotypical features of patients, which were then used as input 
features of predictive models to predict ICU patient outcomes. We demonstrated 
and validated this approach by conducting experiments on three ICU prediction 
tasks, including in-hospital mortality, physiological decompensation and length 
of stay (LOS) for over 24 000 patients using the Medical Information Mart for 
Intensive Care (MIMIC-III) dataset.
RESULTS: The predictive models incorporating phenotypical information achieved 
0.845 (area under the curve-receiver operating characteristic (AUC-ROC)) for 
in-hospital mortality, 0.839 (AUC-ROC) for physiological decompensation and 
0.430 (kappa) for LOS, all of which consistently outperformed the baseline 
models using only vital signs and laboratory test results. Moreover, we 
conducted a thorough interpretability study showing that phenotypes provide 
valuable insights at both the patient and cohort levels.
CONCLUSION: The proposed approach demonstrates that phenotypical information 
complements traditionally used vital signs and laboratory test results and 
significantly improves the accuracy of outcome prediction in the ICU.

© Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No 
commercial re-use. See rights and permissions. Published by BMJ.

DOI: 10.1136/bmjhci-2021-100519
PMCID: PMC9644312
PMID: 36351702 [Indexed for MEDLINE]

Conflict of interest statement: Competing interests: This research is solely 
funded by Pangaea Data Limited. JZ, LDBT, AT, VG and YG are employed by Pangaea 
Data Limited. JI is employed by the Queen Mary University of London, but this 
study was conducted when JI was employed by Pangaea Data Limited. YG is also 
employed by Imperial College London and Hong Kong Baptist University, but YG 
supervised this study at Pangaea Data Limited.


8. J Med Internet Res. 2024 May 2;26:e54363. doi: 10.2196/54363.

Improving the Prognostic Evaluation Precision of Hospital Outcomes for Heart 
Failure Using Admission Notes and Clinical Tabular Data: Multimodal Deep 
Learning Model.

Gao Z(#)(1), Liu X(#)(2), Kang Y(3), Hu P(2), Zhang X(3), Yan W(2), Yan M(2), Yu 
P(3), Zhang Q(3), Xiao W(1), Zhang Z(2).

Author information:
(1)Beijing Engineering Research Center of Industrial Spectrum Imaging, School of 
Automation and Electrical Engineering, University of Science and Technology 
Beijing, Beijing, China.
(2)Center for Artificial Intelligence in Medicine, The General Hospital of 
People's Liberation Army, Beijing, China.
(3)Department of Cardiology, West China Hospital, Sichuan University, Chengdu, 
China.
(#)Contributed equally

BACKGROUND: Clinical notes contain contextualized information beyond structured 
data related to patients' past and current health status.
OBJECTIVE: This study aimed to design a multimodal deep learning approach to 
improve the evaluation precision of hospital outcomes for heart failure (HF) 
using admission clinical notes and easily collected tabular data.
METHODS: Data for the development and validation of the multimodal model were 
retrospectively derived from 3 open-access US databases, including the Medical 
Information Mart for Intensive Care III v1.4 (MIMIC-III) and MIMIC-IV v1.0, 
collected from a teaching hospital from 2001 to 2019, and the eICU Collaborative 
Research Database v1.2, collected from 208 hospitals from 2014 to 2015. The 
study cohorts consisted of all patients with critical HF. The clinical notes, 
including chief complaint, history of present illness, physical examination, 
medical history, and admission medication, as well as clinical variables 
recorded in electronic health records, were analyzed. We developed a deep 
learning mortality prediction model for in-hospital patients, which underwent 
complete internal, prospective, and external evaluation. The Integrated 
Gradients and SHapley Additive exPlanations (SHAP) methods were used to analyze 
the importance of risk factors.
RESULTS: The study included 9989 (16.4%) patients in the development set, 2497 
(14.1%) patients in the internal validation set, 1896 (18.3%) in the prospective 
validation set, and 7432 (15%) patients in the external validation set. The area 
under the receiver operating characteristic curve of the models was 0.838 (95% 
CI 0.827-0.851), 0.849 (95% CI 0.841-0.856), and 0.767 (95% CI 0.762-0.772), for 
the internal, prospective, and external validation sets, respectively. The area 
under the receiver operating characteristic curve of the multimodal model 
outperformed that of the unimodal models in all test sets, and tabular data 
contributed to higher discrimination. The medical history and physical 
examination were more useful than other factors in early assessments.
CONCLUSIONS: The multimodal deep learning model for combining admission notes 
and clinical tabular data showed promising efficacy as a potentially novel 
method in evaluating the risk of mortality in patients with HF, providing more 
accurate and timely decision support.

©Zhenyue Gao, Xiaoli Liu, Yu Kang, Pan Hu, Xiu Zhang, Wei Yan, Muyang Yan, 
Pengming Yu, Qing Zhang, Wendong Xiao, Zhengbo Zhang. Originally published in 
the Journal of Medical Internet Research (https://www.jmir.org), 02.05.2024.

DOI: 10.2196/54363
PMCID: PMC11099809
PMID: 38696251 [Indexed for MEDLINE]

Conflict of interest statement: Conflicts of Interest: None declared.


9. Radiology. 2024 Oct;313(1):e232746. doi: 10.1148/radiol.232746.

Evaluating the Performance and Bias of Natural Language Processing Tools in 
Labeling Chest Radiograph Reports.

Santomartino SM(1), Zech JR(1), Hall K(1), Jeudy J(1), Parekh V(1), Yi PH(1).

Author information:
(1)From Drexel University College of Medicine, Philadelphia, Pa (S.M.S.); 
Department of Radiology, Columbia University Irving Medical Center, New York, NY 
(J.R.Z.); Department of Radiology, Wake Forest University Health Sciences 
Center, Winston-Salem, NC (K.H.); Department of Diagnostic Radiology and Nuclear 
Medicine, University of Maryland School of Medicine, Baltimore, Md (J.J., V.P.); 
and Department of Diagnostic Imaging, St. Jude Children's Research Hospital, 262 
Danny Thomas Plc, Memphis, TN 38105-3678 (P.H.Y.).

Background Natural language processing (NLP) is commonly used to annotate 
radiology datasets for training deep learning (DL) models. However, the accuracy 
and potential biases of these NLP methods have not been thoroughly investigated, 
particularly across different demographic groups. Purpose To evaluate the 
accuracy and demographic bias of four NLP radiology report labeling tools on two 
chest radiograph datasets. Materials and Methods This retrospective study, 
performed between April 2022 and April 2024, evaluated chest radiograph report 
labeling using four NLP tools (CheXpert [rule-based], RadReportAnnotator [RRA; 
DL-based], OpenAI's GPT-4 [DL-based], cTAKES [hybrid]) on a subset of the 
Medical Information Mart for Intensive Care (MIMIC) chest radiograph dataset 
balanced for representation of age, sex, and race and ethnicity (n = 692) and 
the entire Indiana University (IU) chest radiograph dataset (n = 3665). Three 
board-certified radiologists annotated the chest radiograph reports for 14 
thoracic disease labels. NLP tool performance was evaluated using several 
metrics, including accuracy and error rate. Bias was evaluated by comparing 
performance between demographic subgroups using the Pearson χ2 test. Results The 
IU dataset included 3665 patients (mean age, 49.7 years ± 17 [SD]; 1963 female), 
while the MIMIC dataset included 692 patients (mean age, 54.1 years ± 23.1; 357 
female). All four NLP tools demonstrated high accuracy across findings in the IU 
and MIMIC datasets, as follows: CheXpert (92.6% [47 516 of 51 310], 90.2% [8742 
of 9688]), RRA (82.9% [19 746 of 23 829], 92.2% [2870 of 3114]), GPT-4 (94.3% 
[45 586 of 48 342], 91.6% [6721 of 7336]), and cTAKES (84.7% [43 436 of 51 310], 
88.7% [8597 of 9688]). RRA and cTAKES had higher accuracy (P < .001) on the 
MIMIC dataset, while CheXpert and GPT-4 had higher accuracy on the IU dataset. 
Differences (P < .001) in error rates were observed across age groups for all 
NLP tools except RRA on the MIMIC dataset, with the highest error rates for 
CheXpert, RRA, and cTAKES in patients older than 80 years (mean, 15.8% ± 5.0) 
and the highest error rate for GPT-4 in patients 60-80 years of age (8.3%). 
Conclusion Although commonly used NLP tools for chest radiograph report 
annotation are accurate when evaluating reports in aggregate, demographic 
subanalyses showed significant bias, with poorer performance in older patients. 
© RSNA, 2024 Supplemental material is available for this article. See also the 
editorial by Cai in this issue.

DOI: 10.1148/radiol.232746
PMCID: PMC11535863
PMID: 39436298 [Indexed for MEDLINE]

Conflict of interest statement: Disclosures of conflicts of interest: S.M.S. No 
relevant relationships. J.R.Z. Grant from RSNA R&E Foundation; editorial board 
member, Radiology: Artificial Intelligence. K.H. No relevant relationships. J.J. 
No relevant relationships. V.P. No relevant relationships. P.H.Y. Grants or 
contracts from National Institutes of Health–National Cancer Institute, American 
College of Radiology (ACR), RSNA, Johns Hopkins University, and University of 
Maryland; meeting attendance support from Society for Imaging Informatics in 
Medicine (SIIM) and Society of Nuclear Medicine and Molecular Imaging; vice 
chair of Program Planning Committee, SIIM; Informatics Commission, ACR; stock or 
stock options in Bunkerhill Health; editorial board member, Radiology: 
Artificial Intelligence.


10. J Biomed Inform. 2024 Jun;154:104648. doi: 10.1016/j.jbi.2024.104648. Epub 2024 
Apr 30.

Forecasting acute kidney injury and resource utilization in ICU patients using 
longitudinal, multimodal models.

Tan Y(1), Dede M(1), Mohanty V(2), Dou J(2), Hill H(3), Bernstam E(4), Chen 
K(5).

Author information:
(1)Department of Bioinformatics and Computational Biology, The University of 
Texas MD Anderson Cancer Center, Houston, TX, United States. Electronic address: 
https://twitter.com/zhizhid.
(2)Department of Bioinformatics and Computational Biology, The University of 
Texas MD Anderson Cancer Center, Houston, TX, United States.
(3)Division of Pathology and Laboratory Medicine, Molecular Diagnostic 
Laboratory, The University of Texas MD Anderson Cancer Center, Houston, TX, 
United States.
(4)D. Bradley McWilliams School of Biomedical Informatics, The University of 
Texas Health Science Center at Houston, Houston, TX, United States; Division of 
General Internal Medicine, McGovern Medical School, The University of Texas 
Health Science Center at Houston, Houston, TX, United States.
(5)Department of Bioinformatics and Computational Biology, The University of 
Texas MD Anderson Cancer Center, Houston, TX, United States. Electronic address: 
KChen3@mdanderson.org.

Update of
    medRxiv. 2024 Mar 15:2024.03.14.24304230. doi: 10.1101/2024.03.14.24304230.

BACKGROUND: Advances in artificial intelligence (AI) have realized the potential 
of revolutionizing healthcare, such as predicting disease progression via 
longitudinal inspection of Electronic Health Records (EHRs) and lab tests from 
patients admitted to Intensive Care Units (ICU). Although substantial literature 
exists addressing broad subjects, including the prediction of mortality, 
length-of-stay, and readmission, studies focusing on forecasting Acute Kidney 
Injury (AKI), specifically dialysis anticipation like Continuous Renal 
Replacement Therapy (CRRT) are scarce. The technicality of how to implement AI 
remains elusive.
OBJECTIVE: This study aims to elucidate the important factors and methods that 
are required to develop effective predictive models of AKI and CRRT for patients 
admitted to ICU, using EHRs in the Medical Information Mart for Intensive Care 
(MIMIC) database.
METHODS: We conducted a comprehensive comparative analysis of established 
predictive models, considering both time-series measurements and clinical notes 
from MIMIC-IV databases. Subsequently, we proposed a novel multi-modal model 
which integrates embeddings of top-performing unimodal models, including Long 
Short-Term Memory (LSTM) and BioMedBERT, and leverages both unstructured 
clinical notes and structured time series measurements derived from EHRs to 
enable the early prediction of AKI and CRRT.
RESULTS: Our multimodal model achieved a lead time of at least 12 h ahead of 
clinical manifestation, with an Area Under the Receiver Operating Characteristic 
Curve (AUROC) of 0.888 for AKI and 0.997 for CRRT, as well as an Area Under the 
Precision Recall Curve (AUPRC) of 0.727 for AKI and 0.840 for CRRT, 
respectively, which significantly outperformed the baseline models. 
Additionally, we performed a SHapley Additive exPlanation (SHAP) analysis using 
the expected gradients algorithm, which highlighted important, previously 
underappreciated predictive features for AKI and CRRT.
CONCLUSION: Our study revealed the importance and the technicality of applying 
longitudinal, multimodal modeling to improve early prediction of AKI and CRRT, 
offering insights for timely interventions. The performance and interpretability 
of our model indicate its potential for further assessment towards clinical 
applications, to ultimately optimize AKI management and enhance patient 
outcomes.

Copyright © 2024 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jbi.2024.104648
PMID: 38692464 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest The authors 
declare that they have no known competing financial interests or personal 
relationships that could have appeared to influence the work reported in this 
paper.


11. J Am Med Inform Assoc. 2023 Jul 19;30(8):1448-1455. doi: 10.1093/jamia/ocad071.

Extracting social determinants of health from clinical note text with 
classification and sequence-to-sequence approaches.

Romanowski B(1), Ben Abacha A(2), Fan Y(1).

Author information:
(1)Nuance Communications, Burlington, Massachusetts, USA.
(2)Microsoft, Redmond, Washington, USA.

OBJECTIVE: Social determinants of health (SDOH) are nonmedical factors that can 
influence health outcomes. This paper seeks to extract SDOH from clinical texts 
in the context of the National NLP Clinical Challenges (n2c2) 2022 Track 2 Task.
MATERIALS AND METHODS: Annotated and unannotated data from the Medical 
Information Mart for Intensive Care III (MIMIC-III) corpus, the Social History 
Annotation Corpus, and an in-house corpus were used to develop 2 deep learning 
models that used classification and sequence-to-sequence (seq2seq) approaches.
RESULTS: The seq2seq approach had the highest overall F1 scores in the 
challenge's 3 subtasks: 0.901 on the extraction subtask, 0.774 on the 
generalizability subtask, and 0.889 on the learning transfer subtask.
DISCUSSION: Both approaches rely on SDOH event representations that were 
designed to be compatible with transformer-based pretrained models, with the 
seq2seq representation supporting an arbitrary number of overlapping and 
sentence-spanning events. Models with adequate performance could be produced 
quickly, and the remaining mismatch between representation and task requirements 
was then addressed in postprocessing. The classification approach used rules to 
generate entity relationships from its sequence of token labels, while the 
seq2seq approach used constrained decoding and a constraint solver to recover 
entity text spans from its sequence of potentially ambiguous tokens.
CONCLUSION: We proposed 2 different approaches to extract SDOH from clinical 
texts with high accuracy. However, accuracy suffers on text from new healthcare 
institutions not present in the training data, and thus generalization remains 
an important topic for future study.

© The Author(s) 2023. Published by Oxford University Press on behalf of the 
American Medical Informatics Association. All rights reserved. For permissions, 
please email: journals.permissions@oup.com.

DOI: 10.1093/jamia/ocad071
PMCID: PMC10354779
PMID: 37100768 [Indexed for MEDLINE]

Conflict of interest statement: None declared.


12. Comput Inform Nurs. 2024 Mar 1;42(3):184-192. doi: 10.1097/CIN.0000000000001053.

Evaluating Natural Language Processing Packages for Predicting Hospital-Acquired 
Pressure Injuries From Clinical Notes.

Gu S(1), Lee EW, Zhang W, Simpson RL, Hertzberg VS, Ho JC.

Author information:
(1)Author Affiliations: Department of Computer Science, Center for Data Science 
(Ms Gu, Mr Lee, and Dr Ho), and Nell Hodgson Woodruff School of Nursing (Drs 
Zhang, Simpson, and Hertzberg), Emory University, Atlanta, GA.

Incidence of hospital-acquired pressure injury, a key indicator of nursing 
quality, is directly proportional to adverse outcomes, increased hospital stays, 
and economic burdens on patients, caregivers, and society. Thus, predicting 
hospital-acquired pressure injury is important. Prediction models use structured 
data more often than unstructured notes, although the latter often contain 
useful patient information. We hypothesize that unstructured notes, such as 
nursing notes, can predict hospital-acquired pressure injury. We evaluate the 
impact of using various natural language processing packages to identify salient 
patient information from unstructured text. We use named entity recognition to 
identify keywords, which comprise the feature space of our classifier for 
hospital-acquired pressure injury prediction. We compare scispaCy and Stanza, 
two different named entity recognition models, using unstructured notes in 
Medical Information Mart for Intensive Care III, a publicly available ICU data 
set. To assess the impact of vocabulary size reduction, we compare the use of 
all clinical notes with only nursing notes. Our results suggest that named 
entity recognition extraction using nursing notes can yield accurate models. 
Moreover, the extracted keywords play a significant role in the prediction of 
hospital-acquired pressure injury.

Copyright © 2023 The Authors. Published by Wolters Kluwer Health, Inc.

DOI: 10.1097/CIN.0000000000001053
PMCID: PMC10884344
PMID: 37607706 [Indexed for MEDLINE]


13. Int J Med Inform. 2025 Mar;195:105800. doi: 10.1016/j.ijmedinf.2025.105800. Epub 
2025 Jan 21.

Large language models vs human for classifying clinical documents.

Mustafa A(1), Naseem U(2), Rahimi Azghadi M(3).

Author information:
(1)College of Science and Engineering, James Cook University, Townsville, 4811, 
QLD, Australia. Electronic address: akram.mohdmustafa@my.jcu.edu.au.
(2)School of Computing, Macquarie University, Sydney, 2113, NSW, Australia. 
Electronic address: usman.naseem@mq.edu.au.
(3)College of Science and Engineering, James Cook University, Townsville, 4811, 
QLD, Australia. Electronic address: mostafa.rahimiazghadi@jcu.edu.au.

BACKGROUND: Accurate classification of medical records is crucial for clinical 
documentation, particularly when using the 10th revision of the International 
Classification of Diseases (ICD-10) coding system. The use of machine learning 
algorithms and Systematized Nomenclature of Medicine (SNOMED) mapping has shown 
promise in performing these classifications. However, challenges remain, 
particularly in reducing false negatives, where certain diagnoses are not 
correctly identified by either approach.
OBJECTIVE: This study explores the potential of leveraging advanced large 
language models to improve the accuracy of ICD-10 classifications in challenging 
cases of medical records where machine learning and SNOMED mapping fail.
METHODS: We evaluated the performance of ChatGPT 3.5 and ChatGPT 4 in 
classifying ICD-10 codes from discharge summaries within selected records of the 
Medical Information Mart for Intensive Care (MIMIC) IV dataset. These records 
comprised 802 discharge summaries identified as false negatives by both machine 
learning and SNOMED mapping methods, showing their challenging case. Each 
summary was assessed by ChatGPT 3.5 and 4 using a classification prompt, and the 
results were compared to human coder evaluations. Five human coders, with a 
combined experience of over 30 years, independently classified a stratified 
sample of 100 summaries to validate ChatGPT's performance.
RESULTS: ChatGPT 4 demonstrated significantly improved consistency over ChatGPT 
3.5, with matching results between runs ranging from 86% to 89%, compared to 57% 
to 67% for ChatGPT 3.5. The classification accuracy of ChatGPT 4 was variable 
across different ICD-10 codes. Overall, human coders performed better than 
ChatGPT. However, ChatGPT matched the median performance of human coders, 
achieving an accuracy rate of 22%.
CONCLUSION: This study underscores the potential of integrating advanced 
language models with clinical coding processes to improve documentation 
accuracy. ChatGPT 4 demonstrated improved consistency and comparable performance 
to median human coders, achieving 22% accuracy in challenging cases. Combining 
ChatGPT with methods like SNOMED mapping could further enhance clinical coding 
accuracy, particularly for complex scenarios.

Copyright © 2025 The Authors. Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.ijmedinf.2025.105800
PMID: 39848078 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare that they have no known competing financial interests or personal 
relationships that could have appeared to influence the work reported in this 
paper.


14. Dimens Crit Care Nurs. 2023 Nov-Dec 01;42(6):310-318. doi: 
10.1097/DCC.0000000000000606.

Anticholinergic Burden and Xerostomia in Critical Care Settings.

Chung J, Tjia J, Zhang N, O'Connor BT.

BACKGROUND: Although previous studies have established the association of 
medications with anticholinergic adverse effects and xerostomia, anticholinergic 
burden and xerostomia in critical care settings are poorly characterized. The 
objective of this study was to determine the impact of medication burdens 
associated with anticholinergic adverse effects, particularly the occurrence of 
xerostomia (dry mouth) in a critical care setting. In addition, this study 
explored the correlation between the timing of the first instance of xerostomia 
and the administration timing of medication known to have anticholinergic 
adverse effects.
METHODS: A retrospective case-control study was used with the MIMIC (Medical 
Information Mart for Intensive Care) III database. The MIMIC-III clinical 
database is a publicly available, deidentified, health-related database with 
more than 40 000 patients in critical care units from 2001 to 2012. Cases of 
xerostomia (n = 1344) were selected from clinical notes reporting "dry mouth," 
"xerostomia," or evidence of pharmacological treatment for xerostomia; control 
(n = 4032) was selected using the propensity analysis with 1:3 matching on 
covariates (eg, age, sex, race, ethnicity, and length of stay). The 
anticholinergic burden was quantified as the cumulative effect of 
anticholinergic activities using the Anticholinergic Burden Scale.
RESULTS: Anticholinergic burden significantly differed between xerostomia 
patients and control subjects (P = .04). The length of stay was a statistically 
significant factor in xerostomia. The probability of developing the symptom of 
xerostomia within 24 hours was .95 (95%) for patients of xerostomia.
CONCLUSIONS: Anticholinergic Burden Scale is associated with xerostomia in the 
critical care setting, particularly within 24 hours after admission. It is 
crucial to carefully evaluate alternative options for medications that may have 
potential anticholinergic adverse effects. This evaluation should include 
assessing the balance between the benefits and harms, considering the 
probability of withdrawal reactions, and prioritizing deprescribing whenever 
feasible within the initial 24-hour period.

Copyright © 2023 Wolters Kluwer Health, Inc. All rights reserved.

DOI: 10.1097/DCC.0000000000000606
PMID: 37756502 [Indexed for MEDLINE]


15. BMC Med Inform Decis Mak. 2022 Apr 29;22(1):114. doi: 
10.1186/s12911-022-01850-5.

Improving medical term embeddings using UMLS Metathesaurus.

Chanda AK(1), Bai T(1), Yang Z(1), Vucetic S(2).

Author information:
(1)Department of Computer and Information Sciences, Temple University, 
Philadelphia, PA, USA.
(2)Department of Computer and Information Sciences, Temple University, 
Philadelphia, PA, USA. vucetic@temple.edu.

BACKGROUND: Health providers create Electronic Health Records (EHRs) to describe 
the conditions and procedures used to treat their patients. Medical notes 
entered by medical staff in the form of free text are a particularly insightful 
component of EHRs. There is a great interest in applying machine learning tools 
on medical notes in numerous medical informatics applications. Learning vector 
representations, or embeddings, of terms in the notes, is an important 
pre-processing step in such applications. However, learning good embeddings is 
challenging because medical notes are rich in specialized terminology, and the 
number of available EHRs in practical applications is often very small.
METHODS: In this paper, we propose a novel algorithm to learn embeddings of 
medical terms from a limited set of medical notes. The algorithm, called 
definition2vec, exploits external information in the form of medical term 
definitions. It is an extension of a skip-gram algorithm that incorporates 
textual definitions of medical terms provided by the Unified Medical Language 
System (UMLS) Metathesaurus.
RESULTS: To evaluate the proposed approach, we used a publicly available Medical 
Information Mart for Intensive Care (MIMIC-III) EHR data set. We performed 
quantitative and qualitative experiments to measure the usefulness of the 
learned embeddings. The experimental results show that definition2vec keeps the 
semantically similar medical terms together in the embedding vector space even 
when they are rare or unobserved in the corpus. We also demonstrate that learned 
vector embeddings are helpful in downstream medical informatics applications.
CONCLUSION: This paper shows that medical term definitions can be helpful when 
learning embeddings of rare or previously unseen medical terms from a small 
corpus of specialized documents such as medical notes.

© 2022. The Author(s).

DOI: 10.1186/s12911-022-01850-5
PMCID: PMC9052653
PMID: 35488252 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare that they have no competing 
interests.


16. JAMA Netw Open. 2018 Oct 5;1(6):e183451. doi: 10.1001/jamanetworkopen.2018.3451.

Comparison of 2 Natural Language Processing Methods for Identification of 
Bleeding Among Critically Ill Patients.

Taggart M(1), Chapman WW(1), Steinberg BA(2), Ruckel S(3), Pregenzer-Wenzler 
A(3), Du Y(1), Ferraro J(1), Bucher BT(4), Lloyd-Jones DM(5), Rondina 
MT(3)(6)(7), Shah RU(2).

Author information:
(1)Department of Biomedical Informatics, University of Utah School of Medicine, 
Salt Lake City.
(2)Division of Cardiovascular Medicine, University of Utah School of Medicine, 
Salt Lake City.
(3)Department of Internal Medicine, University of Utah School of Medicine, Salt 
Lake City.
(4)Division of Pediatric Surgery, University of Utah School of Medicine, Salt 
Lake City.
(5)Department of Preventive Medicine, Northwestern University Feinberg School of 
Medicine, Chicago, Illinois.
(6)George E. Wahlen Veterans Affairs Medical Center Geriatric Research Education 
and Clinical Center, Salt Lake City, Utah.
(7)Molecular Medicine Program, University of Utah School of Medicine, Salt Lake 
City.

IMPORTANCE: To improve patient safety, health care systems need reliable methods 
to detect adverse events in large patient populations. Events are often 
described in clinical notes, rather than structured data, which make them 
difficult to identify on a large scale.
OBJECTIVE: To develop and compare 2 natural language processing methods, a 
rules-based approach and a machine learning (ML) approach, for identifying 
bleeding events in clinical notes.
DESIGN, SETTING, AND PARTICIPANTS: This diagnostic study used deidentified notes 
from the Medical Information Mart for Intensive Care, which spans 2001 to 2012. 
A training set of 990 notes and a test set of 660 notes were randomly selected. 
Physicians classified each note as present or absent for a clinically relevant 
bleeding event during the hospitalization. A bleeding dictionary was developed 
for the rules-based approach; bleeding mentions were then aggregated to arrive 
at a classification for each note. Three ML models (support vector machine, 
extra trees, and convolutional neural network) were developed and trained using 
the 990-note training set. Another instance of each ML model was also trained on 
a sample of 450 notes, with equal numbers of bleeding-present and 
bleeding-absent notes. The notes were represented using term frequency-inverse 
document frequency vectors and global vectors for word representation.
MAIN OUTCOMES AND MEASURES: The main outcomes were accuracy, sensitivity, 
specificity, positive predictive value, and negative predictive value for each 
model. Following training, the models were tested on the test set and 
sensitivities were compared using a McNemar test.
RESULTS: The 990-note training set represented 769 patients (296 [38.5%] female; 
mean [SD] age, 67.42 [14.7] years). The 660-note test set represented 527 
patients (211 [40.0%] female; mean [SD] age, 67.86 [14.7] years). Bleeding was 
present in 146 notes (22.1%). The extra trees down-sampled model and rules-based 
approaches were similarly sensitive (93.8% vs 91.1%; difference, 2.7%; 95% CI, 
-3.8% to 7.9%; P = .44). The positive predictive value for the extra trees 
model, however, was 48.6%. The rules-based model had the best performance 
overall, with 84.6% specificity, 62.7% positive predictive value, and 97.1% 
negative predictive value.
CONCLUSIONS AND RELEVANCE: Bleeding is a common complication in health care, and 
these results demonstrate an automated and scalable detection method. The 
rules-based natural language processing approach, compared with ML, had the best 
performance in identifying bleeding, with high sensitivity and negative 
predictive value.

DOI: 10.1001/jamanetworkopen.2018.3451
PMCID: PMC6324448
PMID: 30646240 [Indexed for MEDLINE]

Conflict of interest statement: Conflict of Interest Disclosures: Mr Taggart 
reported employment as an intern at Health Catalyst outside the submitted work. 
Dr Chapman reported personal fees from IBM outside the submitted work. Dr 
Steinberg reported grants from Boston Scientific and grants, personal fees, and 
research support from Janssen outside the submitted work. Dr Ferraro reported 
personal fees from Intermountain Healthcare and the University of Utah outside 
the submitted work. Dr Bucher reported grants from the Agency for Healthcare 
Research and Quality outside the submitted work. No other disclosures were 
reported.


17. J Med Internet Res. 2024 May 31;26:e56614. doi: 10.2196/56614.

Redefining Health Care Data Interoperability: Empirical Exploration of Large 
Language Models in Information Exchange.

Yoon D(1)(2)(3), Han C(1), Kim DW(1), Kim S(1), Bae S(3)(4), Ryu JA(1), Choi 
Y(1).

Author information:
(1)Department of Biomedical Systems Informatics, Yonsei University College of 
Medicine, Seoul, Republic of Korea.
(2)Institute for Innovation in Digital Healthcare (IIDH), Severance Hospital, 
Seoul, Republic of Korea.
(3)Center for Digital Health, Yongin Severance Hospital, Yonsei University 
Health System, Yongin, Republic of Korea.
(4)Department of Cardiology, Yongin Severance Hospital, Yonsei University 
College of Medicine, Yongin, Republic of Korea.

BACKGROUND: Efficient data exchange and health care interoperability are impeded 
by medical records often being in nonstandardized or unstructured natural 
language format. Advanced language models, such as large language models (LLMs), 
may help overcome current challenges in information exchange.
OBJECTIVE: This study aims to evaluate the capability of LLMs in transforming 
and transferring health care data to support interoperability.
METHODS: Using data from the Medical Information Mart for Intensive Care III and 
UK Biobank, the study conducted 3 experiments. Experiment 1 assessed the 
accuracy of transforming structured laboratory results into unstructured format. 
Experiment 2 explored the conversion of diagnostic codes between the coding 
frameworks of the ICD-9-CM (International Classification of Diseases, Ninth 
Revision, Clinical Modification), and Systematized Nomenclature of Medicine 
Clinical Terms (SNOMED-CT) using a traditional mapping table and a text-based 
approach facilitated by the LLM ChatGPT. Experiment 3 focused on extracting 
targeted information from unstructured records that included comprehensive 
clinical information (discharge notes).
RESULTS: The text-based approach showed a high conversion accuracy in 
transforming laboratory results (experiment 1) and an enhanced consistency in 
diagnostic code conversion, particularly for frequently used diagnostic names, 
compared with the traditional mapping approach (experiment 2). In experiment 3, 
the LLM showed a positive predictive value of 87.2% in extracting generic drug 
names.
CONCLUSIONS: This study highlighted the potential role of LLMs in significantly 
improving health care data interoperability, demonstrated by their high accuracy 
and efficiency in data transformation and exchange. The LLMs hold vast potential 
for enhancing medical data exchange without complex standardization for medical 
terms and data structure.

©Dukyong Yoon, Changho Han, Dong Won Kim, Songsoo Kim, SungA Bae, Jee An Ryu, 
Yujin Choi. Originally published in the Journal of Medical Internet Research 
(https://www.jmir.org), 31.05.2024.

DOI: 10.2196/56614
PMCID: PMC11179014
PMID: 38819879 [Indexed for MEDLINE]

Conflict of interest statement: Conflicts of Interest: None declared.


18. Stud Health Technol Inform. 2024 Nov 22;321:94-98. doi: 10.3233/SHTI241070.

Utilizing RAG and GPT-4 for Extraction of Substance Use Information from 
Clinical Notes.

Shah-Mohammadi F(1), Finkelstein J(1).

Author information:
(1)Department of Biomedical Informatics, School of Medicine, University of Utah, 
USA.

This research investigates the application of a hybrid Retrieval-Augmented 
Generation (RAG) and Generative Pre-trained Transformer (GPT) pipeline for 
extracting and categorizing substance use information from unstructured clinical 
notes. The aim is to enhance the accuracy and efficiency of identifying 
substance use mentions and determining their status in patient documentation. By 
integrating RAG to pre-filter and focus the input for GPT, the pipeline 
strategically narrows the scope of analysis to the most relevant text segments, 
thereby improving the precision and recall of the extraction. Utilizing the 
Medical Information Mart for Intensive Care III dataset, the performance of the 
pipeline was evaluated through manual verification, assessing various metrics 
including recall, precision, F1-score, and accuracy. The results demonstrated 
high precision rates (up to 0.99 for drug and alcohol mentions), and substantial 
recall (0.88 across all substances for status of the usage).

DOI: 10.3233/SHTI241070
PMID: 39575787 [Indexed for MEDLINE]


19. AMIA Annu Symp Proc. 2022 Feb 21;2021:418-427. eCollection 2021.

Clinical Note Section Detection Using a Hidden Markov Model of Unified Medical 
Language System Semantic Types.

Eisman AS(1)(2), Brown KA(1), Chen ES(1)(2)(3), Sarkar IN(1)(2)(3)(4).

Author information:
(1)Center for Biomedical Informatics, Brown University, Providence RI.
(2)The Warren Alpert Medical School, Brown University, Providence, RI.
(3)School of Public Health, Brown University, Providence, RI.
(4)Rhode Island Quality Institute, Providence, RI.

Clinical notes are a rich source of biomedical data for natural language 
processing (NLP). The identification of note sections represents a first step in 
creating portable NLP tools. Here, a system that used a heterogeneous hidden 
Markov model (HMM) was designed to identify seven note sections: (1) Medical 
History, (2) Medications, (3) Family and Social History, (4) Physical Exam, (5) 
Labs and Imaging, (6) Assessment and Plan, and (7) Review of Systems. Unified 
Medical Language System (UMLS) concepts were identified using MetaMap, and UMLS 
semantic type distributions for each section type were empirically determined. 
The UMLS semantic type distributions were used to train the HMM for identifying 
clinical note sections. The system was evaluated relative to a template boundary 
model using manually annotated notes from the Medical Information Mart for 
Intensive Care III. The results show promise for an approach to segment clinical 
notes into sections for subsequent NLP tasks.

©2021 AMIA - All rights reserved.

PMCID: PMC8861726
PMID: 35308919 [Indexed for MEDLINE]


20. J Am Med Inform Assoc. 2023 Feb 16;30(3):438-446. doi: 10.1093/jamia/ocac230.

Learning from undercoded clinical records for automated International 
Classification of Diseases (ICD) coding.

Jin Y(1), Xiong Y(1)(2), Shi D(3), Lin Y(4)(5), He L(6), Zhang Y(1), Plasek 
JM(7), Zhou L(7), Bates DW(7), Tang C(7).

Author information:
(1)Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan 
University, Shanghai, China.
(2)Peng Cheng Laboratory, Shenzhen, China.
(3)Department of Geriatrics, Yueyang Hospital of Integrated Traditional Chinese 
Medicine and Western Medicine, Shanghai University of Traditional Chinese 
Medicine, Shanghai, China.
(4)Medical Device Regulatory Research Center/Precision Medicine Research Center, 
West China Hospital of Sichuan University, Sichuan, China.
(5)Department of Epidemiology, Harvard T.H. Chan School of Public Health, 
Boston, Massachusetts, USA.
(6)Department of Computer Science and Engineering, Lehigh University, Bethlehem, 
Pennsylvania, USA.
(7)Division of General Internal Medicine and Primary Care, Department of 
Medicine, Brigham and Women's Hospital, Harvard Medical School, Boston, 
Massachusetts, USA.

OBJECTIVES: To develop an unbiased objective for learning automatic coding 
algorithms from clinical records annotated with only partial relevant 
International Classification of Diseases codes, as annotation noise in 
undercoded clinical records used as training data can mislead the learning 
process of deep neural networks.
MATERIALS AND METHODS: We use Medical Information Mart for Intensive Care III as 
our dataset. We employ positive-unlabeled learning to achieve unbiased loss 
estimation, which is free of misleading training signal. We then utilize 
reweighting mechanism to compensate for the imbalance between positive and 
negative samples. To further close the performance gap caused by poor quality 
annotation, we integrate the supervision provided by the automatic annotation 
tool Medical Concept Annotation Toolkit which can ease the heavy burden of 
manual validation.
RESULTS: Our benchmarking results show that positive-unlabeled learning with 
reweighting outperforms competitive baseline methods over a range of missing 
label ratios. Integrating supervision provided by annotation tool further 
boosted the performance.
DISCUSSION: Considering the annotation noise and severe imbalance, unbiased loss 
estimation and reweighting mechanism are both important for learning from 
undercoded clinical records. Unbiased loss requires the estimation of false 
negative ratios and estimation through trained models is practical and 
competitive.
CONCLUSIONS: The combination of positive-unlabeled learning with reweighting and 
supervision provided by the annotation tool is a promising solution to learn 
from undercoded clinical records.

© The Author(s) 2022. Published by Oxford University Press on behalf of the 
American Medical Informatics Association. All rights reserved. For permissions, 
please email: journals.permissions@oup.com.

DOI: 10.1093/jamia/ocac230
PMCID: PMC9933053
PMID: 36478240 [Indexed for MEDLINE]


21. J Intensive Care Med. 2023 Jul;38(7):630-634. doi: 10.1177/08850666231155397. 
Epub 2023 Feb 5.

Racial Disparities in Documented Chief Complaints and Diagnoses in Sepsis 
Patients.

Liu H(1), McCroskery S(1), Rajasekaran V(1), Linker AS(2), Poeran J(3), Truong 
TT(2).

Author information:
(1)Icahn School of Medicine at Mount Sinai, New York, NY, USA.
(2)Division of Hospital Medicine, Icahn School of Medicine at Mount Sinai, New 
York, NY, USA.
(3)Department of Orthopedic Surgery/Institute for Healthcare Delivery Science, 
Department of Population Health Science & Policy/Department of Medicine, Icahn 
School of Medicine at Mount Sinai, New York, NY, USA.

BACKGROUND: Using History and Physical Examination (H&P) notes, we investigated 
potential racial differences in documented chief complaints and problems among 
sepsis patients admitted to the intensive care unit.
METHODS: Patient records from Medical Information Mart for Intensive Care 
(MIMIC-III) dataset indicating a diagnosis of sepsis were included. First 
recorded clinical notes for each hospital admission were assessed; free text 
information was specifically extracted on (1) chief complaints, and (2) problems 
recorded in the Assessment & Plan (A&P) section. The top 10 for each were 
compared between Black and White patients.
RESULTS: In initial H&P notes of 17 434 sepsis patients (n = 1229 Black and 
n = 9806 White), the top 10 most common chief complaints were somewhat similar 
between Black and White patients. However, relative differences existed in terms 
of ranking, specifically for altered mental status which was more commonly 
reported in Black versus White patients (11.7% vs 7.8% P < .001). Among text in 
the A&P, sepsis was documented significantly less frequently among Black versus 
White patients: 11.8% versus 14.3%, P = .001. Racial differences were not 
detected in vital signs and laboratory values.
CONCLUSIONS: This analysis supports the hypothesis that there may be racial 
differences in early sepsis presentation and possible provider interpretation of 
these complaints.

DOI: 10.1177/08850666231155397
PMID: 36740933 [Indexed for MEDLINE]


22. IEEE J Biomed Health Inform. 2020 May;24(5):1469-1476. doi: 
10.1109/JBHI.2019.2949567. Epub 2019 Oct 25.

Leveraging Semantics in WordNet to Facilitate the Computer-Assisted Coding of 
ICD-11.

Chen D, Zhang R, Qiu RG.

The International Classification of Diseases (ICD) not only serves as the 
bedrock for health statistics but also provides a holistic overview of every 
health aspect of life. This study aims to facilitate the computer-assisted 
coding of the 11th revision of the ICD (ICD-11) by leveraging the data 
structures of ICD-11 and semantics in WordNet. First, a computer-assisted coding 
framework using WordNet and ICD-11 application programming interface (API) is 
proposed. Secondly, a network based on entity relations in ICD-11 and synonym 
sets in WordNet, called CodeNet, is developed. Thirdly, an algorithm for 
generating ICD-11 code candidates from CodeNet with two tuning parameters on the 
basis of the input of disease-related text is illustrated. Finally, the 
discharge summaries in the Medical Information Mart for Intensive Care III 
database and textual information from ICD-11 entities are used to evaluate the 
proposed method. Experimental results indicate that the proposed coding method 
achieves a precision of 84% and a recall of 89% relative to a precision of 65% 
and a recall of 81% achieved with the existing ICD-11 API. The proposed method 
also outperforms other methods in the literature by reducing a failure rate of 
up to 8% in ICD-11 coding. The proposed thresholds of similarity and percentage 
can be applied to tuning the performance of our method to meet different coding 
needs. In sum, improving the new structures of ICD-11 with the use of semantics 
in WordNet can help develop more reliable computer-aided coding systems for 
ICD-11 coders.

DOI: 10.1109/JBHI.2019.2949567
PMID: 31670684 [Indexed for MEDLINE]


23. Proc Natl Acad Sci U S A. 2024 Sep 24;121(39):e2320716121. doi: 
10.1073/pnas.2320716121. Epub 2024 Sep 16.

On the development and validation of large language model-based classifiers for 
identifying social determinants of health.

Gabriel RA(1)(2), Litake O(1), Simpson S(1), Burton BN(3), Waterman RS(1), 
Macias AA(1).

Author information:
(1)Division of Perioperative Informatics, Department of Anesthesiology, 
University of California, San Diego, La Jolla, CA 92037.
(2)Department of Biomedical Informatics, University of California, San Diego 
Health, La Jolla, CA 92037.
(3)Department of Anesthesiology, University of California, Los Angeles, CA 
90095.

The assessment of social determinants of health (SDoH) within healthcare systems 
is crucial for comprehensive patient care and addressing health disparities. 
Current challenges arise from the limited inclusion of structured SDoH 
information within electronic health record (EHR) systems, often due to the lack 
of standardized diagnosis codes. This study delves into the transformative 
potential of large language models (LLM) to overcome these challenges. LLM-based 
classifiers-using Bidirectional Encoder Representations from Transformers (BERT) 
and A Robustly Optimized BERT Pretraining Approach (RoBERTa)-were developed for 
SDoH concepts, including homelessness, food insecurity, and domestic violence, 
using synthetic training datasets generated by generative pre-trained 
transformers combined with authentic clinical notes. Models were then validated 
on separate datasets: Medical Information Mart for Intensive Care-III and our 
institutional EHR data. When training the model with a combination of synthetic 
and authentic notes, validation on our institutional dataset yielded an area 
under the receiver operating characteristics curve of 0.78 for detecting 
homelessness, 0.72 for detecting food insecurity, and 0.83 for detecting 
domestic violence. This study underscores the potential of LLMs in extracting 
SDoH information from clinical text. Automated detection of SDoH may be 
instrumental for healthcare providers in identifying at-risk patients, guiding 
targeted interventions, and contributing to population health initiatives aimed 
at mitigating disparities.

DOI: 10.1073/pnas.2320716121
PMCID: PMC11441499
PMID: 39284061 [Indexed for MEDLINE]

Conflict of interest statement: Competing interests statement:The authors 
declare no competing interest.


24. JMIR Med Inform. 2023 Nov 27;11:e49886. doi: 10.2196/49886.

A Large Language Model Screening Tool to Target Patients for Best Practice 
Alerts: Development and Validation.

Savage T(1), Wang J(2), Shieh L(1).

Author information:
(1)Division of Hospital Medicine, Department of Medicine, Stanford University, 
Palo Alto, CA, United States.
(2)Divison of Gastroenterology and Hepatology, Department of Medicine, Stanford 
University, Palo Alto, CA, United States.

BACKGROUND: Best Practice Alerts (BPAs) are alert messages to physicians in the 
electronic health record that are used to encourage appropriate use of health 
care resources. While these alerts are helpful in both improving care and 
reducing costs, BPAs are often broadly applied nonselectively across entire 
patient populations. The development of large language models (LLMs) provides an 
opportunity to selectively identify patients for BPAs.
OBJECTIVE: In this paper, we present an example case where an LLM screening tool 
is used to select patients appropriate for a BPA encouraging the prescription of 
deep vein thrombosis (DVT) anticoagulation prophylaxis. The artificial 
intelligence (AI) screening tool was developed to identify patients experiencing 
acute bleeding and exclude them from receiving a DVT prophylaxis BPA.
METHODS: Our AI screening tool used a BioMed-RoBERTa (Robustly Optimized 
Bidirectional Encoder Representations from Transformers Pretraining Approach; 
AllenAI) model to perform classification of physician notes, identifying 
patients without active bleeding and thus appropriate for a thromboembolism 
prophylaxis BPA. The BioMed-RoBERTa model was fine-tuned using 500 history and 
physical notes of patients from the MIMIC-III (Medical Information Mart for 
Intensive Care) database who were not prescribed anticoagulation. A development 
set of 300 MIMIC patient notes was used to determine the model's 
hyperparameters, and a separate test set of 300 patient notes was used to 
evaluate the screening tool.
RESULTS: Our MIMIC-III test set population of 300 patients included 72 patients 
with bleeding (ie, were not appropriate for a DVT prophylaxis BPA) and 228 
without bleeding who were appropriate for a DVT prophylaxis BPA. The AI 
screening tool achieved impressive accuracy with a precision-recall area under 
the curve of 0.82 (95% CI 0.75-0.89) and a receiver operator curve area under 
the curve of 0.89 (95% CI 0.84-0.94). The screening tool reduced the number of 
patients who would trigger an alert by 20% (240 instead of 300 alerts) and 
increased alert applicability by 14.8% (218 [90.8%] positive alerts from 240 
total alerts instead of 228 [76%] positive alerts from 300 total alerts), 
compared to nonselectively sending alerts for all patients.
CONCLUSIONS: These results show a proof of concept on how language models can be 
used as a screening tool for BPAs. We provide an example AI screening tool that 
uses a HIPAA (Health Insurance Portability and Accountability Act)-compliant 
BioMed-RoBERTa model deployed with minimal computing power. Larger models (eg, 
Generative Pre-trained Transformers-3, Generative Pre-trained Transformers-4, 
and Pathways Language Model) will exhibit superior performance but require data 
use agreements to be HIPAA compliant. We anticipate LLMs to revolutionize 
quality improvement in hospital medicine.

©Thomas Savage, John Wang, Lisa Shieh. Originally published in JMIR Medical 
Informatics (https://medinform.jmir.org), 27.11.2023.

DOI: 10.2196/49886
PMCID: PMC10714262
PMID: 38010803

Conflict of interest statement: Conflicts of Interest: None declared.


25. medRxiv [Preprint]. 2024 Mar 11:2024.03.08.24304011. doi: 
10.1101/2024.03.08.24304011.

Automated Extraction of Stroke Severity from Unstructured Electronic Health 
Records using Natural Language Processing.

Fernandes M(1), Westover MB(2), Singhal AB(1), Zafar SF(1).

Author information:
(1)Department of Neurology, Massachusetts General Hospital (MGH), Boston, 
Massachusetts, United States.
(2)Department of Neurology, Beth Israel Deaconess Medical Center (BIDMC), 
Boston, Massachusetts, United States.

Update in
    J Am Heart Assoc. 2024 Nov 5;13(21):e036386. doi: 10.1161/JAHA.124.036386.

BACKGROUND: Multi-center electronic health records (EHR) can support quality 
improvement initiatives and comparative effectiveness research in stroke care. 
However, limitations of EHR-based research include challenges in abstracting key 
clinical variables from non-structured data at scale. This is further compounded 
by missing data. Here we develop a natural language processing (NLP) model that 
automatically reads EHR notes to determine the NIH stroke scale (NIHSS) score of 
patients with acute stroke.
METHODS: The study included notes from acute stroke patients (>= 18 years) 
admitted to the Massachusetts General Hospital (MGH) (2015-2022). The MGH data 
were divided into training (70%) and hold-out test (30%) sets. A two-stage model 
was developed to predict the admission NIHSS. A linear model with the least 
absolute shrinkage and selection operator (LASSO) was trained within the 
training set. For notes in the test set where the NIHSS was documented, the 
scores were extracted using regular expressions (stage 1), for notes where NIHSS 
was not documented, LASSO was used for prediction (stage 2). The reference 
standard for NIHSS was obtained from Get With The Guidelines Stroke Registry. 
The two-stage model was tested on the hold-out test set and validated in the 
MIMIC-III dataset (Medical Information Mart for Intensive Care-MIMIC III 
2001-2012) v1.4, using root mean squared error (RMSE) and Spearman correlation 
(SC).
RESULTS: We included 4,163 patients (MGH = 3,876; MIMIC = 287); average age of 
69 [SD 15] years; 53% male, and 72% white. 90% patients had ischemic stroke and 
10% hemorrhagic stroke. The two-stage model achieved a RMSE [95% CI] of 3.13 
[2.86-3.41] (SC = 0.90 [0.88-0. 91]) in the MGH hold-out test set and 2.01 
[1.58-2.38] (SC = 0.96 [0.94-0.97]) in the MIMIC validation set.
CONCLUSIONS: The automatic NLP-based model can enable large-scale stroke 
severity phenotyping from EHR and therefore support real-world quality 
improvement and comparative effectiveness studies in stroke.

DOI: 10.1101/2024.03.08.24304011
PMCID: PMC10980121
PMID: 38559062


26. J Am Heart Assoc. 2024 Nov 5;13(21):e036386. doi: 10.1161/JAHA.124.036386. Epub 
2024 Oct 25.

Automated Extraction of Stroke Severity From Unstructured Electronic Health 
Records Using Natural Language Processing.

Fernandes M(1), Westover MB(2), Singhal AB(1), Zafar SF(1).

Author information:
(1)Department of Neurology Massachusetts General Hospital (MGH) Boston MA.
(2)Department of Neurology Beth Israel Deaconess Medical Center (BIDMC) Boston 
MA.

Update of
    medRxiv. 2024 Mar 11:2024.03.08.24304011. doi: 10.1101/2024.03.08.24304011.

BACKGROUND: Multicenter electronic health records can support quality 
improvement and comparative effectiveness research in stroke. However, 
limitations of electronic health record-based research include challenges in 
abstracting key clinical variables, including stroke severity, along with 
missing data. We developed a natural language processing model that reads 
electronic health record notes to directly extract the National Institutes of 
Health Stroke Scale score when documented and predict the score from clinical 
documentation when missing.
METHODS AND RESULTS: The study included notes from patients with acute stroke 
(aged ≥18 years) admitted to Massachusetts General Hospital (2015-2022). The 
Massachusetts General Hospital data were divided into training/holdout test 
(70%/30%) sets. We developed a 2-stage model to predict the admission National 
Institutes of Health Stroke Scale, obtained from the GWTG (Get With The 
Guidelines) stroke registry. We trained a model with the least absolute 
shrinkage and selection operator. For test notes with documented National 
Institutes of Health Stroke Scale, scores were extracted using regular 
expressions (stage 1); when not documented, least absolute shrinkage and 
selection operator was used for prediction (stage 2). The 2-stage model was 
tested on the holdout test set and validated in the Medical Information Mart for 
Intensive Care (2001-2012) version 1.4, using root mean squared error and 
Spearman correlation. We included 4163 patients (Massachusetts General Hospital, 
3876; Medical Information Mart for Intensive Care, 287); average age, 69 (SD, 
15) years; 53% men, and 72% White individuals. The model achieved a root mean 
squared error of 2.89 (95% CI, 2.62-3.19) and Spearman correlation of 0.92 (95% 
CI, 0.91-0.93) in the Massachusetts General Hospital test set, and 2.20 (95% CI, 
1.69-2.66) and 0.96 (95% CI, 0.94-0.97) in the MIMIC validation set, 
respectively.
CONCLUSIONS: The automatic natural language processing-based model can enable 
large-scale stroke severity phenotyping from the electronic health record and 
support real-world quality improvement and comparative effectiveness studies in 
stroke.

DOI: 10.1161/JAHA.124.036386
PMCID: PMC11935650
PMID: 39450737 [Indexed for MEDLINE]


27. Proc Int Conf Comput Ling. 2022 Oct;2022:2979-2991.

Summarizing Patients' Problems from Hospital Progress Notes Using Pre-trained 
Sequence-to-Sequence Models.

Gao Y(1), Miller T(2), Xu D(2), Dligach D(3), Churpek MM(1), Afshar M(1).

Author information:
(1)ICU Data Science Lab, School of Medicine and Public Health, University of 
Wisconsin-Madison.
(2)Boston Children's Hospital, and Harvard Medical School.
(3)Loyola University Chicago.

Automatically summarizing patients' main problems from daily progress notes 
using natural language processing methods helps to battle against information 
and cognitive overload in hospital settings and potentially assists providers 
with computerized diagnostic decision support. Problem list summarization 
requires a model to understand, abstract, and generate clinical documentation. 
In this work, we propose a new NLP task that aims to generate a list of problems 
in a patient's daily care plan using input from the provider's progress notes 
during hospitalization. We investigate the performance of T5 and BART, two 
state-of-the-art seq2seq transformer architectures, in solving this problem. We 
provide a corpus built on top of progress notes from publicly available 
electronic health record progress notes in the Medical Information Mart for 
Intensive Care (MIMIC)-III. T5 and BART are trained on general domain text, and 
we experiment with a data augmentation method and a domain adaptation 
pre-training method to increase exposure to medical vocabulary and knowledge. 
Evaluation methods include ROUGE, BERTScore, cosine similarity on sentence 
embedding, and F-score on medical concepts. Results show that T5 with domain 
adaptive pre-training achieves significant performance gains compared to a 
rule-based system and general domain pre-trained language models, indicating a 
promising direction for tackling the problem summarization task.

PMCID: PMC9581107
PMID: 36268128


28. J Am Med Inform Assoc. 2025 Feb 1;32(2):285-295. doi: 10.1093/jamia/ocae287.

LCD benchmark: long clinical document benchmark on mortality prediction for 
language models.

Yoon W(1)(2), Chen S(1)(2)(3)(4), Gao Y(5), Zhao Z(1)(2), Dligach D(6), 
Bitterman DS(1)(2)(3)(4), Afshar M(5), Miller T(1)(2).

Author information:
(1)Computational Health Informatics Program, Boston Children's Hospital, Boston, 
MA 02215, United States.
(2)Department of Pediatrics, Harvard Medical School, Boston, MA 02115, United 
States.
(3)Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, 
Harvard Medical School, Boston, MA 02115, United States.
(4)Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber 
Cancer Institute, Boston, MA 02215, United States.
(5)Department of Medicine, University of Wisconsin-Madison, Madison, WI 53705, 
United States.
(6)Department of Computer Science, Loyola University Chicago, Chicago, IL 60660, 
United States.

Update of
    medRxiv. 2024 Jul 02:2024.03.26.24304920. doi: 10.1101/2024.03.26.24304920.

OBJECTIVES: The application of natural language processing (NLP) in the clinical 
domain is important due to the rich unstructured information in clinical 
documents, which often remains inaccessible in structured data. When applying 
NLP methods to a certain domain, the role of benchmark datasets is crucial as 
benchmark datasets not only guide the selection of best-performing models but 
also enable the assessment of the reliability of the generated outputs. Despite 
the recent availability of language models capable of longer context, benchmark 
datasets targeting long clinical document classification tasks are absent.
MATERIALS AND METHODS: To address this issue, we propose Long Clinical Document 
(LCD) benchmark, a benchmark for the task of predicting 30-day out-of-hospital 
mortality using discharge notes of Medical Information Mart for Intensive Care 
IV and statewide death data. We evaluated this benchmark dataset using baseline 
models, from bag-of-words and convolutional neural network to instruction-tuned 
large language models. Additionally, we provide a comprehensive analysis of the 
model outputs, including manual review and visualization of model weights, to 
offer insights into their predictive capabilities and limitations.
RESULTS: Baseline models showed 28.9% for best-performing supervised models and 
32.2% for GPT-4 in F1 metrics. Notes in our dataset have a median word count of 
1687.
DISCUSSION: Our analysis of the model outputs showed that our dataset is 
challenging for both models and human experts, but the models can find 
meaningful signals from the text.
CONCLUSION: We expect our LCD benchmark to be a resource for the development of 
advanced supervised models, or prompting methods, tailored for clinical text.

© The Author(s) 2024. Published by Oxford University Press on behalf of the 
American Medical Informatics Association. All rights reserved. For permissions, 
please email: journals.permissions@oup.com.

DOI: 10.1093/jamia/ocae287
PMCID: PMC11756648
PMID: 39602813 [Indexed for MEDLINE]

Conflict of interest statement: None declared.


29. J Biomed Inform. 2022 Mar;127:103984. doi: 10.1016/j.jbi.2021.103984. Epub 2022 
Jan 7.

Classifying social determinants of health from unstructured electronic health 
records using deep learning-based natural language processing.

Han S(1), Zhang RF(2), Shi L(1), Richie R(1), Liu H(3), Tseng A(4), Quan W(5), 
Ryan N(6), Brent D(6), Tsui FR(7).

Author information:
(1)Tsui Laboratory, Department of Biomedical and Health Informatics, Children's 
Hospital of Philadelphia, Philadelphia, PA, USA.
(2)Tsui Laboratory, Department of Biomedical and Health Informatics, Children's 
Hospital of Philadelphia, Philadelphia, PA, USA; Perelman School of Medicine, 
University of Pennsylvania, PA, USA.
(3)Central South University, Changsha, Hunan, CN.
(4)Touro University Nevada, Henderson, NV, USA.
(5)New York University Abu Dhabi, Abu Dhabi, AE.
(6)Department of Psychiatry, University of Pittsburgh, Pittsburgh, PA, USA.
(7)Tsui Laboratory, Department of Biomedical and Health Informatics, Children's 
Hospital of Philadelphia, Philadelphia, PA, USA; Perelman School of Medicine, 
University of Pennsylvania, PA, USA. Electronic address: tsuif@chop.edu.

OBJECTIVE: Social determinants of health (SDOH) are non-medical factors that can 
profoundly impact patient health outcomes. However, SDOH are rarely available in 
structured electronic health record (EHR) data such as diagnosis codes, and more 
commonly found in unstructured narrative clinical notes. Hence, identifying 
social context from unstructured EHR data has become increasingly important. 
Yet, previous work on using natural language processing to automate extraction 
of SDOH from text (a) usually focuses on an ad hoc selection of SDOH, and (b) 
does not use the latest advances in deep learning. Our objective was to advance 
automatic extraction of SDOH from clinical text by (a) systematically creating a 
set of SDOH based on standard biomedical and psychiatric ontologies, and (b) 
training state-of-the-art deep neural networks to extract mentions of these SDOH 
from clinical notes.
DESIGN: A retrospective cohort study.
SETTING AND PARTICIPANTS: Data were extracted from the Medical Information Mart 
for Intensive Care (MIMIC-III) database. The corpus comprised 3,504 social 
related sentences from 2,670 clinical notes.
METHODS: We developed a framework for automated classification of multiple SDOH 
categories. Our dataset comprised narrative clinical notes under the "Social 
Work" category in the MIMIC-III Clinical Database. Using standard terminologies, 
SNOMED-CT and DSM-IV, we systematically curated a set of 13 SDOH categories and 
created annotation guidelines for these. After manually annotating the 3,504 
sentences, we developed and tested three deep neural network (DNN) architectures 
- convolutional neural network (CNN), long short-term memory (LSTM) network, and 
the Bidirectional Encoder Representations from Transformers (BERT) - for 
automated detection of eight SDOH categories. We also compared these DNNs to 
three baselines models: (1) cTAKES, as well as (2) L2-regularized logistic 
regression and (3) random forests on bags-of-words. Model evaluation metrics 
included micro- and macro- F1, and area under the receiver operating 
characteristic curve (AUC).
RESULTS: All three DNN models accurately classified all SDOH categories (minimum 
micro-F1 = 0.632, minimum macro-AUC = 0.854). Compared to the CNN and LSTM, BERT 
performed best in most key metrics (micro-F1 = 0.690, macro-AUC = 0.907). The 
BERT model most effectively identified the "occupational" category (F1 = 0.774, 
AUC = 0.965) and least effectively identified the "non-SDOH" category 
(F = 0.491, AUC = 0.788). BERT outperformed cTAKES in distinguishing social vs 
non-social sentences (BERT F1 = 0.87 vs. cTAKES F1 = 0.06), and outperformed 
logistic regression (micro-F1 = 0.649, macro-AUC = 0.696) and random forest 
(micro-F1 = 0.502, macro-AUC = 0.523) trained on bag-of-words.
CONCLUSIONS: Our study framework with DNN models demonstrated improved 
performance for efficiently identifying a systematic range of SDOH categories 
from clinical notes in the EHR. Improved identification of patient SDOH may 
further improve healthcare outcomes.

Copyright © 2022 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jbi.2021.103984
PMID: 35007754 [Indexed for MEDLINE]


30. Eur Heart J Digit Health. 2024 Feb 9;5(3):229-234. doi: 10.1093/ehjdh/ztae008. 
eCollection 2024 May.

Using natural language processing for automated classification of disease and to 
identify misclassified ICD codes in cardiac disease.

Falter M(1)(2)(3), Godderis D(4), Scherrenberg M(1)(2)(5), Kizilkilic 
SE(1)(2)(6), Xu L(1)(2), Mertens M(7), Jansen J(7), Legroux P(7), Kindermans 
H(1), Sinnaeve P(3), Neven F(4), Dendale P(1)(2).

Author information:
(1)Faculty of Medicine and Life Sciences, Hasselt University, Agoralaan gebouw 
D, 3590 Diepenbeek, Hasselt, Belgium.
(2)Heart Centre Hasselt, Jessa Hospital, Stadsomvaart 11, 3500 Hasselt, Belgium.
(3)Department of Cardiology, KULeuven, Faculty of Medicine, Herestraat 49, 3000 
Leuven, Belgium.
(4)Data Science Institute, Hasselt University, Agoralaan gebouw D, 3590 
Diepenbeek, Hasselt, Belgium.
(5)Faculty of Medicine and Health Sciences, Antwerp University, 
Universiteitsplein 1, 2610 Antwerp, Belgium.
(6)Faculty of Medicine and Health Sciences, Ghent University, Corneel 
Heymanslaan 10, 9000 Gent, Belgium.
(7)Department of Information and Communications Technology, Jessa Hospital, 
Stadsomvaart 11, 3500 Hasselt, Belgium.

AIMS: ICD codes are used for classification of hospitalizations. The codes are 
used for administrative, financial, and research purposes. It is known, however, 
that errors occur. Natural language processing (NLP) offers promising solutions 
for optimizing the process. To investigate methods for automatic classification 
of disease in unstructured medical records using NLP and to compare these to 
conventional ICD coding.
METHODS AND RESULTS: Two datasets were used: the open-source Medical Information 
Mart for Intensive Care (MIMIC)-III dataset (n = 55.177) and a dataset from a 
hospital in Belgium (n = 12.706). Automated searches using NLP algorithms were 
performed for the diagnoses 'atrial fibrillation (AF)' and 'heart failure (HF)'. 
Four methods were used: rule-based search, logistic regression, term 
frequency-inverse document frequency (TF-IDF), Extreme Gradient Boosting 
(XGBoost), and Bio-Bidirectional Encoder Representations from Transformers 
(BioBERT). All algorithms were developed on the MIMIC-III dataset. The best 
performing algorithm was then deployed on the Belgian dataset. After 
preprocessing a total of 1438 reports was retained in the Belgian dataset. 
XGBoost on TF-IDF matrix resulted in an accuracy of 0.94 and 0.92 for AF and HF, 
respectively. There were 211 mismatches between algorithm and ICD codes. One 
hundred and three were due to a difference in data availability or differing 
definitions. In the remaining 108 mismatches, 70% were due to incorrect 
labelling by the algorithm and 30% were due to erroneous ICD coding (2% of total 
hospitalizations).
CONCLUSION: A newly developed NLP algorithm attained a high accuracy for 
classifying disease in medical records. XGBoost outperformed the deep learning 
technique BioBERT. NLP algorithms could be used to identify ICD-coding errors 
and optimize and support the ICD-coding process.

© The Author(s) 2024. Published by Oxford University Press on behalf of the 
European Society of Cardiology.

DOI: 10.1093/ehjdh/ztae008
PMCID: PMC11104467
PMID: 38774372

Conflict of interest statement: Conflict of interest: None declared


31. J Comput Biol. 2023 Aug;30(8):912-925. doi: 10.1089/cmb.2023.0079.

Automatic International Classification of Diseases Coding via Note-Code 
Interaction Network with Denoising Mechanism.

Li X(1), Zhang Y(1), Li X(1), Pan X(2), Wang J(3), Lu M(2).

Author information:
(1)School of Information Science and Technology, Dalian Maritime University, 
Dalian, Liaoning, China.
(2)School of Artificial Intelligence, Dalian University of Technology, Dalian, 
Liaoning, China.
(3)School of Computer Science and Technology, Dalian University of Technology, 
Dalian, Liaoning, China.

Clinical notes are comprehensive files containing explicit information about a 
patient's visit. However, accurately assigning medical codes from clinical 
documents can be a persistent challenge due to the complexity of clinical data 
and the vast range of medical codes. Moreover, the large volume of medical 
records, the noisy medical records, and the uneven quality of coders all 
negatively impact the quality of the final codes. Deep learning technology has 
recently been integrated into automatic International Classification of Diseases 
(ICD) coding tasks to improve accuracy. Nevertheless, the imbalanced class 
problem, the complexness of code associations, and the noise in lengthy records 
still restrict the advancement of ICD coding tasks in deep learning. Thus, we 
present the Note-code Interaction Denoising Network (NIDN) that employs the 
self-attention mechanism to pull critical semantic features in electronic 
medical records (EMRs). Our model utilizes the label attention mechanism for 
retaining code-specific text expression. We introduce Clinical Classifications 
Software coding for multitask learning, capturing the functional relationships 
of medical coding to oblige in model prediction. To minimize the impact of noise 
on model prediction and improve the label distribution imbalance, a denoising 
module is introduced to filter noise. Our practical consequences indicate that 
the model NIDN exceeds competitive models on a third version of Medical 
Information Mart for Intensive Care data set.

DOI: 10.1089/cmb.2023.0079
PMID: 37566468 [Indexed for MEDLINE]


32. Comput Methods Programs Biomed. 2019 Aug;177:141-153. doi: 
10.1016/j.cmpb.2019.05.024. Epub 2019 May 25.

An empirical evaluation of deep learning for ICD-9 code assignment using 
MIMIC-III clinical notes.

Huang J(1), Osorio C(2), Sy LW(3).

Author information:
(1)Georgia Institute of Technology, North Ave NW, Atlanta, Georgia, 30332, USA. 
Electronic address: vichuang@gatech.edu.
(2)Georgia Institute of Technology, North Ave NW, Atlanta, Georgia, 30332, USA. 
Electronic address: cesar.osorio@gatech.edu.
(3)Georgia Institute of Technology, North Ave NW, Atlanta, Georgia, 30332, USA. 
Electronic address: sylukewicent@gmail.com.

BACKGROUND AND OBJECTIVE: Code assignment is of paramount importance in many 
levels in modern hospitals, from ensuring accurate billing process to creating a 
valid record of patient care history. However, the coding process is tedious and 
subjective, and it requires medical coders with extensive training. This study 
aims to evaluate the performance of deep-learning-based systems to automatically 
map clinical notes to ICD-9 medical codes.
METHODS: The evaluations of this research are focused on end-to-end learning 
methods without manually defined rules. Traditional machine learning algorithms, 
as well as state-of-the-art deep learning methods such as Recurrent Neural 
Networks and Convolution Neural Networks, were applied to the Medical 
Information Mart for Intensive Care (MIMIC-III) dataset. An extensive number of 
experiments was applied to different settings of the tested algorithm.
RESULTS: Findings showed that the deep learning-based methods outperformed other 
conventional machine learning methods. From our assessment, the best models 
could predict the top 10 ICD-9 codes with 0.6957 F1 and 0.8967 accuracy and 
could estimate the top 10 ICD-9 categories with 0.7233 F1 and 0.8588 accuracy. 
Our implementation also outperformed existing work under certain evaluation 
metrics.
CONCLUSION: A set of standard metrics was utilized in assessing the performance 
of ICD-9 code assignment on MIMIC-III dataset. All the developed evaluation 
tools and resources are available online, which can be used as a baseline for 
further research.

Copyright © 2019 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.cmpb.2019.05.024
PMID: 31319942 [Indexed for MEDLINE]


33. J Am Med Inform Assoc. 2019 Nov 1;26(11):1297-1304. doi: 10.1093/jamia/ocz096.

Enhancing clinical concept extraction with contextual embeddings.

Si Y(1), Wang J(1), Xu H(1), Roberts K(1).

Author information:
(1)School of Biomedical Informatics, University of Texas Health Science Center 
at Houston, Houston, Texas, USA.

OBJECTIVE: Neural network-based representations ("embeddings") have dramatically 
advanced natural language processing (NLP) tasks, including clinical NLP tasks 
such as concept extraction. Recently, however, more advanced embedding methods 
and representations (eg, ELMo, BERT) have further pushed the state of the art in 
NLP, yet there are no common best practices for how to integrate these 
representations into clinical tasks. The purpose of this study, then, is to 
explore the space of possible options in utilizing these new models for clinical 
concept extraction, including comparing these to traditional word embedding 
methods (word2vec, GloVe, fastText).
MATERIALS AND METHODS: Both off-the-shelf, open-domain embeddings and pretrained 
clinical embeddings from MIMIC-III (Medical Information Mart for Intensive Care 
III) are evaluated. We explore a battery of embedding methods consisting of 
traditional word embeddings and contextual embeddings and compare these on 4 
concept extraction corpora: i2b2 2010, i2b2 2012, SemEval 2014, and SemEval 
2015. We also analyze the impact of the pretraining time of a large language 
model like ELMo or BERT on the extraction performance. Last, we present an 
intuitive way to understand the semantic information encoded by contextual 
embeddings.
RESULTS: Contextual embeddings pretrained on a large clinical corpus achieves 
new state-of-the-art performances across all concept extraction tasks. The 
best-performing model outperforms all state-of-the-art methods with respective 
F1-measures of 90.25, 93.18 (partial), 80.74, and 81.65.
CONCLUSIONS: We demonstrate the potential of contextual embeddings through the 
state-of-the-art performance these methods achieve on clinical concept 
extraction. Additionally, we demonstrate that contextual embeddings encode 
valuable semantic information not accounted for in traditional word 
representations.

© The Author(s) 2019. Published by Oxford University Press on behalf of the 
American Medical Informatics Association. All rights reserved. For permissions, 
please email: journals.permissions@oup.com.

DOI: 10.1093/jamia/ocz096
PMCID: PMC6798561
PMID: 31265066 [Indexed for MEDLINE]


34. Int J Med Inform. 2020 Jul;139:104135. doi: 10.1016/j.ijmedinf.2020.104135. Epub 
2020 Apr 4.

Automated ICD coding via unsupervised knowledge integration (UNITE).

Sonabend W A(1), Cai W(2), Ahuja Y(1), Ananthakrishnan A(3), Xia Z(4), Yu S(5), 
Hong C(6).

Author information:
(1)Department of Biostatistics, Harvard T. H. Chan School of Public Health, 
Boston, MA, USA.
(2)Bronx Science, New York City, NY, USA.
(3)Division of Gastroenterology, Massachusetts General Hospital and Harvard 
Medical School, USA.
(4)Department of Neurology and Biomedical Informatics, University of Pittsburgh, 
Pittsburgh, PA, USA.
(5)Center for Statistical Science, Tsinghua University, Beijing, China; 
Department of Industrial Engineering, Tsinghua University, Beijing, China; 
Institute for Data Science, Tsinghua University, Beijing, China.
(6)Department of Biomedical Informatics, Harvard Medical School, Boston, MA, 
USA. Electronic address: chuan_hong@hms.harvard.edu.

OBJECTIVE: Accurate coding is critical for medical billing and electronic 
medical record (EMR)-based research. Recent research has been focused on 
developing supervised methods to automatically assign International 
Classification of Diseases (ICD) codes from clinical notes. However, supervised 
approaches rely on ICD code data stored in the hospital EMR system and is 
subject to bias rising from the practice and coding behavior. Consequently, 
portability of trained supervised algorithms to external EMR systems may suffer.
METHOD: We developed an unsupervised knowledge integration (UNITE) algorithm to 
automatically assign ICD codes for a specific disease by analyzing clinical 
narrative notes via semantic relevance assessment. The algorithm was validated 
using coded ICD data for 6 diseases from Partners HealthCare (PHS) Biobank and 
Medical Information Mart for Intensive Care (MIMIC-III). We compared the 
performance of UNITE against penalized logistic regression (LR), topic modeling, 
and neural network models within each EMR system. We additionally evaluated the 
portability of UNITE by training at PHS Biobank and validating at MIMIC-III, and 
vice versa.
RESULTS: UNITE achieved an averaged AUC of 0.91 at PHS and 0.92 at MIMIC over 6 
diseases, comparable to LR and MLP. It had substantially better performance than 
topic models. In regards to portability, the performance of UNITE was consistent 
across different EMR systems, superior to LR, topic models and neural network 
models.
CONCLUSION: UNITE accurately assigns ICD code in EMR without requiring human 
labor, and has major advantages over commonly used machine learning approaches. 
In addition, the UNITE attained stable performance and high portability across 
EMRs in different institutions.

Copyright © 2020 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.ijmedinf.2020.104135
PMCID: PMC9410729
PMID: 32361145 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest All authors 
have declared that they have no financial or non-financial interests that may be 
relevant to the submitted work; no other relationships or activities that could 
appear to have influenced the submitted work.


35. BMC Med Inform Decis Mak. 2020 Oct 29;20(1):280. doi: 
10.1186/s12911-020-01297-6.

Combining structured and unstructured data for predictive models: a deep 
learning approach.

Zhang D(1)(2), Yin C(3), Zeng J(1)(2), Yuan X(2), Zhang P(4)(5).

Author information:
(1)Department of Biomedical Informatics, The Ohio State University, 1800 Cannon 
Drive, Columbus, OH, 43210, USA.
(2)School of Computer Science and Technology, Wuhan University of Technology, 
Wuhan, 430070, Hubei, China.
(3)Department of Computer Science and Engineering, The Ohio State University, 
2015 Neil Ave, Columbus, OH, 43210, USA.
(4)Department of Biomedical Informatics, The Ohio State University, 1800 Cannon 
Drive, Columbus, OH, 43210, USA. mail.pingzhang@gmail.com.
(5)Department of Computer Science and Engineering, The Ohio State University, 
2015 Neil Ave, Columbus, OH, 43210, USA. mail.pingzhang@gmail.com.

BACKGROUND: The broad adoption of electronic health records (EHRs) provides 
great opportunities to conduct health care research and solve various clinical 
problems in medicine. With recent advances and success, methods based on machine 
learning and deep learning have become increasingly popular in medical 
informatics. However, while many research studies utilize temporal structured 
data on predictive modeling, they typically neglect potentially valuable 
information in unstructured clinical notes. Integrating heterogeneous data types 
across EHRs through deep learning techniques may help improve the performance of 
prediction models.
METHODS: In this research, we proposed 2 general-purpose multi-modal neural 
network architectures to enhance patient representation learning by combining 
sequential unstructured notes with structured data. The proposed fusion models 
leverage document embeddings for the representation of long clinical note 
documents and either convolutional neural network or long short-term memory 
networks to model the sequential clinical notes and temporal signals, and 
one-hot encoding for static information representation. The concatenated 
representation is the final patient representation which is used to make 
predictions.
RESULTS: We evaluate the performance of proposed models on 3 risk prediction 
tasks (i.e. in-hospital mortality, 30-day hospital readmission, and long length 
of stay prediction) using derived data from the publicly available Medical 
Information Mart for Intensive Care III dataset. Our results show that by 
combining unstructured clinical notes with structured data, the proposed models 
outperform other models that utilize either unstructured notes or structured 
data only.
CONCLUSIONS: The proposed fusion models learn better patient representation by 
combining structured and unstructured data. Integrating heterogeneous data types 
across EHRs helps improve the performance of prediction models and reduce 
errors.

DOI: 10.1186/s12911-020-01297-6
PMCID: PMC7596962
PMID: 33121479 [Indexed for MEDLINE]

Conflict of interest statement: PZ is the member of the editorial board of BMC 
Medical Informatics and Decision Making. The authors declare that they have no 
other competing interests.


36. BMC Med Inform Decis Mak. 2020 Dec 30;20(Suppl 11):295. doi: 
10.1186/s12911-020-01318-4.

Predicting mortality in critically ill patients with diabetes using machine 
learning and clinical notes.

Ye J(1), Yao L(2), Shen J(3), Janarthanam R(1), Luo Y(4).

Author information:
(1)Feinberg School of Medicine, Northwestern University, Chicago, IL, USA.
(2)Tencent, Shenzhen, China.
(3)Dept. of Materials Science and Engineering, Northwestern University, 
Evanston, IL, USA.
(4)Feinberg School of Medicine, Northwestern University, Chicago, IL, USA. 
yuan.luo@northwestern.edu.

BACKGROUND: Diabetes mellitus is a prevalent metabolic disease characterized by 
chronic hyperglycemia. The avalanche of healthcare data is accelerating 
precision and personalized medicine. Artificial intelligence and algorithm-based 
approaches are becoming more and more vital to support clinical decision-making. 
These methods are able to augment health care providers by taking away some of 
their routine work and enabling them to focus on critical issues. However, few 
studies have used predictive modeling to uncover associations between 
comorbidities in ICU patients and diabetes. This study aimed to use Unified 
Medical Language System (UMLS) resources, involving machine learning and natural 
language processing (NLP) approaches to predict the risk of mortality.
METHODS: We conducted a secondary analysis of Medical Information Mart for 
Intensive Care III (MIMIC-III) data. Different machine learning modeling and NLP 
approaches were applied. Domain knowledge in health care is built on the 
dictionaries created by experts who defined the clinical terminologies such as 
medications or clinical symptoms. This knowledge is valuable to identify 
information from text notes that assert a certain disease. Knowledge-guided 
models can automatically extract knowledge from clinical notes or biomedical 
literature that contains conceptual entities and relationships among these 
various concepts. Mortality classification was based on the combination of 
knowledge-guided features and rules. UMLS entity embedding and convolutional 
neural network (CNN) with word embeddings were applied. Concept Unique 
Identifiers (CUIs) with entity embeddings were utilized to build clinical text 
representations.
RESULTS: The best configuration of the employed machine learning models yielded 
a competitive AUC of 0.97. Machine learning models along with NLP of clinical 
notes are promising to assist health care providers to predict the risk of 
mortality of critically ill patients.
CONCLUSION: UMLS resources and clinical notes are powerful and important tools 
to predict mortality in diabetic patients in the critical care setting. The 
knowledge-guided CNN model is effective (AUC = 0.97) for learning hidden 
features.

DOI: 10.1186/s12911-020-01318-4
PMCID: PMC7772896
PMID: 33380338 [Indexed for MEDLINE]

Conflict of interest statement: None.


37. J Biomed Inform. 2018 Jul;83:112-134. doi: 10.1016/j.jbi.2018.04.007. Epub 2018 
Jun 5.

Benchmarking deep learning models on large healthcare datasets.

Purushotham S(1), Meng C(2), Che Z(3), Liu Y(4).

Author information:
(1)University of Southern California, Los Angeles, CA 90089, United States. 
Electronic address: spurusho@usc.edu.
(2)Tsinghua University, Beijing 100084, China. Electronic address: 
mengcz95thu@gmail.com.
(3)University of Southern California, Los Angeles, CA 90089, United States. 
Electronic address: zche@usc.edu.
(4)University of Southern California, Los Angeles, CA 90089, United States. 
Electronic address: yanliu.cs@usc.edu.

Deep learning models (aka Deep Neural Networks) have revolutionized many fields 
including computer vision, natural language processing, speech recognition, and 
is being increasingly used in clinical healthcare applications. However, few 
works exist which have benchmarked the performance of the deep learning models 
with respect to the state-of-the-art machine learning models and prognostic 
scoring systems on publicly available healthcare datasets. In this paper, we 
present the benchmarking results for several clinical prediction tasks such as 
mortality prediction, length of stay prediction, and ICD-9 code group prediction 
using Deep Learning models, ensemble of machine learning models (Super Learner 
algorithm), SAPS II and SOFA scores. We used the Medical Information Mart for 
Intensive Care III (MIMIC-III) (v1.4) publicly available dataset, which includes 
all patients admitted to an ICU at the Beth Israel Deaconess Medical Center from 
2001 to 2012, for the benchmarking tasks. Our results show that deep learning 
models consistently outperform all the other approaches especially when the 
'raw' clinical time series data is used as input features to the models.

Copyright © 2018 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jbi.2018.04.007
PMID: 29879470 [Indexed for MEDLINE]


38. J Med Internet Res. 2024 Oct 30;26:e53636. doi: 10.2196/53636.

Question Answering for Electronic Health Records: Scoping Review of Datasets and 
Models.

Bardhan J(1), Roberts K(2), Wang DZ(1).

Author information:
(1)Department of Computer and Information Science and Engineering, University of 
Florida, Gainesville, FL, United States.
(2)School of Biomedical Informatics, The University of Texas Health Science 
Center at Houston, Houston, TX, United States.

BACKGROUND: Question answering (QA) systems for patient-related data can assist 
both clinicians and patients. They can, for example, assist clinicians in 
decision-making and enable patients to have a better understanding of their 
medical history. Substantial amounts of patient data are stored in electronic 
health records (EHRs), making EHR QA an important research area. Because of the 
differences in data format and modality, this differs greatly from other medical 
QA tasks that use medical websites or scientific papers to retrieve answers, 
making it critical to research EHR QA.
OBJECTIVE: This study aims to provide a methodological review of existing works 
on QA for EHRs. The objectives of this study were to identify the existing EHR 
QA datasets and analyze them, study the state-of-the-art methodologies used in 
this task, compare the different evaluation metrics used by these 
state-of-the-art models, and finally elicit the various challenges and the 
ongoing issues in EHR QA.
METHODS: We searched for articles from January 1, 2005, to September 30, 2023, 
in 4 digital sources, including Google Scholar, ACL Anthology, ACM Digital 
Library, and PubMed, to collect relevant publications on EHR QA. Our systematic 
screening process followed PRISMA (Preferred Reporting Items for Systematic 
Reviews and Meta-Analyses) guidelines. A total of 4111 papers were identified 
for our study, and after screening based on our inclusion criteria, we obtained 
47 papers for further study. The selected studies were then classified into 2 
non-mutually exclusive categories depending on their scope: "EHR QA datasets" 
and "EHR QA models."
RESULTS: A systematic screening process obtained 47 papers on EHR QA for final 
review. Out of the 47 papers, 53% (n=25) were about EHR QA datasets, and 79% 
(n=37) papers were about EHR QA models. It was observed that QA on EHRs is 
relatively new and unexplored. Most of the works are fairly recent. In addition, 
it was observed that emrQA is by far the most popular EHR QA dataset, both in 
terms of citations and usage in other papers. We have classified the EHR QA 
datasets based on their modality, and we have inferred that Medical Information 
Mart for Intensive Care (MIMIC-III) and the National Natural Language Processing 
Clinical Challenges datasets (ie, n2c2 datasets) are the most popular EHR 
databases and corpuses used in EHR QA. Furthermore, we identified the different 
models used in EHR QA along with the evaluation metrics used for these models.
CONCLUSIONS: EHR QA research faces multiple challenges, such as the limited 
availability of clinical annotations, concept normalization in EHR QA, and 
challenges faced in generating realistic EHR QA datasets. There are still many 
gaps in research that motivate further work. This study will assist future 
researchers in focusing on areas of EHR QA that have possible future research 
directions.

©Jayetri Bardhan, Kirk Roberts, Daisy Zhe Wang. Originally published in the 
Journal of Medical Internet Research (https://www.jmir.org), 30.10.2024.

DOI: 10.2196/53636
PMCID: PMC11561445
PMID: 39475821 [Indexed for MEDLINE]

Conflict of interest statement: Conflicts of Interest: None declared.


39. JAMA Netw Open. 2018 Nov 2;1(7):e184178. doi: 10.1001/jamanetworkopen.2018.4178.

Prevalence and Nature of Financial Considerations Documented in Narrative 
Clinical Records in Intensive Care Units.

Gordon DD(1), Patel I(1), Pellegrini AM(2), Perlis RH(2)(3).

Author information:
(1)Mossavar-Rahmani Center for Business and Government, Harvard Kennedy School, 
Cambridge, Massachusetts.
(2)Center for Quantitative Health, Division of Clinical Research and Center for 
Genomic Medicine, Massachusetts General Hospital, Boston.
(3)Department of Psychiatry, Harvard Medical School, Boston, Massachusetts.

IMPORTANCE: The extent to which financial considerations alter intensive care 
unit (ICU) decision making is poorly understood.
OBJECTIVES: To characterize the prevalence and nature of financial 
considerations documented in narrative clinical records and their association 
with patient-level demographic and clinical features.
DESIGN, SETTING, AND PARTICIPANTS: In silico cohort study applying natural 
language processing to narrative notes from the Medical Information Mart for 
Intensive Care (MIMIC-III) study. Data from all individuals hospitalized between 
June 1, 2001, and October 31, 2012, in the ICU of Beth Israel Deaconess Medical 
Center were analyzed from April 1 to April 30, 2018.
MAIN OUTCOMES AND MEASURE: Presence of financial considerations in narrative 
clinical notes.
RESULTS: Among 46 146 index ICU admissions, 1936 patients (4.2%) were identified 
with at least 1 note reflecting financial considerations during the ICU stay. Of 
these 1936 patients, 1135 (58.6%) were male, with a mean (SD) age of 38.8 (28.4) 
years and mean (SD) length of stay of 21.7 (27.1) days. Among the remaining 44 
210 admissions in the cohort, 24 780 (56.1%) were male, with a mean (SD) age of 
48.6 (32.1) years and mean (SD) length of stay of 9.2 (11.4) days. Among the 
46 146 admissions, 142 (0.3%) included notes describing a change in the 
discharge plan, 142 (0.3%) describing a change in the treatment plan, and 303 
(0.7%) describing a change in medication or previous nonadherence to medication 
associated with financial considerations. In logistic regression models adjusted 
for age, sex, marital status, and insurance type, longer hospital stays were 
significantly associated with the presence of financial notes (odds ratio, 1.01; 
95% CI, 1.01-1.01).
CONCLUSIONS AND RELEVANCE: In this study, among patients in the ICU, clinical 
notes document the association of financial considerations with care decisions. 
Although such notes likely underestimate the frequency of such considerations, 
they highlight the need to develop better systematic approaches to understanding 
how financial constraints may alter care decisions in US health systems.

DOI: 10.1001/jamanetworkopen.2018.4178
PMCID: PMC6324587
PMID: 30646344 [Indexed for MEDLINE]

Conflict of interest statement: Conflict of Interest Disclosures: Dr Perlis 
reported receiving fees for consulting or service on scientific advisory boards 
from Genomind, Psy Therapeutics Inc, and RID Ventures LLC and holds equity in 
Psy Therapeutics Inc. No other disclosures were reported.


40. Proceedings (IEEE Int Conf Bioinformatics Biomed). 2018 Dec;2018:683-686. doi: 
10.1109/bibm.2018.8621574. Epub 2019 Jan 24.

Early Prediction of Acute Kidney Injury in Critical Care Setting Using Clinical 
Notes.

Li Y(1), Yao L, Mao C(2), Srivastava A(3), Jiang X(4), Luo Y(2).

Author information:
(1)Dept. of EECS, Northwestern University, Evanston, IL, U.S.A.
(2)Dept. of Preventive Medicine, Northwestern University, Chicago, IL, U.S.A.
(3)Div. of Nephrology and Hypertension, Northwestern University, Chicago, IL, 
U.S.A.
(4)School of Biomedical Informatics, Univ. of Texas Health Science Center, 
Houston, TX, U.S.A.

Acute kidney injury (AKI) in critically ill patients is associated with 
significant morbidity and mortality. Development of novel methods to identify 
patients with AKI earlier will allow for testing of novel strategies to prevent 
or reduce the complications of AKI. We developed data-driven prediction models 
to estimate the risk of new AKI onset. We generated models from clinical notes 
within the first 24 hours following intensive care unit (ICU) admission 
extracted from Medical Information Mart for Intensive Care III (MIMIC-III). From 
the clinical notes, we generated clinically meaningful word and concept 
representations and embeddings, respectively. Five supervised learning 
classifiers and knowledge-guided deep learning architecture were used to 
construct prediction models. The best configuration yielded a competitive AUC of 
0.779. Our work suggests that natural language processing of clinical notes can 
be applied to assist clinicians in identifying the risk of incident AKI onset in 
critically ill patients upon admission to the ICU.

DOI: 10.1109/bibm.2018.8621574
PMCID: PMC7768909
PMID: 33376624


41. Front Med (Lausanne). 2022 Feb 8;8:793815. doi: 10.3389/fmed.2021.793815. 
eCollection 2021.

Transportability and Implementation Challenges of Early Warning Scores for 
Septic Shock in the ICU: A Perspective on the TREWScore.

Niemantsverdriet MSA(1)(2), Varkila MRJ(3), Vromen-Wijsman JLP(3), Hoefer IE(1), 
Bellomo D(2), van Vliet MH(2), van Solinge WW(1), Cremer OL(3), Haitjema S(1).

Author information:
(1)Central Diagnostic Laboratory, University Medical Center Utrecht, Utrecht 
University, Utrecht, Netherlands.
(2)SkylineDx, Rotterdam, Netherlands.
(3)Department of Intensive Care Medicine, University Medical Center Utrecht, 
Utrecht University, Utrecht, Netherlands.

The increased use of electronic health records (EHRs) has improved the 
availability of routine care data for medical research. Combined with machine 
learning techniques this has spurred the development of early warning scores 
(EWSs) in hospitals worldwide. EWSs are commonly used in the hospital where they 
have been developed, yet few have been transported to external settings and/or 
internationally. In this perspective, we describe our experiences in 
implementing the TREWScore, a septic shock EWS, and the transportability 
challenges regarding domain, predictors, and clinical outcome we faced. We used 
data of 53,330 ICU stays from Medical Information Mart for Intensive Care-III 
(MIMIC-III) and 18,013 ICU stays from the University Medical Center (UMC) 
Utrecht, including 17,023 (31.9%) and 2,557 (14.2%) cases of sepsis, 
respectively. The MIMIC-III and UMC populations differed significantly regarding 
the length of stay (6.9 vs. 9.0 days) and hospital mortality (11.6% vs. 13.6%). 
We mapped all 54 TREWScore predictors to the UMC database: 31 were readily 
available, seven required unit conversion, 14 had to be engineered, one 
predictor required text mining, and one predictor could not be mapped. Lastly, 
we classified sepsis cases for septic shock using the sepsis-2 criteria. Septic 
shock populations (UMC 31.3% and MIMIC-III 23.3%) and time to shock events 
showed significant differences between the two cohorts. In conclusion, we 
identified challenges to transportability and implementation regarding domain, 
predictors, and clinical outcome when transporting EWS between hospitals across 
two continents. These challenges need to be systematically addressed to improve 
model transportability between centers and unlock the potential clinical utility 
of EWS.

Copyright © 2022 Niemantsverdriet, Varkila, Vromen-Wijsman, Hoefer, Bellomo, van 
Vliet, van Solinge, Cremer and Haitjema.

DOI: 10.3389/fmed.2021.793815
PMCID: PMC8860834
PMID: 35211485

Conflict of interest statement: MN was employed by SkylineDx, Rotterdam and 
received a PhD fellowship from SkylineDx, Rotterdam. DB was employed by 
SkylineDx, Rotterdam. MVi was employed by SkylineDx, Rotterdam. SH received a 
fellowship from Abbott Diagnostics. The remaining authors declare that the 
research was conducted in the absence of any commercial or financial 
relationships that could be construed as a potential conflict of interest.


42. JMIR Med Inform. 2021 Apr 22;9(4):e22797. doi: 10.2196/22797.

A Hybrid Model for Family History Information Identification and Relation 
Extraction: Development and Evaluation of an End-to-End Information Extraction 
System.

Kim Y(1), Heider PM(1), Lally IR(2), Meystre SM(1).

Author information:
(1)Biomedical Informatics Center, Medical University of South Carolina, 
Charleston, SC, United States.
(2)Department of Computer Science, College of Charleston, Charleston, SC, United 
States.

BACKGROUND: Family history information is important to assess the risk of 
inherited medical conditions. Natural language processing has the potential to 
extract this information from unstructured free-text notes to improve patient 
care and decision making. We describe the end-to-end information extraction 
system the Medical University of South Carolina team developed when 
participating in the 2019 National Natural Language Processing Clinical 
Challenge (n2c2)/Open Health Natural Language Processing (OHNLP) shared task.
OBJECTIVE: This task involves identifying mentions of family members and 
observations in electronic health record text notes and recognizing the 2 types 
of relations (family member-living status relations and family 
member-observation relations). Our system aims to achieve a high level of 
performance by integrating heuristics and advanced information extraction 
methods. Our efforts also include improving the performance of 2 subtasks by 
exploiting additional labeled data and clinical text-based embedding models.
METHODS: We present a hybrid method that combines machine learning and 
rule-based approaches. We implemented an end-to-end system with multiple 
information extraction and attribute classification components. For entity 
identification, we trained bidirectional long short-term memory deep learning 
models. These models incorporated static word embeddings and context-dependent 
embeddings. We created a voting ensemble that combined the predictions of all 
individual models. For relation extraction, we trained 2 relation extraction 
models. The first model determined the living status of each family member. The 
second model identified observations associated with each family member. We 
implemented online gradient descent models to extract related entity pairs. As 
part of postchallenge efforts, we used the BioCreative/OHNLP 2018 corpus and 
trained new models with the union of these 2 datasets. We also pretrained 
language models using clinical notes from the Medical Information Mart for 
Intensive Care (MIMIC-III) clinical database.
RESULTS: The voting ensemble achieved better performance than individual 
classifiers. In the entity identification task, our top-performing system 
reached a precision of 78.90% and a recall of 83.84%. Our natural language 
processing system for entity identification took 3rd place out of 17 teams in 
the challenge. We ranked 4th out of 9 teams in the relation extraction task. Our 
system substantially benefited from the combination of the 2 datasets. Compared 
to our official submission with F1 scores of 81.30% and 64.94% for entity 
identification and relation extraction, respectively, the revised system yielded 
significantly better performance (P<.05) with F1 scores of 86.02% and 72.48%, 
respectively.
CONCLUSIONS: We demonstrated that a hybrid model could be used to successfully 
extract family history information recorded in unstructured free-text notes. In 
this study, our approach to entity identification as a sequence labeling problem 
produced satisfactory results. Our postchallenge efforts significantly improved 
performance by leveraging additional labeled data and using word vector 
representations learned from large collections of clinical notes.

©Youngjun Kim, Paul M Heider, Isabel RH Lally, Stéphane M Meystre. Originally 
published in JMIR Medical Informatics (https://medinform.jmir.org), 22.04.2021.

DOI: 10.2196/22797
PMCID: PMC8103307
PMID: 33885370

Conflict of interest statement: Conflicts of Interest: None declared.


43. Appl Clin Inform. 2021 Aug;12(4):897-909. doi: 10.1055/s-0041-1735179. Epub 2021 
Sep 29.

Examining the Concordance in the Documented Pressure Injury Site, Stage, and 
Count in Medical Information Mart for Intensive Care-III.

Zhang W(1), Sotoodeh M(2), Ho JC(2), Simpson RL(1), Hertzberg VS(1).

Author information:
(1)Center for Data Science, Nell Hodgson Woodruff School of Nursing, Emory 
University, Atlanta, Georgia, United States.
(2)Department of Computer Science, College of Arts and Sciences, Emory 
University, Atlanta, Georgia, United States.

OBJECTIVES: This study aimed to compare the concordance of pressure injury (PI) 
site, stage, and count documented in electronic health records (EHRs); explore 
if PI count during each patient hospitalization is consistent based on PI site 
or stage count in the diagnosis or chart event records; and examine if 
discrepancies in PI count were associated with patient characteristics.
METHODS: Hospitalization records with the International Classification of 
Diseases ninth edition (ICD-9) codes, chart events from two systems (CareVue, 
MetaVision), and clinical notes on PI were extracted from the Medical 
Information Mart for Intensive Care (MIMIC)-III database. PI site and stage 
counts from individual hospitalization were computed. Hospitalizations with the 
same or different counts of site and stage according to ICD-9 codes (site and 
stage), CareVue (site and stage), or MetaVision (stage) charts were defined as 
consistent or discrepant reporting. Chi-squared, independent t-, and 
Kruskal-Wallis tests were examined if the count discrepancy was associated with 
patient characteristics. ICD-9 codes and charts were also compared for people 
with one site or stage.
RESULTS: A total of 31,918 hospitalizations had PI data. Within hospitalizations 
with ICD-9-coded sites and stages, 55.9% reported different counts. Within 
hospitalizations with CareVue charts on PI, 99.3% reported the same count. For 
hospitalizations with stages based on ICD-9 codes or MetaVision chart data, only 
42.9% reported the same count. Discrepancies in counts were consistently and 
significantly associated with variables including PI recording in clinical 
notes, dead/hospice at discharge, more caregivers, longer hospitalization or 
intensive care unit stays, and more days to first transfer. Discrepancies 
between ICD-9 code and chart values on the site and stage were also reported.
CONCLUSION: Patient characteristics associated with PI count discrepancies 
identified patients at risk of having discrepant PI counts or worse outcomes. PI 
documentation quality could be improved with better communication, care 
continuity, and integrity. Clinical research using EHRs should adopt systematic 
data quality analysis to inform limitations.

Thieme. All rights reserved.

DOI: 10.1055/s-0041-1735179
PMCID: PMC8481012
PMID: 34587637 [Indexed for MEDLINE]

Conflict of interest statement: None declared.


44. JMIR Med Inform. 2024 Jun 19;12:e50209. doi: 10.2196/50209.

Retrieval-Based Diagnostic Decision Support: Mixed Methods Study.

Abdullahi T(1), Mercurio L(2), Singh R(1)(3), Eickhoff C(4).

Author information:
(1)Department of Computer Science, Brown University, Providence, RI, United 
States.
(2)Departments of Pediatrics & Emergency Medicine, Alpert Medical School, Brown 
University, Providence, RI, United States.
(3)Center for Computational Molecular Biology, Brown University, Providence, RI, 
United States.
(4)School of Medicine, University of Tübingen, Tübingen, Germany.

BACKGROUND: Diagnostic errors pose significant health risks and contribute to 
patient mortality. With the growing accessibility of electronic health records, 
machine learning models offer a promising avenue for enhancing diagnosis 
quality. Current research has primarily focused on a limited set of diseases 
with ample training data, neglecting diagnostic scenarios with limited data 
availability.
OBJECTIVE: This study aims to develop an information retrieval (IR)-based 
framework that accommodates data sparsity to facilitate broader diagnostic 
decision support.
METHODS: We introduced an IR-based diagnostic decision support framework called 
CliniqIR. It uses clinical text records, the Unified Medical Language System 
Metathesaurus, and 33 million PubMed abstracts to classify a broad spectrum of 
diagnoses independent of training data availability. CliniqIR is designed to be 
compatible with any IR framework. Therefore, we implemented it using both dense 
and sparse retrieval approaches. We compared CliniqIR's performance to that of 
pretrained clinical transformer models such as Clinical Bidirectional Encoder 
Representations from Transformers (ClinicalBERT) in supervised and zero-shot 
settings. Subsequently, we combined the strength of supervised fine-tuned 
ClinicalBERT and CliniqIR to build an ensemble framework that delivers 
state-of-the-art diagnostic predictions.
RESULTS: On a complex diagnosis data set (DC3) without any training data, 
CliniqIR models returned the correct diagnosis within their top 3 predictions. 
On the Medical Information Mart for Intensive Care III data set, CliniqIR models 
surpassed ClinicalBERT in predicting diagnoses with <5 training samples by an 
average difference in mean reciprocal rank of 0.10. In a zero-shot setting where 
models received no disease-specific training, CliniqIR still outperformed the 
pretrained transformer models with a greater mean reciprocal rank of at least 
0.10. Furthermore, in most conditions, our ensemble framework surpassed the 
performance of its individual components, demonstrating its enhanced ability to 
make precise diagnostic predictions.
CONCLUSIONS: Our experiments highlight the importance of IR in leveraging 
unstructured knowledge resources to identify infrequently encountered diagnoses. 
In addition, our ensemble framework benefits from combining the complementary 
strengths of the supervised and retrieval-based models to diagnose a broad 
spectrum of diseases.

©Tassallah Abdullahi, Laura Mercurio, Ritambhara Singh, Carsten Eickhoff. 
Originally published in JMIR Medical Informatics (https://medinform.jmir.org), 
19.06.2024.

DOI: 10.2196/50209
PMCID: PMC11222760
PMID: 38896468

Conflict of interest statement: Conflicts of Interest: None declared.


45. J Am Med Inform Assoc. 2020 Mar 1;27(3):407-418. doi: 10.1093/jamia/ocz207.

medExtractR: A targeted, customizable approach to medication extraction from 
electronic health records.

Weeks HL(1), Beck C(1), McNeer E(1), Williams ML(1), Bejan CA(2), Denny JC(3), 
Choi L(1).

Author information:
(1)Department of Biostatistics, Vanderbilt University Medical Center, Nashville, 
Tennessee, USA.
(2)Department of Biomedical Informatics, Vanderbilt University Medical Center, 
Nashville, Tennessee, USA.
(3)Department of Biomedical Informatics, Department of Medicine, Vanderbilt 
University Medical Center, Nashville, Tennessee, USA.

OBJECTIVE: We developed medExtractR, a natural language processing system to 
extract medication information from clinical notes. Using a targeted approach, 
medExtractR focuses on individual drugs to facilitate creation of 
medication-specific research datasets from electronic health records.
MATERIALS AND METHODS: Written using the R programming language, medExtractR 
combines lexicon dictionaries and regular expressions to identify relevant 
medication entities (eg, drug name, strength, frequency). MedExtractR was 
developed on notes from Vanderbilt University Medical Center, using medications 
prescribed with varying complexity. We evaluated medExtractR and compared it 
with 3 existing systems: MedEx, MedXN, and CLAMP (Clinical Language Annotation, 
Modeling, and Processing). We also demonstrated how medExtractR can be easily 
tuned for better performance on an outside dataset using the MIMIC-III (Medical 
Information Mart for Intensive Care III) database.
RESULTS: On 50 test notes per development drug and 110 test notes for an 
additional drug, medExtractR achieved high overall performance (F-measures 
>0.95), exceeding performance of the 3 existing systems across all drugs. 
MedExtractR achieved the highest F-measure for each individual entity, except 
drug name and dose amount for allopurinol. With tuning and customization, 
medExtractR achieved F-measures >0.90 in the MIMIC-III dataset.
DISCUSSION: The medExtractR system successfully extracted entities for 
medications of interest. High performance in entity-level extraction provides a 
strong foundation for developing robust research datasets for pharmacological 
research. When working with new datasets, medExtractR should be tuned on a small 
sample of notes before being broadly applied.
CONCLUSIONS: The medExtractR system achieved high performance extracting 
specific medications from clinical text, leading to higher-quality research 
datasets for drug-related studies than some existing general-purpose medication 
extraction tools.

© The Author(s) 2020. Published by Oxford University Press on behalf of the 
American Medical Informatics Association. All rights reserved. For permissions, 
please email: journals.permissions@oup.com.

DOI: 10.1093/jamia/ocz207
PMCID: PMC7025369
PMID: 31943012 [Indexed for MEDLINE]


46. Front Immunol. 2022 Jul 12;13:925494. doi: 10.3389/fimmu.2022.925494. 
eCollection 2022.

Influence of the Initial Neutrophils to Lymphocytes and Platelets Ratio on the 
Incidence and Severity of Sepsis-Associated Acute Kidney Injury: A Double Robust 
Estimation Based on a Large Public Database.

Xiao W(1)(2), Lu Z(1)(2), Liu Y(3)(4), Hua T(1)(2), Zhang J(1)(2), Hu J(1)(2), 
Li H(1)(2), Xu Y(3)(4), Yang M(1)(2).

Author information:
(1)The 2nd Department of Intensive Care Unit, the Second Affiliated Hospital of 
Anhui Medical University, Hefei, China.
(2)The Laboratory of Cardiopulmonary Resuscitation and Critical Care Medicine, 
The Second Affiliated Hospital of Anhui Medical University, Hefei, China.
(3)Key Laboratory of Intelligent Computing and Signal Processing, Anhui 
University, Ministry of Education, Hefei, China.
(4)School of Integrated Circuits, Anhui University, Hefei, China.

BACKGROUND: Acute kidney injury (AKI) is a frequent consequence of sepsis and 
has been linked to poor prognosis. In critically ill patients, the ratio of 
neutrophils to lymphocytes and platelets (N/LP) has been confirmed as an 
inflammation-related marker connected with the development of renal dysfunction. 
However, the effect of the N/LP ratio on the initiation and development of AKI 
in patients with sepsis remained unclear. The purpose of this study was to 
determine if the N/LP ratio on intensive care unit (ICU) admission was 
associated with the occurrence of sepsis-associated AKI (S-AKI) and severe AKI.
METHODS: Adult septic patients from the Medical Information Mart for Intensive 
Care-IV database were screened and classified into three categories (low, 
middle, or high) based on their N/LP ratio quartiles. The Cox proportional 
hazard and competing risk models were used to determine the risk of S-AKI in 
various N/LP groups, whilst the logistic regression model and restricted cubic 
splines (RCS) analysis were employed to investigate the link between N/LP ratios 
and the occurrence of severe AKI. Finally, we did a doubly robust estimation, a 
subgroup analysis, and a sensitivity analysis to determine the findings' 
robustness.
RESULTS: We categorized 485, 968, and 485 septic patients into three groups 
based on their N/LP ratios: low, intermediate, and high. According the Cox 
proportional hazard model, the hazard rate (95% CI) for those in the middle and 
high N/LP groups on the incidence of S-AKI were 1.30(1.07, 1.58) and 1.27(1.02, 
1.59), respectively, as compared to those in the low N/LP group. And the 
Fine-Gray proportional subdistribution hazards model indicated that mortality 
was not a substantial competing risk for S-AKI. Additionally, multivariate 
logistic regression revealed that the risk of severe AKI increased 1.83 fold in 
the high group compared to the low group. The RCS result also suggested that the 
probability of severe AKI rose significantly when N/LP > 9.5. The consistency of 
these findings was confirmed using doubly robust estimation. However, subgroup 
and sensitivity analyses revealed that the association between N/LP and the 
incidence of S-AKI, severe AKI varied considerably between different populations 
and diagnostic criteria.
CONCLUSION: A raised initial N/LP level may induce the development of S-AKI and 
severe AKI within 7 days after ICU admission in septic patients. These 
influences were enhanced in elder, male, septic shock, and those with poor 
health condition. Furthermore, high NLP was more strongly connected to the risk 
of S-AKI and severe AKI in sepsis patients on the urine output-based AKI 
criteria than on the serum creatinine-based criteria.

Copyright © 2022 Xiao, Lu, Liu, Hua, Zhang, Hu, Li, Xu and Yang.

DOI: 10.3389/fimmu.2022.925494
PMCID: PMC9320191
PMID: 35903103 [Indexed for MEDLINE]

Conflict of interest statement: KS is employed by Daiichi Sankyo Co., Ltd. The 
remaining authors declare that the research was conducted in the absence of any 
commercial or financial relationships that could be construed as a potential 
conflict of interest.


47. BMC Med Inform Decis Mak. 2024 Jul 16;24(1):195. doi: 
10.1186/s12911-024-02573-5.

ARDSFlag: an NLP/machine learning algorithm to visualize and detect 
high-probability ARDS admissions independent of provider recognition and billing 
codes.

Gandomi A(1)(2), Wu P(3), Clement DR(4), Xing J(5), Aviv R(6), Federbush M(4), 
Yuan Z(5), Jing Y(5), Wei G(5), Hajizadeh N(7).

Author information:
(1)Frank G. Zarb School of Business, Hofstra University, Hempstead, NY, USA. 
amir.gandomi@hofstra.edu.
(2)Institute of Health System Science, Feinstein Institute for Medical Research, 
Manhasset, NY, USA. amir.gandomi@hofstra.edu.
(3)AiD Technologies, Stony Brook, NY, USA.
(4)Donald and Barbara Zucker School of Medicine at Hofstra/Northwell, Manhasset, 
NY, USA.
(5)Department of Critical Care Medicine, The Affiliated Hospital of Qingdao 
University, Qingdao, China.
(6)Kaiser Permanente, Oakland, CA, USA.
(7)Institute of Health System Science, Feinstein Institute for Medical Research, 
Manhasset, NY, USA.

BACKGROUND: Despite the significance and prevalence of acute respiratory 
distress syndrome (ARDS), its detection remains highly variable and 
inconsistent. In this work, we aim to develop an algorithm (ARDSFlag) to 
automate the diagnosis of ARDS based on the Berlin definition. We also aim to 
develop a visualization tool that helps clinicians efficiently assess ARDS 
criteria.
METHODS: ARDSFlag applies machine learning (ML) and natural language processing 
(NLP) techniques to evaluate Berlin criteria by incorporating structured and 
unstructured data in an electronic health record (EHR) system. The study cohort 
includes 19,534 ICU admissions in the Medical Information Mart for Intensive 
Care III (MIMIC-III) database. The output is the ARDS diagnosis, onset time, and 
severity.
RESULTS: ARDSFlag includes separate text classifiers trained using large 
training sets to find evidence of bilateral infiltrates in radiology reports 
(accuracy of 91.9%±0.5%) and heart failure/fluid overload in radiology reports 
(accuracy 86.1%±0.5%) and echocardiogram notes (accuracy 98.4%±0.3%). A test set 
of 300 cases, which was blindly and independently labeled for ARDS by two groups 
of clinicians, shows that ARDSFlag generates an overall accuracy of 89.0% 
(specificity = 91.7%, recall = 80.3%, and precision = 75.0%) in detecting ARDS 
cases.
CONCLUSION: To our best knowledge, this is the first study to focus on 
developing a method to automate the detection of ARDS. Some studies have 
developed and used other methods to answer other research questions. Expectedly, 
ARDSFlag generates a significantly higher performance in all accuracy measures 
compared to those methods.

© 2024. The Author(s).

DOI: 10.1186/s12911-024-02573-5
PMCID: PMC11250933
PMID: 39014417 [Indexed for MEDLINE]

Conflict of interest statement: The authors declare no competing interests.


48. Comput Biol Med. 2024 Mar;171:108121. doi: 10.1016/j.compbiomed.2024.108121. 
Epub 2024 Feb 9.

Multi-modal learning for inpatient length of stay prediction.

Chen J(1), Wen Y(2), Pokojovy M(3), Tseng TB(4), McCaffrey P(5), Vo A(5), Walser 
E(5), Moen S(5).

Author information:
(1)Dale E. and Sarah Ann Fowler School of Engineering, Chapman University, 
Orange, CA, 92866, USA.
(2)Dale E. and Sarah Ann Fowler School of Engineering, Chapman University, 
Orange, CA, 92866, USA. Electronic address: yuwen@chapman.edu.
(3)Department of Mathematics and Statistics, Old Dominion University, Norfolk, 
VA, 23529, USA.
(4)Department of Industrial, Manufacturing and Systems Engineering, The 
University of Texas at El Paso, El Paso, TX, 79968, USA.
(5)University of Texas Medical Branch, Galveston, TX, 77550, USA.

Predicting inpatient length of stay (LoS) is important for hospitals aiming to 
improve service efficiency and enhance management capabilities. Patient medical 
records are strongly associated with LoS. However, due to diverse modalities, 
heterogeneity, and complexity of data, it becomes challenging to effectively 
leverage these heterogeneous data to put forth a predictive model that can 
accurately predict LoS. To address the challenge, this study aims to establish a 
novel data-fusion model, termed as DF-Mdl, to integrate heterogeneous clinical 
data for predicting the LoS of inpatients between hospital discharge and 
admission. Multi-modal data such as demographic data, clinical notes, laboratory 
test results, and medical images are utilized in our proposed methodology with 
individual "basic" sub-models separately applied to each different data 
modality. Specifically, a convolutional neural network (CNN) model, which we 
termed CRXMDL, is designed for chest X-ray (CXR) image data, two long short-term 
memory networks are used to extract features from long text data, and a novel 
attention-embedded 1D convolutional neural network is developed to extract 
useful information from numerical data. Finally, these basic models are 
integrated to form a new data-fusion model (DF-Mdl) for inpatient LoS 
prediction. The proposed method attains the best R2 and EVAR values of 0.6039 
and 0.6042 among competitors for the LoS prediction on the Medical Information 
Mart for Intensive Care (MIMIC)-IV test dataset. Empirical evidence suggests 
better performance compared with other state-of-the-art (SOTA) methods, which 
demonstrates the effectiveness and feasibility of the proposed approach.

Copyright © 2024 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.compbiomed.2024.108121
PMID: 38382388 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of competing interest On behalf of 
all authors, the corresponding author states that there is no conflict of 
interest.


49. Int J Med Inform. 2025 Apr;196:105815. doi: 10.1016/j.ijmedinf.2025.105815. Epub 
2025 Feb 4.

Multimodal convolutional neural networks for the prediction of acute kidney 
injury in the intensive care.

van Slobbe R(1), Herrmannova D(2), Boeke DJ(2), Lima-Walton ES(2), Abu-Hanna 
A(3), Vagliano I(4).

Author information:
(1)Vrij Univeriteit, Amsterdam, the Netherlands.
(2)Elsevier B.V., Amsterdam, the Netherlands.
(3)Department of Medical Informatics, Amsterdam UMC, University of Amsterdam, 
Amsterdam, the Netherlands; Amsterdam Public Health research institute, 
Amsterdam, the Netherlands.
(4)Department of Medical Informatics, Amsterdam UMC, University of Amsterdam, 
Amsterdam, the Netherlands; Amsterdam Public Health research institute, 
Amsterdam, the Netherlands. Electronic address: i.vagliano@amsterdamumc.nl.

Increased monitoring of health-related data for ICU patients holds great 
potential for the early prediction of medical outcomes. Research on whether the 
use of clinical notes and concepts from knowledge bases can improve the 
performance of prediction models is limited. We investigated the effects of 
combining clinical variables, clinical notes, and clinical concepts. We focus on 
the early prediction of Acute Kidney Injury (AKI) in the intensive care unit 
(ICU). AKI is a sudden reduction in kidney function measured by increased serum 
creatinine (SCr) or decreased urine output. AKI may occur in up to 30% of ICU 
stays. We developed three models based on convolutional neural networks using 
data from the Medical Information Mart for Intensive Care (MIMIC) database. The 
models used clinical variables, free-text notes, and concepts from the Elsevier 
H-Graph. Our models achieved good predictive performance (AUROC 0.73-0.90). 
These models were assessed both when using Scr and urine output as predictors 
and when omitting them. When Scr and urine output were used as predictors, 
models that included clinical notes and concepts together with clinical 
variables performed on par with models that only used clinical variables. When 
excluding SCr and urine output, predictive performance improved by combining 
multiple modalities. The models that used only clinical variables were 
externally validated on the eICU dataset and transported fairly to the new 
population (AUROC 0.68-0.77). Our in-depth comparison of modalities and text 
representations may further guide researchers and practitioners in applying 
multimodal models for predicting AKI and inspire them to investigate 
multimodality and contextualized embeddings for other tasks. Our models can 
support clinicians to promptly recognize and treat deteriorating AKI patients 
and may improve patient outcomes in the ICU.

Copyright © 2025 The Author(s). Published by Elsevier B.V. All rights reserved.

DOI: 10.1016/j.ijmedinf.2025.105815
PMID: 39914070 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare that they have no conflict of interest.


50. J Am Med Inform Assoc. 2025 Feb 1;32(2):365-374. doi: 10.1093/jamia/ocae310.

CARE-SD: classifier-based analysis for recognizing provider stigmatizing and 
doubt marker labels in electronic health records: model development and 
validation.

Walker A(1), Thorne A(2), Das S(1), Love J(3), Cooper HLF(4), Livingston M 
3rd(4), Sarker A(1)(5).

Author information:
(1)Department of Biomedical Informatics, School of Medicine, Emory University, 
Atlanta, GA 30322, United States.
(2)Department of Infectious Disease, Children's Healthcare of Atlanta, Atlanta, 
GA 30329, United States.
(3)Department of Emergency Medicine, Mount Sinai, New York, NY 10029, United 
States.
(4)Department of Behavioral, Social, Health Education Sciences, Rollins School 
of Public Health, Emory University, Atlanta, GA 30322, United States.
(5)Department of Biomedical Engineering, Georgia Institute of Technology and 
Emory University, Atlanta, GA 30332, United States.

OBJECTIVE: To detect and classify features of stigmatizing and biased language 
in intensive care electronic health records (EHRs) using natural language 
processing techniques.
MATERIALS AND METHODS: We first created a lexicon and regular expression lists 
from literature-driven stem words for linguistic features of stigmatizing 
patient labels, doubt markers, and scare quotes within EHRs. The lexicon was 
further extended using Word2Vec and GPT 3.5, and refined through human 
evaluation. These lexicons were used to search for matches across 18 million 
sentences from the de-identified Medical Information Mart for Intensive Care-III 
(MIMIC-III) dataset. For each linguistic bias feature, 1000 sentence matches 
were sampled, labeled by expert clinical and public health annotators, and used 
to supervised learning classifiers.
RESULTS: Lexicon development from expanded literature stem-word lists resulted 
in a doubt marker lexicon containing 58 expressions, and a stigmatizing labels 
lexicon containing 127 expressions. Classifiers for doubt markers and 
stigmatizing labels had the highest performance, with macro F1-scores of 0.84 
and 0.79, positive-label recall and precision values ranging from 0.71 to 0.86, 
and accuracies aligning closely with human annotator agreement (0.87).
DISCUSSION: This study demonstrated the feasibility of supervised classifiers in 
automatically identifying stigmatizing labels and doubt markers in medical text 
and identified trends in stigmatizing language use in an EHR setting. Additional 
labeled data may help improve lower scare quote model performance.
CONCLUSIONS: Classifiers developed in this study showed high model performance 
and can be applied to identify patterns and target interventions to reduce 
stigmatizing labels and doubt markers in healthcare systems.

© The Author(s) 2024. Published by Oxford University Press on behalf of the 
American Medical Informatics Association.

DOI: 10.1093/jamia/ocae310
PMCID: PMC11756621
PMID: 39724920 [Indexed for MEDLINE]

Conflict of interest statement: The authors have no competing interests to 
share.


51. Comput Cardiol (2010). 2015 Sep;2015:629-632. doi: 10.1109/CIC.2015.7410989. 
Epub 2016 Feb 18.

A Visualization of Evolving Clinical Sentiment Using Vector Representations of 
Clinical Notes.

Ghassemi MM(1), Mark RG(1), Nemati S(2).

Author information:
(1)Department of Electrical Engineering and Computer Science at the 
Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, MA 
02139, USA.
(2)Department of Biomedical Informatics at Emory University, Atlanta, GA 30322, 
USA.

Our objective in this paper was to visualize the evolution of clinical language 
and sentiment with respect to several common population-level categories 
including: time in the hospital, age, mortality, gender and race. Our analysis 
utilized seven years of unstructured free text notes from the Multiparameter 
Intelligent Monitoring in Intensive Care (MIMIC) database. The text data was 
partitioned by category and used to generate several high dimensional vector 
space representations. We generated visualizations of the vector spaces using 
Distributed Stochastic Neighbor Embedding (tSNE) and Principal Component 
Analysis (PCA). We also investigated representative words from clusters in the 
vector space. Lastly, we inferred the general sentiment of the clinical notes 
toward each parameter by gauging the average distance between positive and 
negative keywords and all other terms in the space. We found intriguing 
differences in the sentiment of clinical notes over time, outcome, and 
demographic features. We noted a decrease in the homogeneity and complexity of 
clusters over time for patients with poor outcomes. We also found greater 
positive sentiment for females, unmarried patients, and patients of African 
ethnicity.

DOI: 10.1109/CIC.2015.7410989
PMCID: PMC5070922
PMID: 27774487


52. medRxiv [Preprint]. 2024 Mar 15:2024.03.14.24304230. doi: 
10.1101/2024.03.14.24304230.

Forecasting Acute Kidney Injury and Resource Utilization in ICU patients using 
longitudinal, multimodal models.

Tan Y(1), Dede M(1), Mohanty V(1), Dou J(1), Hill H(2), Bernstam E(3)(4), Chen 
K(1).

Author information:
(1)Department of Bioinformatics and Computational Biology, The University of 
Texas MD Anderson Cancer Center.
(2)Division of Pathology and Laboratory Medicine, Molecular Diagnostic 
Laboratory, The University of Texas MD Anderson Cancer Center.
(3)D. Bradley McWilliams School of Biomedical Informatics, The University of 
Texas Health Science Center at Houston.
(4)Division of General Internal Medicine, McGovern Medical School, The 
University of Texas Health Science Center at Houston.

Update in
    J Biomed Inform. 2024 Jun;154:104648. doi: 10.1016/j.jbi.2024.104648.

BACKGROUND: Advances in artificial intelligence (AI) have realized the potential 
of revolutionizing healthcare, such as predicting disease progression via 
longitudinal inspection of Electronic Health Records (EHRs) and lab tests from 
patients admitted to Intensive Care Units (ICU). Although substantial literature 
exists addressing broad subjects, including the prediction of mortality, 
length-of-stay, and readmission, studies focusing on forecasting Acute Kidney 
Injury (AKI), specifically dialysis anticipation like Continuous Renal 
Replacement Therapy (CRRT) are scarce. The technicality of how to implement AI 
remains elusive.
OBJECTIVE: This study aims to elucidate the important factors and methods that 
are required to develop effective predictive models of AKI and CRRT for patients 
admitted to ICU, using EHRs in the Medical Information Mart for Intensive Care 
(MIMIC) database.
METHODS: We conducted a comprehensive comparative analysis of established 
predictive models, considering both time-series measurements and clinical notes 
from MIMIC-IV databases. Subsequently, we proposed a novel multi-modal model 
which integrates embeddings of top-performing unimodal models, including Long 
Short-Term Memory (LSTM) and BioMedBERT, and leverages both unstructured 
clinical notes and structured time series measurements derived from EHRs to 
enable the early prediction of AKI and CRRT.
RESULTS: Our multimodal model achieved a lead time of at least 12 hours ahead of 
clinical manifestation, with an Area Under the Receiver Operating Characteristic 
Curve (AUROC) of 0.888 for AKI and 0.997 for CRRT, as well as an Area Under the 
Precision Recall Curve (AUPRC) of 0.727 for AKI and 0.840 for CRRT, 
respectively, which significantly outperformed the baseline models. 
Additionally, we performed a SHapley Additive exPlanation (SHAP) analysis using 
the expected gradients algorithm, which highlighted important, previously 
underappreciated predictive features for AKI and CRRT.
CONCLUSION: Our study revealed the importance and the technicality of applying 
longitudinal, multimodal modeling to improve early prediction of AKI and CRRT, 
offering insights for timely interventions. The performance and interpretability 
of our model indicate its potential for further assessment towards clinical 
applications, to ultimately optimize AKI management and enhance patient 
outcomes.

DOI: 10.1101/2024.03.14.24304230
PMCID: PMC10980131
PMID: 38559064

Conflict of interest statement: Declaration of competing interest The authors 
declare that they have no known competing financial interests or personal 
relationships that could have appeared to influence the work reported in this 
paper.


53. JMIR Med Inform. 2024 Oct 28;12:e54246. doi: 10.2196/54246.

A New Natural Language Processing-Inspired Methodology (Detection, Initial 
Characterization, and Semantic Characterization) to Investigate Temporal Shifts 
(Drifts) in Health Care Data: Quantitative Study.

Paiva B(1), Gonçalves MA(1), da Rocha LCD(2), Marcolino MS(3), Lana FCB(3), 
Souza-Silva MVR(3), Almeida JM(1), Pereira PD(3), de Andrade CMV(1), Gomes 
AGDR(4), Ferreira MAP(5), Bartolazzi F(6), Sacioto MF(7), Boscato AP(8), 
Guimarães-Júnior MH(9), Dos Reis PP(10), Costa FR(3), Jorge AO(11), Coelho 
LR(12), Carneiro M(13), Sales TLS(1), Araújo SF(14), Silveira DV(15), Ruschel 
KB(1), Santos FCV(16), Cenci EPA(17), Menezes LSM(1), Anschau F(18), Bicalho 
MAC(19), Manenti ERF(20), Finger RG(21), Ponce D(22), de Aguiar FC(23), Marques 
LM(7), de Castro LC(24), Vietta GG(25), Godoy MF(6), Vilaça MDN(26), Morais 
VC(7).

Author information:
(1)Computer Science Department, Universidade Federal de Minas Gerais, Belo 
Horizonte, Brazil, Belo Horizonte, Brazil.
(2)Computer Science Department, Universidade Federal de São João del-Rei, 
Brazil, São João del-Rei, Brazil.
(3)Faculdade de Medicina, Universidade Federal de Minas Gerais, Belo Horizonte, 
Brazil, Belo Horizonte, Brazil.
(4)Hospitais da Rede Mater Dei, Belo Horizonte, Brazil.
(5)Hospital de Clínicas de Porto Alegre, Porto Alegre, Brazil.
(6)Hospital Santo Antônio, Curvelo, Brazil.
(7)Faculdade Ciências Médicas de Minas Gerais, Belo Horizonte, Brazil.
(8)Hospital Tacchini, Bento Gonçalves, Brazil.
(9)Hospital Márcio Cunha, Ipatinga, Brazil.
(10)Hospital Metropolitano Doutor Célio de Castro, Belo Horizonte, Brazil.
(11)Hospital Risoleta Tolentino Neves, Belo Horizonte, Brazil.
(12)Faculdade de Medicina, Universidade Federal dos Vales do Jequitinhonha e 
Mucuri, Teófilo Otoni, Brazil.
(13)Hospital Santa Cruz, Santa Cruz do Sul, Brazil.
(14)Hospital Semper, Belo Horizonte, Brazil.
(15)Hospital Unimed BH, Belo Horizonte, Brazil.
(16)Hospital Universitário de Santa Maria, Santa Maria, Brazil.
(17)Hospital Moinhos de Vento, Porto Alegre, Brazil.
(18)Hospital Nossa Senhora da Conceição, Porto Alegre, Brazil.
(19)Fundação Hospitalar do Estado de Minas Gerais, Belo Horizonte, Brazil.
(20)Hospital Mãe de Deus, Porto Alegre, Brazil.
(21)Hospital Regional do Oeste, Chapecó, Brazil.
(22)Faculdade de Medicina de Botucatu, Universidade Estadual Paulista Júlio de 
Mesquita Filho, Botucatu, Brazil.
(23)Hospital das Clínicas, Universidade Federal de Pernambuco, Recife, Brazil.
(24)Hospital Bruno Born, Lajeado, Brazil.
(25)Hospital SOS Cárdio, Florianópolis, Brazil.
(26)Hospital Metropolitano Odilon Behrens, Belo Horizonte, Brazil.

BACKGROUND: Proper analysis and interpretation of health care data can 
significantly improve patient outcomes by enhancing services and revealing the 
impacts of new technologies and treatments. Understanding the substantial impact 
of temporal shifts in these data is crucial. For example, COVID-19 vaccination 
initially lowered the mean age of at-risk patients and later changed the 
characteristics of those who died. This highlights the importance of 
understanding these shifts for assessing factors that affect patient outcomes.
OBJECTIVE: This study aims to propose detection, initial characterization, and 
semantic characterization (DIS), a new methodology for analyzing changes in 
health outcomes and variables over time while discovering contextual changes for 
outcomes in large volumes of data.
METHODS: The DIS methodology involves 3 steps: detection, initial 
characterization, and semantic characterization. Detection uses metrics such as 
Jensen-Shannon divergence to identify significant data drifts. Initial 
characterization offers a global analysis of changes in data distribution and 
predictive feature significance over time. Semantic characterization uses 
natural language processing-inspired techniques to understand the local context 
of these changes, helping identify factors driving changes in patient outcomes. 
By integrating the outcomes from these 3 steps, our results can identify 
specific factors (eg, interventions and modifications in health care practices) 
that drive changes in patient outcomes. DIS was applied to the Brazilian 
COVID-19 Registry and the Medical Information Mart for Intensive Care, version 
IV (MIMIC-IV) data sets.
RESULTS: Our approach allowed us to (1) identify drifts effectively, especially 
using metrics such as the Jensen-Shannon divergence, and (2) uncover reasons for 
the decline in overall mortality in both the COVID-19 and MIMIC-IV data sets, as 
well as changes in the cooccurrence between different diseases and this 
particular outcome. Factors such as vaccination during the COVID-19 pandemic and 
reduced iatrogenic events and cancer-related deaths in MIMIC-IV were 
highlighted. The methodology also pinpointed shifts in patient demographics and 
disease patterns, providing insights into the evolving health care landscape 
during the study period.
CONCLUSIONS: We developed a novel methodology combining machine learning and 
natural language processing techniques to detect, characterize, and understand 
temporal shifts in health care data. This understanding can enhance predictive 
algorithms, improve patient outcomes, and optimize health care resource 
allocation, ultimately improving the effectiveness of machine learning 
predictive algorithms applied to health care data. Our methodology can be 
applied to a variety of scenarios beyond those discussed in this paper.

©Bruno Paiva, Marcos André Gonçalves, Leonardo Chaves Dutra da Rocha, Milena 
Soriano Marcolino, Fernanda Cristina Barbosa Lana, Maira Viana Rego Souza-Silva, 
Jussara M Almeida, Polianna Delfino Pereira, Claudio Moisés Valiense de Andrade, 
Angélica Gomides dos Reis Gomes, Maria Angélica Pires Ferreira, Frederico 
Bartolazzi, Manuela Furtado Sacioto, Ana Paula Boscato, Milton Henriques 
Guimarães-Júnior, Priscilla Pereira dos Reis, Felício Roberto Costa, Alzira de 
Oliveira Jorge, Laryssa Reis Coelho, Marcelo Carneiro, Thaís Lorenna Souza 
Sales, Silvia Ferreira Araújo, Daniel Vitório Silveira, Karen Brasil Ruschel, 
Fernanda Caldeira Veloso Santos, Evelin Paola de Almeida Cenci, Luanna Silva 
Monteiro Menezes, Fernando Anschau, Maria Aparecida Camargos Bicalho, Euler 
Roberto Fernandes Manenti, Renan Goulart Finger, Daniela Ponce, Filipe Carrilho 
de Aguiar, Luiza Margoto Marques, Luís César de Castro, Giovanna Grünewald 
Vietta, Mariana Frizzo de Godoy, Mariana do Nascimento Vilaça, Vivian Costa 
Morais. Originally published in JMIR Medical Informatics 
(https://medinform.jmir.org), 28.10.2024.

DOI: 10.2196/54246
PMCID: PMC11555458
PMID: 39467275 [Indexed for MEDLINE]

Conflict of interest statement: Conflicts of Interest: None declared.


54. EGEMS (Wash DC). 2018 Sep 20;6(1):21. doi: 10.5334/egems.237.

What Can We Learn about Fall Risk Factors from EHR Nursing Notes? A Text Mining 
Study.

Bjarnadottir RI(1), Lucero RJ(1).

Author information:
(1)University of Florida, US.

INTRODUCTION: Hospital falls are a continuing clinical concern, with over one 
million falls occurring each year in the United States. Annually, 
hospital-acquired falls result in an estimated $34 billion in direct medical 
costs. Falls are considered largely preventable and, as a result, the Centers 
for Medicare and Medicaid Services have announced that fall-related injuries are 
no longer a reimbursable hospital cost. While policies and practices have been 
implemented to reduce falls, little sustained reduction has been achieved. 
Little empirical evidence supports the validity of published fall risk factors. 
While chart abstraction has been used to operationalize risk factors, few 
studies have examined registered nurses' (RNs') narrative notes as a source of 
actionable data. Therefore, the purpose of our study was to explore whether 
there is meaningful fall risk and prevention information in RNs' electronic 
narrative notes.
METHODS: This study utilized a natural language processing design. Data for this 
study were extracted from the publicly available Medical Information Mart for 
Intensive Care (MIMIC-III) database. The date comprises deidentified EHR data 
associated with patients who stayed in critical care units between 2001 and 
2012. Text mining procedures were performed on RN's narrative notes following 
the traditional steps of knowledge discovery.
RESULTS: The corpus of data extracted from MIMIC-III database was comprised of 
1,046,053 RNs' notes from 36,583 unique patients. We identified 3,972 notes (0.4 
percent) representing 1,789 (5 percent) patients with explicit documentation 
related to fall risk/prevention. Around 10 percent of the notes (103,685) from 
23,025 patients mentioned intrinsic (patient-related) factors that have been 
theoretically associated with risk of falling. An additional 1,322 notes (0.1 
percent) from 692 patients (2 percent) mentioned extrinsic risk factors, related 
to organizational design and environment. Moreover, 7672 notes (0.7 percent) 
from 2,571 patients (7 percent) included information on interventions that could 
theoretically impact patient falls.
CONCLUSIONS: This exploratory study using a NLP approach revealed that 
meaningful information related to fall risk and prevention may be found in RNs' 
narrative notes. In particular, RNs' notes can contain information about 
clinical as well as environmental and organizational factors that could affect 
fall risk but are not explicitly recorded by the provider as a fall risk 
factors. In our study, potential fall risk factors were documented for more than 
half of the sample. Further research is needed to determine the predictive value 
of these factors.
IMPLICATIONS FOR POLICY OR PRACTICE: This study highlights a potentially rich 
but understudied source of actionable fall risk data. Furthermore, the 
application of novel methods to identify quality and safety measures in RNs' 
notes can facilitate inclusion of RNs' voices in patient outcomes and health 
services research.

DOI: 10.5334/egems.237
PMCID: PMC6157016
PMID: 30263902


55. Stud Health Technol Inform. 2024 Aug 22;316:1008-1012. doi: 10.3233/SHTI240580.

What Kind of Transformer Models to Use for the ICD-10 Codes Classification Task.

Mansour M(1), Yilmaz F(1), Miletic M(1), Sariyar M(1).

Author information:
(1)Bern University of Applied Sciences, Switzerland.

Coding according to the International Classification of Diseases (ICD)-10 and 
its clinical modifications (CM) is inherently complex and expensive. Natural 
Language Processing (NLP) assists by simplifying the analysis of unstructured 
data from electronic health records, thereby facilitating diagnosis coding. This 
study investigates the suitability of transformer models for ICD-10 
classification, considering both encoder and encoder-decoder architectures. The 
analysis is performed on clinical discharge summaries from the Medical 
Information Mart for Intensive Care (MIMIC)-IV dataset, which contains an 
extensive collection of electronic health records. Pre-trained models such as 
BioBERT, ClinicalBERT, ClinicalLongformer, and ClinicalBigBird are adapted for 
the coding task, incorporating specific preprocessing techniques to enhance 
performance. The findings indicate that increasing context length improves 
accuracy, and that the difference in accuracy between encoder and 
encoder-decoder models is negligible.

DOI: 10.3233/SHTI240580
PMID: 39176961 [Indexed for MEDLINE]


56. Acad Radiol. 2024 Dec;31(12):4823-4832. doi: 10.1016/j.acra.2024.07.020. Epub 
2024 Aug 13.

Practical Evaluation of ChatGPT Performance for Radiology Report Generation.

Soleimani M(1), Seyyedi N(2), Ayyoubzadeh SM(3), Kalhori SRN(4), Keshavarz H(5).

Author information:
(1)Department of Health Information Management and Medical Informatics, School 
of Allied Medical Sciences, Tehran University of Medical Sciences, Tehran, Iran.
(2)Department of Health Information Management and Medical Informatics, School 
of Allied Medical Sciences, Tehran University of Medical Sciences, Tehran, Iran. 
Electronic address: n-seyyedi@razi.tums.ac.ir.
(3)Department of Health Information Management and Medical Informatics, School 
of Allied Medical Sciences, Tehran University of Medical Sciences, Tehran, Iran; 
Health Information Management Research Centre, Tehran University of Medical 
Sciences, Tehran, Iran.
(4)Department of Health Information Management and Medical Informatics, School 
of Allied Medical Sciences, Tehran University of Medical Sciences, Tehran, Iran; 
Peter L. Reichertz Institute for Medical Informatics, TU Braunschweig and 
Hannover Medical School, Braunschweig, Germany.
(5)Faculty of Electrical and Computer Engineering, Tarbiat Modares University, 
Tehran, Iran.

RATIONALE AND OBJECTIVES: The process of generating radiology reports is often 
time-consuming and labor-intensive, prone to incompleteness, heterogeneity, and 
errors. By employing natural language processing (NLP)-based techniques, this 
study explores the potential for enhancing the efficiency of radiology report 
generation through the remarkable capabilities of ChatGPT (Generative 
Pre-training Transformer), a prominent large language model (LLM).
MATERIALS AND METHODS: Using a sample of 1000 records from the Medical 
Information Mart for Intensive Care (MIMIC) Chest X-ray Database, this 
investigation employed Claude.ai to extract initial radiological report 
keywords. ChatGPT then generated radiology reports using a consistent 3-step 
prompt template outline. Various lexical and sentence similarity techniques were 
employed to evaluate the correspondence between the AI assistant-generated 
reports and reference reports authored by medical professionals.
RESULTS: Results showed varying performance among NLP models, with Bart 
(Bidirectional and Auto-Regressive Transformers) and XLM (Cross-lingual Language 
Model) displaying high proficiency (mean similarity scores up to 99.3%), closely 
mirroring physician reports. Conversely, DeBERTa (Decoding-enhanced BERT with 
disentangled attention) and sequence-matching models scored lower, indicating 
less alignment with medical language. In the Impression section, the 
Word-Embedding model excelled with a mean similarity of 84.4%, while others like 
the Jaccard index showed lower performance.
CONCLUSION: Overall, the study highlights significant variations across NLP 
models in their ability to generate radiology reports consistent with medical 
professionals' language. Pairwise comparisons and Kruskal-Wallis tests confirmed 
these differences, emphasizing the need for careful selection and evaluation of 
NLP models in radiology report generation. This research underscores the 
potential of ChatGPT to streamline and improve the radiology reporting process, 
with implications for enhancing efficiency and accuracy in clinical practice.

Copyright © 2024 The Association of University Radiologists. Published by 
Elsevier Inc. All rights reserved.

DOI: 10.1016/j.acra.2024.07.020
PMID: 39142976 [Indexed for MEDLINE]

Conflict of interest statement: Declaration of Competing Interest The authors 
declare that they have no known competing financial interests or personal 
relationships that could have appeared to influence the work reported in this 
paper.


57. JMIR Form Res. 2024 Jul 10;8:e54044. doi: 10.2196/54044.

Predictive Model for Extended-Spectrum β-Lactamase-Producing Bacterial 
Infections Using Natural Language Processing Technique and Open Data in 
Intensive Care Unit Environment: Retrospective Observational Study.

Ito G(1), Yada S(1), Wakamiya S(1), Aramaki E(1).

Author information:
(1)Department of Information Science, Nara Institute of Science and Technology, 
Ikoma City, Japan.

BACKGROUND: Machine learning has advanced medical event prediction, mostly using 
private data. The public MIMIC-3 (Medical Information Mart for Intensive Care 
III) data set, which contains detailed data on over 40,000 intensive care unit 
patients, stands out as it can help develop better models including structured 
and textual data.
OBJECTIVE: This study aimed to build and test a machine learning model using the 
MIMIC-3 data set to determine the effectiveness of information extracted from 
electronic medical record text using a named entity recognition, specifically 
QuickUMLS, for predicting important medical events. Using the prediction of 
extended-spectrum β-lactamase (ESBL)-producing bacterial infections as an 
example, this study shows how open data sources and simple technology can be 
useful for making clinically meaningful predictions.
METHODS: The MIMIC-3 data set, including demographics, vital signs, laboratory 
results, and textual data, such as discharge summaries, was used. This study 
specifically targeted patients diagnosed with Klebsiella pneumoniae or 
Escherichia coli infection. Predictions were based on ESBL-producing bacterial 
standards and the minimum inhibitory concentration criteria. Both the structured 
data and extracted patient histories were used as predictors. In total, 2 
models, an L1-regularized logistic regression model and a LightGBM model, were 
evaluated using the receiver operating characteristic area under the curve 
(ROC-AUC) and the precision-recall curve area under the curve (PR-AUC).
RESULTS: Of 46,520 MIMIC-3 patients, 4046 were identified with bacterial 
cultures, indicating the presence of K pneumoniae or E coli. After excluding 
patients who lacked discharge summary text, 3614 patients remained. The 
L1-penalized model, with variables from only the structured data, displayed a 
ROC-AUC of 0.646 and a PR-AUC of 0.307. The LightGBM model, combining structured 
and textual data, achieved a ROC-AUC of 0.707 and a PR-AUC of 0.369. Key 
contributors to the LightGBM model included patient age, duration since hospital 
admission, and specific medical history such as diabetes. The structured 
data-based model showed improved performance compared to the reference models. 
Performance was further improved when textual medical history was included. 
Compared to other models predicting drug-resistant bacteria, the results of this 
study ranked in the middle. Some misidentifications, potentially due to the 
limitations of QuickUMLS, may have affected the accuracy of the model.
CONCLUSIONS: This study successfully developed a predictive model for 
ESBL-producing bacterial infections using the MIMIC-3 data set, yielding results 
consistent with existing literature. This model stands out for its transparency 
and reliance on open data and open-named entity recognition technology. The 
performance of the model was enhanced using textual information. With 
advancements in natural language processing tools such as BERT and GPT, the 
extraction of medical data from text holds substantial potential for future 
model optimization.

©Genta Ito, Shuntaro Yada, Shoko Wakamiya, Eiji Aramaki. Originally published in 
JMIR Formative Research (https://formative.jmir.org), 10.07.2024.

DOI: 10.2196/54044
PMCID: PMC11269962
PMID: 38986131

Conflict of interest statement: Conflicts of Interest: GI is an employee at 
Shionogi & Co. There was no involvement of Shionogi & Co in the publication 
process. The other authors declare no conflicts of interest.


58. J Am Med Inform Assoc. 2018 May 1;25(5):530-537. doi: 10.1093/jamia/ocx160.

SemEHR: A general-purpose semantic search system to surface semantic data from 
clinical notes for tailored care, trial recruitment, and clinical research.

Wu H(1)(2), Toti G(3), Morley KI(3)(4), Ibrahim ZM(1)(5), Folarin A(1)(5), 
Jackson R(1), Kartoglu I(6), Agrawal A(7), Stringer C(7), Gale D(7), Gorrell 
G(8), Roberts A(8), Broadbent M(9), Stewart R(9)(10), Dobson RJB(1)(5).

Author information:
(1)Department of Biostatistics and Health Informatics, Institute of Psychiatry, 
Psychology and Neuroscience, King's College London, London, UK.
(2)School of Computer and Software, Nanjing University of Information Science 
and Technology, Nanjing, China.
(3)National Addiction Centre, Institute of Psychiatry, Psychology and 
Neuroscience, King's College London, London, UK.
(4)Centre for Epidemiology and Biostatistics, Melbourne School of Population and 
Global Health, University of Melbourne, Australia.
(5)Farr Institute of Health Informatics Research, University College London, 
London, UK.
(6)InterDigital Europe, London, UK.
(7)King's College Hospital NHS Foundation Trust, London, UK.
(8)Department of Computer Science, University of Sheffield, Sheffield, UK.
(9)South London and Maudsley NHS Foundation Trust, London, UK.
(10)Psychological Medicine, Institute of Psychiatry, Psychology and 
Neuroscience, King's College London, London, UK.

OBJECTIVE: Unlocking the data contained within both structured and unstructured 
components of electronic health records (EHRs) has the potential to provide a 
step change in data available for secondary research use, generation of 
actionable medical insights, hospital management, and trial recruitment. To 
achieve this, we implemented SemEHR, an open source semantic search and 
analytics tool for EHRs.
METHODS: SemEHR implements a generic information extraction (IE) and retrieval 
infrastructure by identifying contextualized mentions of a wide range of 
biomedical concepts within EHRs. Natural language processing annotations are 
further assembled at the patient level and extended with EHR-specific knowledge 
to generate a timeline for each patient. The semantic data are serviced via 
ontology-based search and analytics interfaces.
RESULTS: SemEHR has been deployed at a number of UK hospitals, including the 
Clinical Record Interactive Search, an anonymized replica of the EHR of the UK 
South London and Maudsley National Health Service Foundation Trust, one of 
Europe's largest providers of mental health services. In 2 Clinical Record 
Interactive Search-based studies, SemEHR achieved 93% (hepatitis C) and 99% 
(HIV) F-measure results in identifying true positive patients. At King's College 
Hospital in London, as part of the CogStack program (github.com/cogstack), 
SemEHR is being used to recruit patients into the UK Department of Health 
100 000 Genomes Project (genomicsengland.co.uk). The validation study suggests 
that the tool can validate previously recruited cases and is very fast at 
searching phenotypes; time for recruitment criteria checking was reduced from 
days to minutes. Validated on open intensive care EHR data, Medical Information 
Mart for Intensive Care III, the vital signs extracted by SemEHR can achieve 
around 97% accuracy.
CONCLUSION: Results from the multiple case studies demonstrate SemEHR's 
efficiency: weeks or months of work can be done within hours or minutes in some 
cases. SemEHR provides a more comprehensive view of patients, bringing in more 
and unexpected insight compared to study-oriented bespoke IE systems. SemEHR is 
open source, available at https://github.com/CogStack/SemEHR.

DOI: 10.1093/jamia/ocx160
PMCID: PMC6019046
PMID: 29361077 [Indexed for MEDLINE]


59. JMIR Med Inform. 2020 Jul 10;8(7):e18417. doi: 10.2196/18417.

Extraction of Information Related to Drug Safety Surveillance From Electronic 
Health Record Notes: Joint Modeling of Entities and Relations Using 
Knowledge-Aware Neural Attentive Models.

Dandala B(1), Joopudi V(1), Tsou CH(1), Liang JJ(1), Suryanarayanan P(1).

Author information:
(1)IBM Research, Yorktown Heights, NY, United States.

BACKGROUND: An adverse drug event (ADE) is commonly defined as "an injury 
resulting from medical intervention related to a drug." Providing information 
related to ADEs and alerting caregivers at the point of care can reduce the risk 
of prescription and diagnostic errors and improve health outcomes. ADEs captured 
in structured data in electronic health records (EHRs) as either coded problems 
or allergies are often incomplete, leading to underreporting. Therefore, it is 
important to develop capabilities to process unstructured EHR data in the form 
of clinical notes, which contain a richer documentation of a patient's ADE. 
Several natural language processing (NLP) systems have been proposed to 
automatically extract information related to ADEs. However, the results from 
these systems showed that significant improvement is still required for the 
automatic extraction of ADEs from clinical notes.
OBJECTIVE: This study aims to improve the automatic extraction of ADEs and 
related information such as drugs, their attributes, and reason for 
administration from the clinical notes of patients.
METHODS: This research was conducted using discharge summaries from the Medical 
Information Mart for Intensive Care III (MIMIC-III) database obtained through 
the 2018 National NLP Clinical Challenges (n2c2) annotated with drugs, drug 
attributes (ie, strength, form, frequency, route, dosage, duration), ADEs, 
reasons, and relations between drugs and other entities. We developed a deep 
learning-based system for extracting these drug-centric concepts and relations 
simultaneously using a joint method enhanced with contextualized embeddings, a 
position-attention mechanism, and knowledge representations. The joint method 
generated different sentence representations for each drug, which were then used 
to extract related concepts and relations simultaneously. Contextualized 
representations trained on the MIMIC-III database were used to capture 
context-sensitive meanings of words. The position-attention mechanism amplified 
the benefits of the joint method by generating sentence representations that 
capture long-distance relations. Knowledge representations were obtained from 
graph embeddings created using the US Food and Drug Administration Adverse Event 
Reporting System database to improve relation extraction, especially when 
contextual clues were insufficient.
RESULTS: Our system achieved new state-of-the-art results on the n2c2 data set, 
with significant improvements in recognizing crucial drug-reason (F1=0.650 
versus F1=0.579) and drug-ADE (F1=0.490 versus F1=0.476) relations.
CONCLUSIONS: This study presents a system for extracting drug-centric concepts 
and relations that outperformed current state-of-the-art results and shows that 
contextualized embeddings, position-attention mechanisms, and knowledge graph 
embeddings effectively improve deep learning-based concepts and relation 
extraction. This study demonstrates the potential for deep learning-based 
methods to help extract real-world evidence from unstructured patient data for 
drug safety surveillance.

©Bharath Dandala, Venkata Joopudi, Ching-Huei Tsou, Jennifer J Liang, 
Parthasarathy Suryanarayanan. Originally published in JMIR Medical Informatics 
(http://medinform.jmir.org), 10.07.2020.

DOI: 10.2196/18417
PMCID: PMC7382020
PMID: 32459650

Conflict of interest statement: Conflicts of Interest: None declared.


60. JMIR Med Inform. 2023 Feb 23;11:e40672. doi: 10.2196/40672.

A Comprehensive and Improved Definition for Hospital-Acquired Pressure Injury 
Classification Based on Electronic Health Records: Comparative Study.

Sotoodeh M(1), Zhang W(2), Simpson RL(2), Hertzberg VS(2), Ho JC(3).

Author information:
(1)Public Health Research Institute of University of Montreal, University of 
Montreal, Montreal, QC, Canada.
(2)School of Nursing, Emory University, Atlanta, GA, United States.
(3)Department of Computer Science, Emory University, Atlanta, GA, United States.

BACKGROUND: Patients develop pressure injuries (PIs) in the hospital owing to 
low mobility, exposure to localized pressure, circulatory conditions, and other 
predisposing factors. Over 2.5 million Americans develop PIs annually. The 
Center for Medicare and Medicaid considers hospital-acquired PIs (HAPIs) as the 
most frequent preventable event, and they are the second most common claim in 
lawsuits. With the growing use of electronic health records (EHRs) in hospitals, 
an opportunity exists to build machine learning models to identify and predict 
HAPI rather than relying on occasional manual assessments by human experts. 
However, accurate computational models rely on high-quality HAPI data labels. 
Unfortunately, the different data sources within EHRs can provide conflicting 
information on HAPI occurrence in the same patient. Furthermore, the existing 
definitions of HAPI disagree with each other, even within the same patient 
population. The inconsistent criteria make it impossible to benchmark machine 
learning methods to predict HAPI.
OBJECTIVE: The objective of this project was threefold. We aimed to identify 
discrepancies in HAPI sources within EHRs, to develop a comprehensive definition 
for HAPI classification using data from all EHR sources, and to illustrate the 
importance of an improved HAPI definition.
METHODS: We assessed the congruence among HAPI occurrences documented in 
clinical notes, diagnosis codes, procedure codes, and chart events from the 
Medical Information Mart for Intensive Care III database. We analyzed the 
criteria used for the 3 existing HAPI definitions and their adherence to the 
regulatory guidelines. We proposed the Emory HAPI (EHAPI), which is an improved 
and more comprehensive HAPI definition. We then evaluated the importance of the 
labels in training a HAPI classification model using tree-based and sequential 
neural network classifiers.
RESULTS: We illustrate the complexity of defining HAPI, with <13% of hospital 
stays having at least 3 PI indications documented across 4 data sources. 
Although chart events were the most common indicator, it was the only PI 
documentation for >49% of the stays. We demonstrate a lack of congruence across 
existing HAPI definitions and EHAPI, with only 219 stays having a consensus 
positive label. Our analysis highlights the importance of our improved HAPI 
definition, with classifiers trained using our labels outperforming others on a 
small manually labeled set from nurse annotators and a consensus set in which 
all definitions agreed on the label.
CONCLUSIONS: Standardized HAPI definitions are important for accurately 
assessing HAPI nursing quality metric and determining HAPI incidence for 
preventive measures. We demonstrate the complexity of defining an occurrence of 
HAPI, given the conflicting and incomplete EHR data. Our EHAPI definition has 
favorable properties, making it a suitable candidate for HAPI classification 
tasks.

©Mani Sotoodeh, Wenhui Zhang, Roy L Simpson, Vicki Stover Hertzberg, Joyce C Ho. 
Originally published in JMIR Medical Informatics (https://medinform.jmir.org), 
23.02.2023.

DOI: 10.2196/40672
PMCID: PMC9999254
PMID: 36649481

Conflict of interest statement: Conflicts of Interest: None declared.


61. J Hosp Palliat Nurs. 2025 Apr 7. doi: 10.1097/NJH.0000000000001117. Online ahead 
of print.

Opportunities for Improvement in Caring for Critically Ill Patients Who Are 
Incapacitated With No Evident Advance Directives or Surrogates: A Nested 
Case-Control Study.

Kinsinger M, Song J, Topaz M, Landau AY, Klitzman RL, Shang J, Stone PW, Cohen 
B.

Providing ethical, timely, and goal-concordant care for critical patients who 
are incapacitated with no evident advance directives or surrogates (INEADS) can 
pose challenges to nursing staff and other care team members and may delay or 
alter care trajectories. In a nested case-control study, we aimed to determine 
whether critical care patients who are INEADS have different hospitalization 
timelines, consultative services, and discharge dispositions relative to matched 
control subjects. Data were obtained from the publicly accessible Medical 
Information Mart for Intensive Care III database of 23 904 adult critical care 
hospitalizations in a Boston, Massachusetts, hospital from 2001 to 2012. Using 
natural language processing and verifying by manual chart review, we identified 
40 patients in this cohort who were INEADS and matched them 1:1 with control 
subjects based on age, sex, and comorbidity index. Average length of 
hospitalization was 11 days for patients and 9 days for control subjects; 
average time until code status documentation was 8 days for patients and 6 days 
for control subjects, and average time until documentation of social work 
involvement was 9 days for patients and 2 days for control subjects. Although 
these differences were not statistically significant, procedures to support 
timely ethical decision-making for patients who are INEADS require attention.

Copyright © 2025 by The Hospice and Palliative Nurses Association. All rights 
reserved.

DOI: 10.1097/NJH.0000000000001117
PMID: 40203195

Conflict of interest statement: The authors have no conflicts of interest to 
disclose.


62. JMIR Med Inform. 2024 Aug 5;12:e56627. doi: 10.2196/56627.

Advancing Accuracy in Multimodal Medical Tasks Through Bootstrapped 
Language-Image Pretraining (BioMedBLIP): Performance Evaluation Study.

Naseem U(1), Thapa S(2), Masood A(3)(4)(5).

Author information:
(1)School of Computing, Macquarie University, Sydney, Australia.
(2)Department of Computer Science, Virginia Tech, Blacksburg, VA, United States.
(3)Department of Circulation and Medical Imaging, Norwegian University of 
Science and Technology, Trondheim, Norway.
(4)Harvard Medical School, Harvard University, Boston, MA, United States.
(5)Department of Radiology, Boston Children's Hospital, Boston, MA, United 
States.

BACKGROUND: Medical image analysis, particularly in the context of visual 
question answering (VQA) and image captioning, is crucial for accurate diagnosis 
and educational purposes.
OBJECTIVE: Our study aims to introduce BioMedBLIP models, fine-tuned for VQA 
tasks using specialized medical data sets such as Radiology Objects in Context 
and Medical Information Mart for Intensive Care-Chest X-ray, and evaluate their 
performance in comparison to the state of the art (SOTA) original Bootstrapping 
Language-Image Pretraining (BLIP) model.
METHODS: We present 9 versions of BioMedBLIP across 3 downstream tasks in 
various data sets. The models are trained on a varying number of epochs. The 
findings indicate the strong overall performance of our models. We proposed 
BioMedBLIP for the VQA generation model, VQA classification model, and 
BioMedBLIP image caption model. We conducted pretraining in BLIP using medical 
data sets, producing an adapted BLIP model tailored for medical applications.
RESULTS: In VQA generation tasks, BioMedBLIP models outperformed the SOTA on the 
Semantically-Labeled Knowledge-Enhanced (SLAKE) data set, VQA in Radiology 
(VQA-RAD), and Image Cross-Language Evaluation Forum data sets. In VQA 
classification, our models consistently surpassed the SOTA on the SLAKE data 
set. Our models also showed competitive performance on the VQA-RAD and PathVQA 
data sets. Similarly, in image captioning tasks, our model beat the SOTA, 
suggesting the importance of pretraining with medical data sets. Overall, in 20 
different data sets and task combinations, our BioMedBLIP excelled in 15 (75%) 
out of 20 tasks. BioMedBLIP represents a new SOTA in 15 (75%) out of 20 tasks, 
and our responses were rated higher in all 20 tasks (P<.005) in comparison to 
SOTA models.
CONCLUSIONS: Our BioMedBLIP models show promising performance and suggest that 
incorporating medical knowledge through pretraining with domain-specific medical 
data sets helps models achieve higher performance. Our models thus demonstrate 
their potential to advance medical image analysis, impacting diagnosis, medical 
education, and research. However, data quality, task-specific variability, 
computational resources, and ethical considerations should be carefully 
addressed. In conclusion, our models represent a contribution toward the synergy 
of artificial intelligence and medicine. We have made BioMedBLIP freely 
available, which will help in further advancing research in multimodal medical 
tasks.

©Usman Naseem, Surendrabikram Thapa, Anum Masood. Originally published in JMIR 
Medical Informatics (https://medinform.jmir.org), 05.08.2024.

DOI: 10.2196/56627
PMCID: PMC11333867
PMID: 39102281

Conflict of interest statement: Conflicts of Interest: None declared.


63. Ann Transl Med. 2022 Jun;10(12):676. doi: 10.21037/atm-22-1613.

A prediction model with measured sentiment scores for the risk of in-hospital 
mortality in acute pancreatitis: a retrospective cohort study.

Liu Z(1), Yang Y(1), Song H(1), Luo J(2).

Author information:
(1)Emergency Department, Aerospace Center Hospital, Beijing, China.
(2)Traditional Chinese Medicine Rheumatic Immunology Department, People's 
Hospital of Chongqing Banan District, Chongqing, China.

BACKGROUND: Accurate and prompt clinical assessment of the severity and 
prognosis of patients with acute pancreatitis (AP) is critical, particularly 
during hospitalization. Natural language processing algorithms gain an 
opportunity from the growing number of free-text notes in electronic health 
records to mine this unstructured data, e.g., nursing notes, to detect and 
predict adverse outcomes. However, the predictive value of nursing notes for AP 
prognosis is unclear. In this study, a predictive model for in-hospital 
mortality in AP was developed using measured sentiment scores in nursing notes.
METHODS: The data of AP patients in the retrospective cohort study were 
collected from the Medical Information Mart for Intensive Care III (MIMIC-III) 
database. Sentiments in nursing notes were assessed by sentiment analysis. For 
each individual clinical note, sentiment polarity and sentiment subjectivity 
scores were assigned. The in-hospital mortality of AP patients was the outcome. 
A predictive model was built based on clinical information and sentiment scores, 
and its performance and clinical value were evaluated using the area under 
curves (AUCs) and decision-making curves, respectively.
RESULTS: Of the 631 AP patients included, 88 cases (13.9%) cases were dead in 
hospital. When various confounding factors were adjusted, the mean sentiment 
polarity was associated with a reduced risk of in-hospital mortality in AP [odds 
ratio (OR): 0.448; 95% confidence interval (CI): 0.233-0.833; P=0.014]. A 
predictive model was established in the training group via multivariate logistic 
regression analysis, including 12 independent variables. In the testing group, 
the model showed an AUC of 0.812, which was significantly greater than the 
sequential organ failure assessment (SOFA) of 0.732 and the simplified acute 
physiology score-II (SAPS-II) of 0.792 (P<0.05). When the same level of risk was 
considered, the clinical benefits of the predictive model were found to be the 
highest compared with SOFA and SAPS-II scores.
CONCLUSIONS: The model combined sentiment scores in nursing notes showed well 
predictive performance and clinical value in in-hospital mortality of AP 
patients.

2022 Annals of Translational Medicine. All rights reserved.

DOI: 10.21037/atm-22-1613
PMCID: PMC9279801
PMID: 35845515

Conflict of interest statement: Conflicts of Interest: All authors have 
completed the ICMJE uniform disclosure form (available at 
https://atm.amegroups.com/article/view/10.21037/atm-22-1613/coif). The authors 
have no conflicts of interest to declare.


64. J Biomed Inform. 2022 Jan;125:103971. doi: 10.1016/j.jbi.2021.103971. Epub 2021 
Dec 14.

Word embeddings trained on published case reports are lightweight, effective for 
clinical tasks, and free of protected health information.

Flamholz ZN(1), Crane-Droesch A(2), Ungar LH(3), Weissman GE(4).

Author information:
(1)Medical Scientist Training Program, Albert Einstein College of Medicine, 
Bronx, NY, USA. Electronic address: zachary.flamholz@einsteinmed.edu.
(2)Penn Medicine Predictive Healthcare, University of Pennsylvania Health 
System, Philadelphia, PA, USA; Palliative and Advanced Illness Research (PAIR) 
Center, University of Pennsylvania Perelman School of Medicine, Philadelphia, 
PA, USA.
(3)Department of Computer and Information Science, University of Pennsylvania, 
Philadelphia, PA, USA; Institute for Biomedical Informatics, University of 
Pennsylvania, Philadelphia, PA, USA.
(4)Palliative and Advanced Illness Research (PAIR) Center, University of 
Pennsylvania Perelman School of Medicine, Philadelphia, PA, USA; Institute for 
Biomedical Informatics, University of Pennsylvania, Philadelphia, PA, USA; 
Leonard Davis Institute of Health Economics, University of Pennsylvania, 
Philadelphia, PA, USA; Pulmonary, Allergy, and Critical Care Division, 
University of Pennsylvania Perelman School of Medicine, Philadelphia, PA, USA.

OBJECTIVE: Quantify tradeoffs in performance, reproducibility, and resource 
demands across several strategies for developing clinically relevant word 
embeddings.
MATERIALS AND METHODS: We trained separate embeddings on all full-text 
manuscripts in the Pubmed Central (PMC) Open Access subset, case reports 
therein, the English Wikipedia corpus, the Medical Information Mart for 
Intensive Care (MIMIC) III dataset, and all notes in the University of 
Pennsylvania Health System (UPHS) electronic health record. We tested embeddings 
in six clinically relevant tasks including mortality prediction and 
de-identification, and assessed performance using the scaled Brier score (SBS) 
and the proportion of notes successfully de-identified, respectively.
RESULTS: Embeddings from UPHS notes best predicted mortality (SBS 0.30, 95% CI 
0.15 to 0.45) while Wikipedia embeddings performed worst (SBS 0.12, 95% CI -0.05 
to 0.28). Wikipedia embeddings most consistently (78% of notes) and the full PMC 
corpus embeddings least consistently (48%) de-identified notes. Across all six 
tasks, the full PMC corpus demonstrated the most consistent performance, and the 
Wikipedia corpus the least. Corpus size ranged from 49 million tokens (PMC case 
reports) to 10 billion (UPHS).
DISCUSSION: Embeddings trained on published case reports performed as least as 
well as embeddings trained on other corpora in most tasks, and clinical corpora 
consistently outperformed non-clinical corpora. No single corpus produced a 
strictly dominant set of embeddings across all tasks and so the optimal training 
corpus depends on intended use.
CONCLUSION: Embeddings trained on published case reports performed comparably on 
most clinical tasks to embeddings trained on larger corpora. Open access corpora 
allow training of clinically relevant, effective, and reproducible embeddings.

Copyright © 2021 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jbi.2021.103971
PMCID: PMC8766939
PMID: 34920127 [Indexed for MEDLINE]


65. JMIR AI. 2023 Jan-Dec;2:e45000. doi: 10.2196/45000. Epub 2023 Jul 18.

Artificial Intelligence-Enabled Software Prototype to Inform Opioid 
Pharmacovigilance From Electronic Health Records: Development and Usability 
Study.

Sorbello A(1), Haque SA(1), Hasan R(1), Jermyn R(2), Hussein A(2), Vega A(2), 
Zembrzuski K(2), Ripple A(3), Ahadpour M(1).

Author information:
(1)Center for Drug Evaluation and Research, US Food and Drug Administration, 
Silver Spring, MD, United States.
(2)Neuromuscular Institute, Rowan-Virtua School of Osteopathic Medicine, 
Stratford, NJ, United States.
(3)Lister Hill National Center for Biomedical Communications, National Library 
of Medicine-National Institutes of Health, Rockville, MD, United States.

BACKGROUND: The use of patient health and treatment information captured in 
structured and unstructured formats in computerized electronic health record 
(EHR) repositories could potentially augment the detection of safety signals for 
drug products regulated by the US Food and Drug Administration (FDA). Natural 
language processing and other artificial intelligence (AI) techniques provide 
novel methodologies that could be leveraged to extract clinically useful 
information from EHR resources.
OBJECTIVE: Our aim is to develop a novel AI-enabled software prototype to 
identify adverse drug event (ADE) safety signals from free-text discharge 
summaries in EHRs to enhance opioid drug safety and research activities at the 
FDA.
METHODS: We developed a prototype for web-based software that leverages keyword 
and trigger-phrase searching with rule-based algorithms and deep learning to 
extract candidate ADEs for specific opioid drugs from discharge summaries in the 
Medical Information Mart for Intensive Care III (MIMIC III) database. The 
prototype uses MedSpacy components to identify relevant sections of discharge 
summaries and a pretrained natural language processing (NLP) model, Spark NLP 
for Healthcare, for named entity recognition. Fifteen FDA staff members provided 
feedback on the prototype's features and functionalities.
RESULTS: Using the prototype, we were able to identify known, labeled, 
opioid-related adverse drug reactions from text in EHRs. The AI-enabled model 
achieved accuracy, recall, precision, and F1-scores of 0.66, 0.69, 0.64, and 
0.67, respectively. FDA participants assessed the prototype as highly desirable 
in user satisfaction, visualizations, and in the potential to support drug 
safety signal detection for opioid drugs from EHR data while saving time and 
manual effort. Actionable design recommendations included (1) enlarging the tabs 
and visualizations; (2) enabling more flexibility and customizations to fit end 
users' individual needs; (3) providing additional instructional resources; (4) 
adding multiple graph export functionality; and (5) adding project summaries.
CONCLUSIONS: The novel prototype uses innovative AI-based techniques to automate 
searching for, extracting, and analyzing clinically useful information captured 
in unstructured text in EHRs. It increases efficiency in harnessing real-world 
data for opioid drug safety and increases the usability of the data to support 
regulatory review while decreasing the manual research burden.

DOI: 10.2196/45000
PMCID: PMC10538589
PMID: 37771410

Conflict of interest statement: Conflicts of Interest None declared.


66. J Med Internet Res. 2024 Aug 21;26:e52730. doi: 10.2196/52730.

Using Domain Adaptation and Inductive Transfer Learning to Improve Patient 
Outcome Prediction in the Intensive Care Unit: Retrospective Observational 
Study.

Mutnuri MK(1)(2), Stelfox HT(3)(4), Forkert ND(5)(6), Lee J(1)(7)(8)(9).

Author information:
(1)Data Intelligence for Health Lab, Cumming School of Medicine, University of 
Calgary, Calgary, AB, Canada.
(2)Department of Biomedical Engineering, Schulich School of Engineering, 
University of Calgary, Calgary, AB, Canada.
(3)Department of Critical Care Medicine, Cumming School of Medicine, University 
of Calgary, Calgary, AB, Canada.
(4)O'Brien Institute for Public Health, Cumming School of Medicine, University 
of Calgary, Calgary, AB, Canada.
(5)Department of Radiology, Cumming School of Medicine, University of Calgary, 
Calgary, AB, Canada.
(6)Alberta Children's Hospital Research Institute, Cumming School of Medicine, 
University of Calgary, Calgary, AB, Canada.
(7)Department of Cardiac Sciences, Cumming School of Medicine, University of 
Calgary, Calgary, AB, Canada.
(8)Department of Community Health Sciences, Cumming School of Medicine, 
University of Calgary, Calgary, AB, Canada.
(9)Department of Preventive Medicine, School of Medicine, Kyung Hee University, 
Seoul, Republic of Korea.

BACKGROUND: Accurate patient outcome prediction in the intensive care unit (ICU) 
can potentially lead to more effective and efficient patient care. Deep learning 
models are capable of learning from data to accurately predict patient outcomes, 
but they typically require large amounts of data and computational resources. 
Transfer learning (TL) can help in scenarios where data and computational 
resources are scarce by leveraging pretrained models. While TL has been widely 
used in medical imaging and natural language processing, it has been rare in 
electronic health record (EHR) analysis. Furthermore, domain adaptation (DA) has 
been the most common TL method in general, whereas inductive transfer learning 
(ITL) has been rare. To the best of our knowledge, DA and ITL have never been 
studied in-depth in the context of EHR-based ICU patient outcome prediction.
OBJECTIVE: This study investigated DA, as well as rarely researched ITL, in 
EHR-based ICU patient outcome prediction under simulated, varying levels of data 
scarcity.
METHODS: Two patient cohorts were used in this study: (1) eCritical, a 
multicenter ICU data from 55,689 unique admission records from 48,672 unique 
patients admitted to 15 medical-surgical ICUs in Alberta, Canada, between March 
2013 and December 2019, and (2) Medical Information Mart for Intensive Care III, 
a single-center, publicly available ICU data set from Boston, Massachusetts, 
acquired between 2001 and 2012 containing 61,532 admission records from 46,476 
patients. We compared DA and ITL models with baseline models (without TL) of 
fully connected neural networks, logistic regression, and lasso regression in 
the prediction of 30-day mortality, acute kidney injury, ICU length of stay, and 
hospital length of stay. Random subsets of training data, ranging from 1% to 
75%, as well as the full data set, were used to compare the performances of DA 
and ITL with the baseline models at various levels of data scarcity.
RESULTS: Overall, the ITL models outperformed the baseline models in 55 of 56 
comparisons (all P values <.001). The DA models outperformed the baseline models 
in 45 of 56 comparisons (all P values <.001). ITL resulted in better performance 
than DA in terms of the number of times and the margin with which it 
outperformed the baseline models. In 11 of 16 cases (8 of 8 for ITL and 3 of 8 
for DA), TL models outperformed baseline models when trained using 1% data 
subset.
CONCLUSIONS: TL-based ICU patient outcome prediction models are useful in 
data-scarce scenarios. The results of this study can be used to estimate ICU 
outcome prediction performance at different levels of data scarcity, with and 
without TL. The publicly available pretrained models from this study can serve 
as building blocks in further research for the development and validation of 
models in other ICU cohorts and outcomes.

©Maruthi Kumar Mutnuri, Henry Thomas Stelfox, Nils Daniel Forkert, Joon Lee. 
Originally published in the Journal of Medical Internet Research 
(https://www.jmir.org), 21.08.2024.

DOI: 10.2196/52730
PMCID: PMC11375375
PMID: 39167442 [Indexed for MEDLINE]

Conflict of interest statement: Conflicts of Interest: JL is a cofounder and a 
major shareholder of Symbiotic AI, Inc.


67. Stud Health Technol Inform. 2020 Jun 16;270:1195-1196. doi: 10.3233/SHTI200359.

An "in silico" Bench to Bedside Approach to Investigating Sepsis Biomarkers.

O'Mahony G(1), Hawthorne C(1), McQuaid K(1), Lopez-Campos GH(1).

Author information:
(1)Wellcome-Wolfson Institute for Experimental Medicine, Queen's University 
Belfast, Belfast, UK.

Sepsis results in various patient complications and is due to a heightened 
inflammatory response against infection. This condition requires further 
exploration of biomarkers. We employed an "in silico" method comprised of 
text-mining and additionally clinical validation through the Medical Information 
Mart for Intensive Care. We highlight that Factor VIII shows potential as a 
pertinent septic shock biomarker.

DOI: 10.3233/SHTI200359
PMID: 32570576 [Indexed for MEDLINE]


68. J Biomed Inform. 2021 Apr;116:103699. doi: 10.1016/j.jbi.2021.103699. Epub 2021 
Feb 15.

GHS-NET a generic hybridized shallow neural network for multi-label biomedical 
text classification.

Ibrahim MA(1), Ghani Khan MU(2), Mehmood F(3), Asim MN(4), Mahmood W(3).

Author information:
(1)Intelligent Criminology Research Lab, National Center of Artificial 
Intelligence, Al-Khawarizmi Institute of Computer Science, UET, Lahore, 
Pakistan; German Research Center for Artificial Intelligence (DFKI), 67663 
Kaiserslautern, Germany.
(2)Intelligent Criminology Research Lab, National Center of Artificial 
Intelligence, Al-Khawarizmi Institute of Computer Science, UET, Lahore, 
Pakistan; Department of Computer Science, University of Engineering and 
Technology (UET), Lahore, Pakistan.
(3)Intelligent Criminology Research Lab, National Center of Artificial 
Intelligence, Al-Khawarizmi Institute of Computer Science, UET, Lahore, 
Pakistan.
(4)Intelligent Criminology Research Lab, National Center of Artificial 
Intelligence, Al-Khawarizmi Institute of Computer Science, UET, Lahore, 
Pakistan; German Research Center for Artificial Intelligence (DFKI), 67663 
Kaiserslautern, Germany. Electronic address: nabeel.asim@kics.edu.pk.

Exponential growth of biomedical literature and clinical data demands more 
robust yet precise computational methodologies to extract useful insights from 
biomedical literature and to perform accurate assignment of disease-specific 
codes. Such approaches can largely enhance the effectiveness of diverse 
biomedicine and bioinformatics applications. State-of-the-art computational 
biomedical text classification methodologies either solely leverage 
discrimintaive features extracted through convolution operations performed by 
deep convolutional neural network or contextual information extracted by 
recurrent neural network. However, none of the methodology takes advantage of 
both convolutional and recurrent neural networks. Further, existing 
methodologies lack to produce decent performance for the classification of 
different genre biomedical text such as biomedical literature or clinical notes. 
We, for the very first time, present a generic deep learning based hybrid 
multi-label classification methodology namely GHS-NET which can be utilized to 
accurately classify biomedical text of diverse genre. GHS-NET makes use of 
convolutional neural network to extract most discriminative features and 
bi-directional Long Short-Term Memory to acquire contextual information. GHS-NET 
effectiveness is evaluated for extreme multi-label biomedical literature 
classification and assignment of ICD-9 codes to clinical notes. For the task of 
extreme multi-label biomedical literature classification, performance comparison 
of GHS-Net and state-of-the-art deep learning based methodology reveals that 
GHS-Net marks the increment of 1%, 6%, and 1% for hallmarks of cancer dataset, 
10%, 16%, and 11% for chemical exposure dataset in terms of precision, recall, 
and F1-score. For the task of clinical notes classification, GHS-Net outperforms 
previous best deep learning based methodology over Medical Information Mart for 
Intensive Care dataset (MIMIC-III) by the significant margin of 6%, 8% in terms 
of recall and F1-score. GHS-NET is available as a web service at1 and 
potentially can be used to accurately classify multi-variate disease and 
chemical exposure specific text.

Copyright © 2021 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jbi.2021.103699
PMID: 33601013 [Indexed for MEDLINE]


69. Drug Saf. 2025 Feb 21. doi: 10.1007/s40264-025-01525-w. Online ahead of print.

Effectiveness of Transformer-Based Large Language Models in Identifying Adverse 
Drug Reaction Relations from Unstructured Discharge Summaries in Singapore.

Koon YL(1), Lam YT(1), Tan HX(1), Teo DHC(1), Neo JW(1), Yap AJY(1), Ang PS(1), 
Loke CPW(1), Tham MY(1), Tan SH(1), Soh SLB(1), Foo BQP(1), Ling ZJ(2), Yip 
JLW(3)(4), Dorajoo SR(5).

Author information:
(1)Vigilance and Compliance Branch, Health Products Regulation Group, Health 
Sciences Authority, 11 Biopolis Way, #11-01 Helios, Singapore, 138667, 
Singapore.
(2)Regional Health System Office, National University of Singapore, National 
University Health System, Singapore, Singapore.
(3)Department of Cardiology, National University Heart Centre, Singapore, 
Singapore.
(4)Academic Informatics Office, National University Health System, Singapore, 
Singapore.
(5)Vigilance and Compliance Branch, Health Products Regulation Group, Health 
Sciences Authority, 11 Biopolis Way, #11-01 Helios, Singapore, 138667, 
Singapore. sreemanee_dorajoo@hsa.gov.sg.

INTRODUCTION: Transformer-based large language models (LLMs) have transformed 
the field of natural language processing and led to significant advancements in 
various text processing tasks. However, the applicability of these LLMs in 
identifying related drug-adverse event (AE) pairs within clinical context may be 
limited by the prevalent use of non-standard sentence structures and grammar.
METHOD: Nine transformer-based LLMs pre-trained on biomedical domain corpora are 
fine-tuned on annotated data (n = 5088) to classify drug-AE pairs in 
unstructured discharge summaries as causally related or unrelated. These LLMs 
are then validated on text segments from deidentified hospital discharge 
summaries from Singapore (n = 1647). To assess generalisability, the models are 
validated on annotated segments (n = 4418) from the Medical Information Mart for 
Intensive Care (MIMIC-III) database. Performance of LLMs in identifying related 
drug-AE pairs is then compared against a prior benchmark set by traditional 
machine learning models on the same data.
RESULTS: Using an LLM-Bidirectional long short-term memory (LLM-BiLSTM) 
architecture, transformer-based LLMs improve F1 score as compared to prior 
benchmark with BioM-ELECTRA-Large-BiLSTM showing an average F1 score improvement 
of 16.1% (increase from 0.64 to 0.74). Applying additional rules on the 
LLM-based predictions, like ignoring drug-AE pairs when the AE is a known 
indication of the drug, results in a further reduction in false positive rates 
with precision increases of up to 5.6% (0.04 increment).
CONCLUSION: Transformer-based LLMs outperform traditional machine learning 
methods in identifying causally related drug-AE pairs embedded within 
unstructured discharge summaries. Nonetheless the improvement in performance 
with rules indicates that LLMs still possess some degree of imperfection for 
this causal relation detection task.

© 2025. The Author(s), under exclusive licence to Springer Nature Switzerland 
AG.

DOI: 10.1007/s40264-025-01525-w
PMID: 39982676

Conflict of interest statement: Declarations. Funding: This study was conducted 
under the SAPhIRE Project, funded by a Strategic Positioning Fund grant from the 
Biomedical Research Council of the Agency for Science, Technology and Research 
of Singapore (SPF2014/001). Conflict of interest: The authors have no conflicts 
of interest that are directly relevant to the content of this article. The view 
expressed in this article are the authors’ personal views and may not be 
understood or quoted as being made on behalf or reflect the positions of HSA, 
NUH and NUS. Ethical approval: No ethics approval was required for this study. 
Consent to participate: Not applicable. Consent for publication: Not applicable. 
Code availability: All data were processed and analysed using Python 3.8. The 
code developed for this study can be made available for research purposes upon 
justified request. Interested researchers should contact the corresponding 
author via email, providing a concise outline of their intended use for the 
code. Model availability: The models developed in this study were trained on 
confidential clinical data. To protect patient privacy and prevent potential 
information leakage, the trained models cannot be made available. Availability 
of data and material: The MIMIC-III database [13, 14], an open-source resource 
utilised in this study, is available through Google Cloud Platform (GCP) and 
Amazon Web Services (AWS). To facilitate access, investigators are required to 
append the appropriate cloud identifier to their PhysioNet profile. More 
information is provided on the official MIMIC-III website ( 
https://mimic.mit.edu/gettingstarted/cloud/ ). Author contributions: YL Koon, YT 
Lam and SR Dorajoo designed the research and models and did the computational 
framework to analyse the data. PS Ang, CWP Loke, MY Tham, SH Tan, SBL Soh, BPQ 
Foo, DCH Teo and SR Dorajoo provided the domain expertise for manual annotation 
of discharge summaries and developed the list of trigger words, short forms and 
acronyms. HX Tan, DCH Teo, JW Neo, AJY Yap and PS Ang participated in 
discussions and refined the results. ZJ Ling and JWL Yip coordinated the 
provision of NUH data and participated in discussions. All authors read and 
approved the final version of this manuscript.


70. medRxiv [Preprint]. 2024 Oct 8:2024.10.08.24315035. doi: 
10.1101/2024.10.08.24315035.

Automated Transformation of Unstructured Cardiovascular Diagnostic Reports into 
Structured Datasets Using Sequentially Deployed Large Language Models.

Shankar SV(1), Dhingra LS(1), Aminorroaya A(1), Adejumo P(1), Nadkarni GN(2), Xu 
H(3), Brandt C(3), Oikonomou EK(1), Pedroso AF(1), Khera R(1)(4)(5)(3).

Author information:
(1)Section of Cardiovascular Medicine, Department of Internal Medicine, Yale 
School of Medicine, New Haven, CT, USA.
(2)The Charles Bronfman Institute for Personalized Medicine, Icahn School of 
Medicine at Mount Sinai, New York, NY, USA.
(3)Section of Biomedical Informatics and Data Science, Yale School of Medicine, 
New Haven, CT.
(4)Section of Health Informatics, Department of Biostatistics, Yale School of 
Public Health, New Haven, CT, USA.
(5)Center for Outcomes Research and Evaluation (CORE), Yale New Haven Hospital, 
New Haven, CT, USA.

BACKGROUND: Rich data in cardiovascular diagnostic testing are often sequestered 
in unstructured reports, with the necessity of manual abstraction limiting their 
use in real-time applications in patient care and research.
METHODS: We developed a two-step process that sequentially deploys generative 
and interpretative large language models (LLMs; Llama2 70b and Llama2 13b). 
Using a Llama2 70b model, we generated varying formats of transthoracic 
echocardiogram (TTE) reports from 3,000 real-world echo reports with paired 
structured elements, leveraging temporal changes in reporting formats to define 
the variations. Subsequently, we fine-tuned Llama2 13b using sequentially larger 
batches of generated echo reports as inputs, to extract data from free-text 
narratives across 18 clinically relevant echocardiographic fields. This was set 
up as a prompt-based supervised training task. We evaluated the fine-tuned 
Llama2 13b model, HeartDx-LM, on several distinct echocardiographic datasets: 
(i) reports across the different time periods and formats at Yale New Haven 
Health System (YNHHS), (ii) the Medical Information Mart for Intensive Care 
(MIMIC) III dataset, and (iii) the MIMIC IV dataset. We used the accuracy of 
extracted fields and Cohen's Kappa as the metrics and have publicly released the 
HeartDX-LM model.
RESULTS: The HeartDX-LM model was trained on randomly selected 2,000 synthetic 
echo reports with varying formats and paired structured labels, with a wide 
range of clinical findings. We identified a lower threshold of 500 annotated 
reports required for fine-tuning Llama2 13b to achieve stable and consistent 
performance. At YNHHS, the HeartDx-LM model accurately extracted 69,144 out of 
70,032 values (98.7%) across 18 clinical fields from unstructured reports in the 
test set from contemporary records where paired structured data were also 
available. In older echo reports where only unstructured reports were available, 
the model achieved 87.1% accuracy against expert annotations for the same 18 
fields for a random sample of 100 reports. Similarly, in expert-annotated 
external validation sets from MIMIC-IV and MIMIC-III, HeartDx-LM correctly 
extracted 201 out of 220 available values (91.3%) and 615 out of 707 available 
values (87.9%), respectively, from 100 randomly chosen and expert annotated echo 
reports from each set.
CONCLUSION: We developed a novel method using paired large and moderate-sized 
LLMs to automate the extraction of unstructured echocardiographic reports into 
tabular datasets. Our approach represents a scalable strategy that transforms 
unstructured reports into computable elements that can be leveraged to improve 
cardiovascular care quality and enable research.

DOI: 10.1101/2024.10.08.24315035
PMCID: PMC11482995
PMID: 39417094

Conflict of interest statement: Dr. Khera is an Associate Editor of JAMA and is 
a co-founder of Ensight-AI. Dr. Khera receives support from the National Heart, 
Lung, and Blood Institute of the National Institutes of Health (under awards 
R01HL167858 and K23HL153775) and the Doris Duke Charitable Foundation (under 
award 2022060). He receives support from the Blavatnik Foundation through the 
Blavatnik Fund for Innovation at Yale. He also receives research support, 
through Yale, from Bristol-Myers Squibb, BridgeBio, and Novo Nordisk. In 
addition to 63/346,610, Dr. Khera is a coinventor of U.S. Pending Patent 
Applications WO2023230345A1, US20220336048A1, 63/484,426, 63/508,315, 
63/580,137, 63/619,241, 63/346,610, 63/562,335 and 18/813,882. Dr. Khera, Dr. 
Oikonomou and Mr. Vasisht Shankar are co-inventors of the US patent application 
63/606,203. Dr. Khera and Dr. Oikonomou are co-founders of Evidence2Health, a 
precision health platform to improve evidence-based cardiovascular care. Dr. 
Oikonomou receives support from the National Heart, Lung, and Blood Institute of 
the National Institutes of Health (under award F32HL170592). He is a co-inventor 
of the U.S. Patent Applications 18/813,882, 17/720,068, 63/619,241, 63/177,117, 
63/580,137, 63/606,203, 63/562,335, US11948230B2 , US20210374951A1. He has been 
a consultant for Caristo Diagnostics Ltd and Ensight-AI Inc, and has received 
royalty fees from technology licensed through the University of Oxford.. Mr. 
Vasisht Shankar works as a data scientist at Evidence2Health (outside the 
current work). Dr. Nadkarni is a founder of Renalytix, Pensieve, and Verici and 
provides consultancy services to AstraZeneca, Reata, Renalytix, and Pensieve. He 
also has equity in Renalytix, Pensieve, and Verici.


71. JMIR Med Educ. 2024 Feb 13;10:e51391. doi: 10.2196/51391.

Learning to Make Rare and Complex Diagnoses With Generative AI Assistance: 
Qualitative Study of Popular Large Language Models.

Abdullahi T(1), Singh R(1)(2), Eickhoff C(3).

Author information:
(1)Department of Computer Science, Brown University, Providence, RI, United 
States.
(2)Center for Computational Molecular Biology, Brown University, Providence, RI, 
United States.
(3)School of Medicine, University of Tübingen, Tübingen, Germany.

BACKGROUND: Patients with rare and complex diseases often experience delayed 
diagnoses and misdiagnoses because comprehensive knowledge about these diseases 
is limited to only a few medical experts. In this context, large language models 
(LLMs) have emerged as powerful knowledge aggregation tools with applications in 
clinical decision support and education domains.
OBJECTIVE: This study aims to explore the potential of 3 popular LLMs, namely 
Bard (Google LLC), ChatGPT-3.5 (OpenAI), and GPT-4 (OpenAI), in medical 
education to enhance the diagnosis of rare and complex diseases while 
investigating the impact of prompt engineering on their performance.
METHODS: We conducted experiments on publicly available complex and rare cases 
to achieve these objectives. We implemented various prompt strategies to 
evaluate the performance of these models using both open-ended and 
multiple-choice prompts. In addition, we used a majority voting strategy to 
leverage diverse reasoning paths within language models, aiming to enhance their 
reliability. Furthermore, we compared their performance with the performance of 
human respondents and MedAlpaca, a generative LLM specifically designed for 
medical tasks.
RESULTS: Notably, all LLMs outperformed the average human consensus and 
MedAlpaca, with a minimum margin of 5% and 13%, respectively, across all 30 
cases from the diagnostic case challenge collection. On the frequently 
misdiagnosed cases category, Bard tied with MedAlpaca but surpassed the human 
average consensus by 14%, whereas GPT-4 and ChatGPT-3.5 outperformed MedAlpaca 
and the human respondents on the moderately often misdiagnosed cases category 
with minimum accuracy scores of 28% and 11%, respectively. The majority voting 
strategy, particularly with GPT-4, demonstrated the highest overall score across 
all cases from the diagnostic complex case collection, surpassing that of other 
LLMs. On the Medical Information Mart for Intensive Care-III data sets, Bard and 
GPT-4 achieved the highest diagnostic accuracy scores, with multiple-choice 
prompts scoring 93%, whereas ChatGPT-3.5 and MedAlpaca scored 73% and 47%, 
respectively. Furthermore, our results demonstrate that there is no 
one-size-fits-all prompting approach for improving the performance of LLMs and 
that a single strategy does not universally apply to all LLMs.
CONCLUSIONS: Our findings shed light on the diagnostic capabilities of LLMs and 
the challenges associated with identifying an optimal prompting strategy that 
aligns with each language model's characteristics and specific task 
requirements. The significance of prompt engineering is highlighted, providing 
valuable insights for researchers and practitioners who use these language 
models for medical training. Furthermore, this study represents a crucial step 
toward understanding how LLMs can enhance diagnostic reasoning in rare and 
complex medical cases, paving the way for developing effective educational tools 
and accurate diagnostic aids to improve patient care and outcomes.

©Tassallah Abdullahi, Ritambhara Singh, Carsten Eickhoff. Originally published 
in JMIR Medical Education (https://mededu.jmir.org), 13.02.2024.

DOI: 10.2196/51391
PMCID: PMC10900078
PMID: 38349725 [Indexed for MEDLINE]

Conflict of interest statement: Conflicts of Interest: None declared.


72. Digit Health. 2025 Apr 15;11:20552076251326021. doi: 10.1177/20552076251326021. 
eCollection 2025 Jan-Dec.

Development of a digital treatment analyzer for the management of prostate 
cancer patients, with the help of real world data and use of predictive 
modelling.

Korolkov L(1), Robinson HA(2), Mouratis K(3).

Author information:
(1)Technical University of Munich, Munchen, Germany.
(2)Health eResearch Centre, University of Manchester, Manchester, UK.
(3)Leipzig Heart Centre University Hospital: Herzzentrum Leipzig 
Universitatsklinik, Leipzig, Germany.

Prostate cancer is the second most diagnosed cancer in the world. Treatment 
guidelines involve a multitude of therapies, however adherence to them is not 
fully established, while lack of personalized treatment strategies fails to put 
the patient as an individual clinical profile at the center of their treatment. 
We aim to present the concept of a digital treatment analyzer (TA) for the 
management of prostate cancer (PC) patients, leveraging real-world data (RWD) 
and predictive modeling to enhance personalized disease management strategies 
and adherence to PC guidelines, ultimately aiming to optimize therapeutic 
efficacy and improve outcomes. The TA comprises digital tools integrated into 
one user-intuitive interface, facilitating the development of patient-specific 
clinical profiles, classification of patients into matched historical RWD 
cohorts, presentation of relevant clinical guidelines, visual representation of 
treatment and outcomes, and mortality risk prediction based on a validated 
machine learning models. The Medical Information Mart for Intensive Care (MIMIC) 
IV dataset was utilized, including structured and unstructured data from the 
patient journey. The developed TA represents a promising approach to enhance 
personalized disease management strategies and adherence to PC guidelines. By 
integrating contemporary clinical guidelines, RWD and AI-driven insights, our 
digital TA aims to optimize therapeutic efficacy and improve patient outcomes. 
The presented concept demonstrates the potential for using a digital approach 
that integrates RWD into a treatment journey, to provide healthcare stakeholders 
with a holistic approach to PC management involving all available modern tools 
to achieve optimal outcomes.

© The Author(s) 2025.

DOI: 10.1177/20552076251326021
PMCID: PMC12034955
PMID: 40297371

Conflict of interest statement: The authors declared no potential conflicts of 
interest with respect to the research, authorship, and/or publication of this 
article.